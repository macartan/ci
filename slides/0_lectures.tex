% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\usetheme[]{AnnArbor}
\usecolortheme{seahorse}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\newif\ifbibliography
\usepackage{soul}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
\usepackage{caption}
% Make caption package work with longtable
\makeatletter
\def\fnum@table{\tablename~\thetable}
\makeatother
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{amsmath, amssymb, bbm, amstext, array, listings, mathtools, caption, color, graphics, ulem, caption, changepage, atbegshi, soul}
\newcommand\E{\mathbb{E}}
\newcommand\V{\mathbb{V}}
\hypersetup{colorlinks=true,linkcolor=red}
\usepackage{ulem}
\pdfstringdefDisableCommands{\let\sout\relax}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Lectures on causal inference and experimental methods},
  pdfauthor={Macartan Humphreys},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Lectures on causal inference and experimental methods}
\author{Macartan Humphreys}
\date{}

\begin{document}
\frame{\titlepage}
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[borderline west={3pt}{0pt}{shadecolor}, interior hidden, sharp corners, breakable, enhanced, boxrule=0pt, frame hidden]}{\end{tcolorbox}}\fi

\hypertarget{roadmap}{%
\section{Roadmap}\label{roadmap}}

\begin{frame}[fragile]{Road Map}
\protect\hypertarget{road-map}{}
Day 1: Intro

\begin{itemize}
\tightlist
\item
  1.1 Course outline, tools,
\item
  1.2 Introduction to Declare design
\end{itemize}

Day 2: Causality

\begin{itemize}
\tightlist
\item
  2.1 Fundamental problems and basic solutions
\item
  2.2 General inquiries and causal identification
\end{itemize}

Day 3: Estimation and Inference

\begin{itemize}
\tightlist
\item
  3.1 Frequentist
\item
  3.2 Bayesian
\end{itemize}

Day 4:

\begin{itemize}
\tightlist
\item
  4.1 Experimental Design
\item
  4.2 Design evaluation
\end{itemize}

Day 5:

\begin{itemize}
\tightlist
\item
  5.1 Topics and techniques
\item
  5.2 Open science
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}\OperatorTok{|}\NormalTok{ echo}\InformationTok{: false}
\NormalTok{\#\#}\OperatorTok{|}\NormalTok{ include}\InformationTok{: false}

\FunctionTok{.reveal}\NormalTok{ table \{}
  \KeywordTok{font{-}size}\NormalTok{: }\DecValTok{medium}\OperatorTok{;}
\NormalTok{\}}

\NormalTok{\#\# also}\InformationTok{: smaller}\OperatorTok{,}\NormalTok{ small}
\end{Highlighting}
\end{Shaded}
\end{frame}

\hypertarget{getting-started}{%
\subsection{Getting started}\label{getting-started}}

\begin{frame}[fragile]{Plan}
\protect\hypertarget{plan}{}
\begin{itemize}
\tightlist
\item
  General aims and structure
\item
  Expectations
\item
  Pointers for exercises
\item
  Quick \texttt{declaredesign} intro
\end{itemize}
\end{frame}

\begin{frame}{Aims}
\protect\hypertarget{aims}{}
\begin{itemize}
\tightlist
\item
  Deep understanding of key ideas in causal inference
\item
  Transportable tools for understanding how to evaluate and improve
  design
\item
  Applied skills for design and analysis
\item
  Exposure to open science practices
\end{itemize}
\end{frame}

\begin{frame}{Syllabus}
\protect\hypertarget{syllabus}{}
\url{https://macartan.github.io/ci/syllabus.pdf}
\end{frame}

\begin{frame}{The topics}
\protect\hypertarget{the-topics}{}
Day 1: Intro

\begin{itemize}
\tightlist
\item
  1.1 Course outline, tools,
\item
  1.2 Introduction to Declare design
\end{itemize}

Day 2: Causality

\begin{itemize}
\tightlist
\item
  2.1 Fundamental problems and basic solutions
\item
  2.2 General inquiries and causal identification
\end{itemize}

Day 3: Estimation and Inference

\begin{itemize}
\tightlist
\item
  3.1 Frequentist
\item
  3.2 Bayesian
\end{itemize}

Day 4:

\begin{itemize}
\tightlist
\item
  4.1 Experimental Design
\item
  4.2 Design evaluation
\end{itemize}

Day 5:

\begin{itemize}
\tightlist
\item
  5.1 Topics and techniques @ref(topics)
\item
  5.2 Open science @ref(openscience)
\end{itemize}
\end{frame}

\begin{frame}{Expectations}
\protect\hypertarget{expectations}{}
\begin{itemize}
\tightlist
\item
  5 tasks
\item
  (Required) Work in four ``exercise teams'': 1 team per session
  \(\times 4\)
\item
  (Optional) Prepare a research design or short paper, perhaps building
  on existing work. Typically this contains:

  \begin{itemize}
  \tightlist
  \item
    a problem statement
  \item
    a description of a method to address the problem
  \item
    analytic or simulation based results describing properties of the
    solution
  \item
    a discussion of implications for practice. A passing paper will
    illustrate subtle features of a method; a good paper will identify
    unknow properties of a method; en excellent paper will develop a new
    method.
  \end{itemize}
\item
  Plus general reading and participation.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Exercise team job}
\protect\hypertarget{exercise-team-job}{}
Teams should prepare 15 - 20 minute presentations on set puzzles.
Typically the task is to:

\begin{itemize}
\item
  Take a puzzle, theorem, claim
\item
  Declare and diagnose a design that shows the claim operating
  (e.g.~some estimator produces unbiased estimates under some condition)
\item
  Modify the design to show behavior when conditions are violated
\item
  Share a report with the class. Best in self-contained documents for
  easy third party viewing. e.g.~\texttt{.html} via \texttt{.qmd} or
  \texttt{.Rmd}
\end{itemize}

See example in \texttt{git}.
\end{frame}

\begin{frame}{Good coding rules}
\protect\hypertarget{good-coding-rules}{}
\begin{itemize}
\tightlist
\item
  \url{https://bookdown.org/content/d1e53ac9-28ce-472f-bc2c-f499f18264a3/code.html}
\item
  \url{https://www.r-bloggers.com/2018/09/r-code-best-practices/}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Good coding rules}
\protect\hypertarget{good-coding-rules-1}{}
\begin{itemize}
\tightlist
\item
  Metadata first
\item
  Call packages at the beginning: use \texttt{pacman}
\item
  Put options at the top
\item
  Call all data files once, at the top. Best to call directly from a
  public archive, when possible.\\
\item
  Use functions and define them at the top: comment them; useful
  sometimes to illustrate what they do
\item
  Replicate first, re-analyze second. Use sections.
\item
  Have subsections named after specific tables, figures or analyses
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Aim}
\protect\hypertarget{aim}{}
Nothing local, everything relative: so please do not include hardcoded
paths to your computer

\begin{itemize}
\item
  First best: if someone has access to your \texttt{.Rmd}/\texttt{.qmd}
  file they can hit render or compile and the whole thing reproduces
  first time.
\item
  But: often you need ancillary files for data and code. That's OK but
  aims should still be that with a self contained folder someone can
  open a \texttt{master.Rmd} file, hit compile and get everything. I
  usually have an \texttt{input} and an \texttt{output} subfolder.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Collaborative coding / writing}
\protect\hypertarget{collaborative-coding-writing}{}
\begin{itemize}
\tightlist
\item
  Do not get in the business of passing attachments around
\item
  Share self contained folders; folders contain a small set of live
  documents plus an archive. Old versions of documents are in archive.
  Only one version of the most recent document is in a main folder.
\item
  Data is self contained folder (\texttt{in}) and is never edited
  directly
\item
  Update to github frequently
\end{itemize}
\end{frame}

\hypertarget{declaredesign}{%
\section{\texorpdfstring{\texttt{DeclareDesign}}{DeclareDesign}}\label{declaredesign}}

\hypertarget{roadmap-1}{%
\subsection{Roadmap}\label{roadmap-1}}

\begin{frame}[fragile]{Roadmap}
\begin{enumerate}
\tightlist
\item
  The MIDA framework and the declaration-diagnosis-redesign cycle
\item
  \texttt{DeclareDesign}: key resources
\item
  The Declare-Diagnose-Redesign life cycle
\item
  Using designs
\item
  Hands-on declaration and diagnosis
\item
  An illustration of power
\item
  A deeper dive into declaration functionality
\item
  Topics and Exercises
\item
  Solutions
\end{enumerate}
\end{frame}

\hypertarget{the-mida-framework}{%
\subsection{The MIDA Framework}\label{the-mida-framework}}

\begin{frame}[fragile]{Four elements of any research design}
\protect\hypertarget{four-elements-of-any-research-design}{}
\begin{itemize}
\tightlist
\item
  \texttt{Model}: set of models of what causes what and how
\item
  \texttt{Inquiry}: a question stated in terms of the model
\item
  \texttt{Data\ strategy}: the set of procedures we use to gather
  information from the world (sampling, assignment, measurement)
\item
  \texttt{Answer\ strategy}: how we summarize the data produced by the
  data strategy
\end{itemize}
\end{frame}

\begin{frame}{Four elements of any research design}
\protect\hypertarget{four-elements-of-any-research-design-1}{}
\includegraphics[width=4.41in,height=\textheight]{assets/mida.png}
\end{frame}

\begin{frame}[fragile]{Declaration}
\protect\hypertarget{declaration}{}
Design declaration is telling the computer (and readers) what
\texttt{M}, \texttt{I}, \texttt{D}, and \texttt{A} are.
\end{frame}

\begin{frame}{Diagnosis}
\protect\hypertarget{diagnosis}{}
Design diagnosis is figuring out how the design will perform under
imagined conditions.

Estimating ``diagnosands'' like power, bias, rmse, error rates, ethical
harm, amount learned.

Diagnosis take account of model uncertainty: it seems to identify models
for which the design works well and models for which it does not
\end{frame}

\begin{frame}{Redesign}
\protect\hypertarget{redesign}{}
Redesign is the fine-tuning of features of the data and answer
strategies to understand how changing them affects the diagnosands

\begin{itemize}
\tightlist
\item
  Different sample sizes
\item
  Different randomization procedures
\item
  Different estimation strategies
\item
  Implementation: effort into compliance versus more effort into sample
  size
\end{itemize}
\end{frame}

\begin{frame}{Very often you have to simulate!}
\protect\hypertarget{very-often-you-have-to-simulate}{}
\begin{itemize}
\tightlist
\item
  Doing all this is often too hard to work out from rules of thumb or
  power calculators
\item
  Specialized formulas exist for some diagnosands, but not all
\end{itemize}
\end{frame}

\hypertarget{declaredesign-overview-of-key-functions-and-resources}{%
\subsection{DeclareDesign: Overview of key functions and
resources}\label{declaredesign-overview-of-key-functions-and-resources}}

\begin{frame}[fragile]{Key commands for making a design}
\protect\hypertarget{key-commands-for-making-a-design}{}
\begin{itemize}
\item
  \texttt{declare\_model()}
\item
  \texttt{declare\_inquiry()}
\item
  \texttt{declare\_sampling()}
\item
  \texttt{declare\_assignment()}
\item
  \texttt{declare\_measurement()}
\item
  \texttt{declare\_estimator()}
\end{itemize}

and there are more \texttt{declare\_} functions!
\end{frame}

\begin{frame}[fragile]{Key commands for using a design}
\protect\hypertarget{key-commands-for-using-a-design}{}
\begin{itemize}
\tightlist
\item
  \texttt{draw\_data(design)}
\item
  \texttt{draw\_estimands(design)}
\item
  \texttt{draw\_estimates(design)}
\item
  \texttt{get\_estimates(design,\ data)}
\item
  \texttt{run\_design(design)}, \texttt{simulate\_design(design)}
\item
  \texttt{diagnose\_design(design)}
\item
  \texttt{redesign(design,\ N\ =\ 200)}
\item
  \texttt{compare\_designs()}, \texttt{compare\_diagnoses()}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Pipeable commands}
\protect\hypertarget{pipeable-commands}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{redesign}\NormalTok{(}\AttributeTok{N =} \FunctionTok{c}\NormalTok{(}\DecValTok{200}\NormalTok{, }\DecValTok{400}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{diagnose\_designs}\NormalTok{() }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{(...) }
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Cheat sheet}
\protect\hypertarget{cheat-sheet}{}
\url{https://raw.githubusercontent.com/rstudio/cheatsheets/master/declaredesign.pdf}

\includegraphics[width=3.87in,height=\textheight]{assets/cheat_sheet.png}
\end{frame}

\begin{frame}[fragile]{Other resources}
\protect\hypertarget{other-resources}{}
\begin{itemize}
\tightlist
\item
  The website: https://declaredesign.org/
\item
  The book: https://book.declaredesign.org
\item
  The console: \texttt{?DeclareDesign}
\end{itemize}
\end{frame}

\hypertarget{design-declaration-diagnosis-redesign-workflow-design}{%
\subsection{Design declaration-diagnosis-redesign workflow:
Design}\label{design-declaration-diagnosis-redesign-workflow-design}}

\begin{frame}[fragile]{The simplest possible (diagnosable) design?}
\protect\hypertarget{the-simplest-possible-diagnosable-design}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mean }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{simplest\_design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{100}\NormalTok{, }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N, mean)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q =}\NormalTok{ mean) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  We draw 100 units from a standard normal distribution, we define our
  inquiry as the population expectation (0), we estimate the average
  using a regression with a constant term.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{The simplest possible design?}
\protect\hypertarget{the-simplest-possible-design}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simplest\_design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{100}\NormalTok{, }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  This design has three steps, with steps connected by a \texttt{+}
\item
  The design itself is just a list of steps and has class
  \texttt{design}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(simplest\_design)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
List of 3
 $ model    :design_step:    declare_model(N = 100, Y = rnorm(N)) 
 $ Q        :design_step:    declare_inquiry(Q = 0) 
 $ estimator:design_step:    declare_estimator(Y ~ 1) 
 - attr(*, "call")= language construct_design(steps = steps)
 - attr(*, "class")= chr [1:2] "design" "dd"
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{The simplest possible design? It's a pipe}
\protect\hypertarget{the-simplest-possible-design-its-a-pipe}{}
Each step is a function (or rather: a function that generates functions)
and each function presupposes what is created by previous functions.

\begin{itemize}
\tightlist
\item
  The ordering of steps is quite important
\item
  Most steps take the \texttt{main} data frame in and push the
  \texttt{main} dataframe out; this data frame normally builds up as you
  move along the pipe.
\item
  \texttt{declare\_estimator} steps take the \texttt{main} data frame in
  and send out an \texttt{estimator\_df} dataframe;
  \texttt{declare\_inquiry} steps take the \texttt{main} data frame in
  and send out an \texttt{estimand\_df} dataframe.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{The simplest possible design? It's a pipe}
\protect\hypertarget{the-simplest-possible-design-its-a-pipe-1}{}
\begin{itemize}
\tightlist
\item
  You can run these functions one at a time if you like.
\item
  For instance the third step presupposes the data from the first step:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ simplest\_design[[}\DecValTok{1}\NormalTok{]]()}
\NormalTok{A  }\OtherTok{\textless{}{-}}\NormalTok{ simplest\_design[[}\DecValTok{3}\NormalTok{]](df)}

\NormalTok{A }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|r|r|r|r|r|r|r|l}
\hline
estimator & term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
estimator & (Intercept) & -0.1 & 0.09 & -1.2 & 0.23 & -0.27 & 0.07 & 99 & Y\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Estimand  }\OtherTok{\textless{}{-}}\NormalTok{ simplest\_design[[}\DecValTok{2}\NormalTok{]](df)}

\NormalTok{Estimand }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r}
\hline
inquiry & estimand\\
\hline
Q & 0\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{The simplest possible design? Run it once}
\protect\hypertarget{the-simplest-possible-design-run-it-once}{}
You can also just run through the whole design once by typing the name
of the design:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simplest\_design}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Research design declaration summary

Step 1 (model): declare_model(N = 100, Y = rnorm(N)) ---------------------------

Step 2 (inquiry): declare_inquiry(Q = 0) ---------------------------------------

Step 3 (estimator): declare_estimator(Y ~ 1) -----------------------------------

Run of the design:

 inquiry estimand estimator        term estimate std.error statistic p.value
       Q        0 estimator (Intercept)  0.00249    0.0916    0.0272   0.978
 conf.low conf.high df outcome
   -0.179     0.184 99       Y
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{The simplest possible design? Run it again}
\protect\hypertarget{the-simplest-possible-design-run-it-again}{}
Or by asking for a run of the design

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{one\_run }\OtherTok{\textless{}{-}}\NormalTok{ simplest\_design }\SpecialCharTok{|\textgreater{}} \FunctionTok{run\_design}\NormalTok{()}
\NormalTok{one\_run }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|l|r|r|r|r|r|r|r|l}
\hline
inquiry & estimand & estimator & term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
Q & 0 & estimator & (Intercept) & 0 & 0.09 & -0.03 & 0.97 & -0.18 & 0.18 & 99 & Y\\
\hline
\end{tabular}

A single run creates data, calculates estimands (the answer to
inquiries) and calculates estimates plus ancillary statistics.
\end{frame}

\begin{frame}[fragile]{The simplest possible design?: Simulation}
\protect\hypertarget{the-simplest-possible-design-simulation}{}
Or by asking for a run of the design

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{some\_runs }\OtherTok{\textless{}{-}}\NormalTok{ simplest\_design }\SpecialCharTok{|\textgreater{}} \FunctionTok{simulate\_design}\NormalTok{(}\AttributeTok{sims =} \DecValTok{1000}\NormalTok{)}
\NormalTok{some\_runs }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|r|l|l|r|r|r|r|r|r|r|l}
\hline
design & sim\_ID & inquiry & estimand & estimator & term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
simplest\_design & 1 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.16 & 0.88 & -0.17 & 0.20 & 99 & Y\\
\hline
simplest\_design & 2 & Q & 0 & estimator & (Intercept) & 0.15 & 0.09 & 1.65 & 0.10 & -0.03 & 0.33 & 99 & Y\\
\hline
simplest\_design & 3 & Q & 0 & estimator & (Intercept) & -0.20 & 0.11 & -1.91 & 0.06 & -0.41 & 0.01 & 99 & Y\\
\hline
simplest\_design & 4 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.74 & 0.46 & -0.30 & 0.14 & 99 & Y\\
\hline
simplest\_design & 5 & Q & 0 & estimator & (Intercept) & -0.14 & 0.10 & -1.36 & 0.18 & -0.34 & 0.06 & 99 & Y\\
\hline
simplest\_design & 6 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.19 & 0.24 & -0.28 & 0.07 & 99 & Y\\
\hline
simplest\_design & 7 & Q & 0 & estimator & (Intercept) & 0.12 & 0.10 & 1.19 & 0.24 & -0.08 & 0.31 & 99 & Y\\
\hline
simplest\_design & 8 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.50 & 0.62 & -0.14 & 0.23 & 99 & Y\\
\hline
simplest\_design & 9 & Q & 0 & estimator & (Intercept) & -0.04 & 0.11 & -0.38 & 0.71 & -0.26 & 0.18 & 99 & Y\\
\hline
simplest\_design & 10 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.58 & 0.56 & -0.13 & 0.24 & 99 & Y\\
\hline
simplest\_design & 11 & Q & 0 & estimator & (Intercept) & -0.17 & 0.11 & -1.56 & 0.12 & -0.39 & 0.05 & 99 & Y\\
\hline
simplest\_design & 12 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.10 & 0.92 & -0.17 & 0.19 & 99 & Y\\
\hline
simplest\_design & 13 & Q & 0 & estimator & (Intercept) & 0.10 & 0.09 & 1.19 & 0.24 & -0.07 & 0.28 & 99 & Y\\
\hline
simplest\_design & 14 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & 0.04 & 0.97 & -0.19 & 0.20 & 99 & Y\\
\hline
simplest\_design & 15 & Q & 0 & estimator & (Intercept) & 0.11 & 0.09 & 1.18 & 0.24 & -0.08 & 0.30 & 99 & Y\\
\hline
simplest\_design & 16 & Q & 0 & estimator & (Intercept) & -0.10 & 0.12 & -0.85 & 0.40 & -0.33 & 0.13 & 99 & Y\\
\hline
simplest\_design & 17 & Q & 0 & estimator & (Intercept) & -0.21 & 0.10 & -2.08 & 0.04 & -0.41 & -0.01 & 99 & Y\\
\hline
simplest\_design & 18 & Q & 0 & estimator & (Intercept) & -0.05 & 0.11 & -0.42 & 0.68 & -0.26 & 0.17 & 99 & Y\\
\hline
simplest\_design & 19 & Q & 0 & estimator & (Intercept) & -0.09 & 0.11 & -0.82 & 0.42 & -0.31 & 0.13 & 99 & Y\\
\hline
simplest\_design & 20 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.20 & 0.84 & -0.23 & 0.19 & 99 & Y\\
\hline
simplest\_design & 21 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.37 & 0.71 & -0.16 & 0.23 & 99 & Y\\
\hline
simplest\_design & 22 & Q & 0 & estimator & (Intercept) & 0.11 & 0.09 & 1.12 & 0.26 & -0.08 & 0.29 & 99 & Y\\
\hline
simplest\_design & 23 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.04 & 0.97 & -0.20 & 0.20 & 99 & Y\\
\hline
simplest\_design & 24 & Q & 0 & estimator & (Intercept) & 0.09 & 0.11 & 0.84 & 0.40 & -0.12 & 0.30 & 99 & Y\\
\hline
simplest\_design & 25 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.02 & 0.98 & -0.21 & 0.21 & 99 & Y\\
\hline
simplest\_design & 26 & Q & 0 & estimator & (Intercept) & -0.08 & 0.09 & -0.79 & 0.43 & -0.26 & 0.11 & 99 & Y\\
\hline
simplest\_design & 27 & Q & 0 & estimator & (Intercept) & -0.11 & 0.10 & -1.13 & 0.26 & -0.30 & 0.08 & 99 & Y\\
\hline
simplest\_design & 28 & Q & 0 & estimator & (Intercept) & -0.06 & 0.11 & -0.59 & 0.56 & -0.28 & 0.15 & 99 & Y\\
\hline
simplest\_design & 29 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.73 & 0.47 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 30 & Q & 0 & estimator & (Intercept) & -0.13 & 0.09 & -1.41 & 0.16 & -0.31 & 0.05 & 99 & Y\\
\hline
simplest\_design & 31 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.88 & 0.38 & -0.27 & 0.11 & 99 & Y\\
\hline
simplest\_design & 32 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.25 & 0.80 & -0.18 & 0.23 & 99 & Y\\
\hline
simplest\_design & 33 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & 0.02 & 0.98 & -0.19 & 0.19 & 99 & Y\\
\hline
simplest\_design & 34 & Q & 0 & estimator & (Intercept) & 0.06 & 0.11 & 0.59 & 0.56 & -0.15 & 0.27 & 99 & Y\\
\hline
simplest\_design & 35 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.56 & 0.12 & -0.36 & 0.04 & 99 & Y\\
\hline
simplest\_design & 36 & Q & 0 & estimator & (Intercept) & 0.21 & 0.11 & 1.95 & 0.05 & 0.00 & 0.43 & 99 & Y\\
\hline
simplest\_design & 37 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.44 & 0.66 & -0.15 & 0.23 & 99 & Y\\
\hline
simplest\_design & 38 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.20 & 0.84 & -0.17 & 0.20 & 99 & Y\\
\hline
simplest\_design & 39 & Q & 0 & estimator & (Intercept) & -0.20 & 0.10 & -2.02 & 0.05 & -0.40 & 0.00 & 99 & Y\\
\hline
simplest\_design & 40 & Q & 0 & estimator & (Intercept) & 0.17 & 0.10 & 1.76 & 0.08 & -0.02 & 0.36 & 99 & Y\\
\hline
simplest\_design & 41 & Q & 0 & estimator & (Intercept) & -0.10 & 0.10 & -1.07 & 0.29 & -0.29 & 0.09 & 99 & Y\\
\hline
simplest\_design & 42 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.78 & 0.44 & -0.30 & 0.13 & 99 & Y\\
\hline
simplest\_design & 43 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.53 & 0.60 & -0.13 & 0.23 & 99 & Y\\
\hline
simplest\_design & 44 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 1.08 & 0.28 & -0.09 & 0.30 & 99 & Y\\
\hline
simplest\_design & 45 & Q & 0 & estimator & (Intercept) & -0.06 & 0.11 & -0.49 & 0.63 & -0.28 & 0.17 & 99 & Y\\
\hline
simplest\_design & 46 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.34 & 0.73 & -0.24 & 0.17 & 99 & Y\\
\hline
simplest\_design & 47 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & -0.04 & 0.97 & -0.19 & 0.18 & 99 & Y\\
\hline
simplest\_design & 48 & Q & 0 & estimator & (Intercept) & 0.12 & 0.09 & 1.27 & 0.21 & -0.07 & 0.31 & 99 & Y\\
\hline
simplest\_design & 49 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.35 & 0.73 & -0.24 & 0.17 & 99 & Y\\
\hline
simplest\_design & 50 & Q & 0 & estimator & (Intercept) & 0.11 & 0.09 & 1.21 & 0.23 & -0.07 & 0.30 & 99 & Y\\
\hline
simplest\_design & 51 & Q & 0 & estimator & (Intercept) & 0.13 & 0.11 & 1.17 & 0.24 & -0.09 & 0.34 & 99 & Y\\
\hline
simplest\_design & 52 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.13 & 0.90 & -0.21 & 0.19 & 99 & Y\\
\hline
simplest\_design & 53 & Q & 0 & estimator & (Intercept) & 0.16 & 0.10 & 1.69 & 0.09 & -0.03 & 0.35 & 99 & Y\\
\hline
simplest\_design & 54 & Q & 0 & estimator & (Intercept) & 0.14 & 0.10 & 1.47 & 0.14 & -0.05 & 0.33 & 99 & Y\\
\hline
simplest\_design & 55 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.57 & 0.12 & -0.37 & 0.04 & 99 & Y\\
\hline
simplest\_design & 56 & Q & 0 & estimator & (Intercept) & -0.09 & 0.09 & -1.07 & 0.29 & -0.27 & 0.08 & 99 & Y\\
\hline
simplest\_design & 57 & Q & 0 & estimator & (Intercept) & -0.05 & 0.11 & -0.48 & 0.63 & -0.26 & 0.16 & 99 & Y\\
\hline
simplest\_design & 58 & Q & 0 & estimator & (Intercept) & -0.10 & 0.11 & -0.94 & 0.35 & -0.32 & 0.11 & 99 & Y\\
\hline
simplest\_design & 59 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.58 & 0.56 & -0.24 & 0.13 & 99 & Y\\
\hline
simplest\_design & 60 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.83 & 0.41 & -0.28 & 0.11 & 99 & Y\\
\hline
simplest\_design & 61 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.59 & 0.11 & -0.36 & 0.04 & 99 & Y\\
\hline
simplest\_design & 62 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.09 & 0.28 & -0.09 & 0.31 & 99 & Y\\
\hline
simplest\_design & 63 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.75 & 0.46 & -0.12 & 0.26 & 99 & Y\\
\hline
simplest\_design & 64 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.09 & 0.93 & -0.17 & 0.19 & 99 & Y\\
\hline
simplest\_design & 65 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.17 & 0.87 & -0.16 & 0.19 & 99 & Y\\
\hline
simplest\_design & 66 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.45 & 0.65 & -0.15 & 0.23 & 99 & Y\\
\hline
simplest\_design & 67 & Q & 0 & estimator & (Intercept) & -0.09 & 0.09 & -0.99 & 0.32 & -0.26 & 0.09 & 99 & Y\\
\hline
simplest\_design & 68 & Q & 0 & estimator & (Intercept) & -0.03 & 0.09 & -0.35 & 0.73 & -0.21 & 0.15 & 99 & Y\\
\hline
simplest\_design & 69 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.17 & 0.25 & -0.27 & 0.07 & 99 & Y\\
\hline
simplest\_design & 70 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.34 & 0.73 & -0.17 & 0.24 & 99 & Y\\
\hline
simplest\_design & 71 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 0.99 & 0.32 & -0.10 & 0.31 & 99 & Y\\
\hline
simplest\_design & 72 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.21 & 0.84 & -0.19 & 0.23 & 99 & Y\\
\hline
simplest\_design & 73 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.05 & 0.96 & -0.20 & 0.19 & 99 & Y\\
\hline
simplest\_design & 74 & Q & 0 & estimator & (Intercept) & 0.01 & 0.11 & 0.05 & 0.96 & -0.22 & 0.23 & 99 & Y\\
\hline
simplest\_design & 75 & Q & 0 & estimator & (Intercept) & 0.06 & 0.11 & 0.50 & 0.61 & -0.17 & 0.28 & 99 & Y\\
\hline
simplest\_design & 76 & Q & 0 & estimator & (Intercept) & 0.12 & 0.09 & 1.26 & 0.21 & -0.07 & 0.30 & 99 & Y\\
\hline
simplest\_design & 77 & Q & 0 & estimator & (Intercept) & -0.25 & 0.11 & -2.30 & 0.02 & -0.47 & -0.04 & 99 & Y\\
\hline
simplest\_design & 78 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.13 & 0.89 & -0.16 & 0.19 & 99 & Y\\
\hline
simplest\_design & 79 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.74 & 0.46 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 80 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.60 & 0.55 & -0.13 & 0.24 & 99 & Y\\
\hline
simplest\_design & 81 & Q & 0 & estimator & (Intercept) & -0.03 & 0.12 & -0.22 & 0.83 & -0.26 & 0.21 & 99 & Y\\
\hline
simplest\_design & 82 & Q & 0 & estimator & (Intercept) & -0.05 & 0.09 & -0.59 & 0.56 & -0.23 & 0.12 & 99 & Y\\
\hline
simplest\_design & 83 & Q & 0 & estimator & (Intercept) & -0.17 & 0.10 & -1.60 & 0.11 & -0.37 & 0.04 & 99 & Y\\
\hline
simplest\_design & 84 & Q & 0 & estimator & (Intercept) & 0.13 & 0.10 & 1.34 & 0.18 & -0.06 & 0.32 & 99 & Y\\
\hline
simplest\_design & 85 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.32 & 0.19 & -0.32 & 0.06 & 99 & Y\\
\hline
simplest\_design & 86 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.86 & 0.39 & -0.28 & 0.11 & 99 & Y\\
\hline
simplest\_design & 87 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.43 & 0.67 & -0.25 & 0.16 & 99 & Y\\
\hline
simplest\_design & 88 & Q & 0 & estimator & (Intercept) & -0.12 & 0.11 & -1.06 & 0.29 & -0.33 & 0.10 & 99 & Y\\
\hline
simplest\_design & 89 & Q & 0 & estimator & (Intercept) & -0.18 & 0.10 & -1.79 & 0.08 & -0.39 & 0.02 & 99 & Y\\
\hline
simplest\_design & 90 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.03 & 0.98 & -0.20 & 0.20 & 99 & Y\\
\hline
simplest\_design & 91 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.11 & 0.91 & -0.17 & 0.19 & 99 & Y\\
\hline
simplest\_design & 92 & Q & 0 & estimator & (Intercept) & -0.18 & 0.10 & -1.82 & 0.07 & -0.39 & 0.02 & 99 & Y\\
\hline
simplest\_design & 93 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & 0.05 & 0.96 & -0.20 & 0.21 & 99 & Y\\
\hline
simplest\_design & 94 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.15 & 0.88 & -0.19 & 0.22 & 99 & Y\\
\hline
simplest\_design & 95 & Q & 0 & estimator & (Intercept) & 0.13 & 0.10 & 1.27 & 0.21 & -0.07 & 0.34 & 99 & Y\\
\hline
simplest\_design & 96 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.98 & 0.33 & -0.10 & 0.28 & 99 & Y\\
\hline
simplest\_design & 97 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.79 & 0.43 & -0.28 & 0.12 & 99 & Y\\
\hline
simplest\_design & 98 & Q & 0 & estimator & (Intercept) & 0.16 & 0.10 & 1.61 & 0.11 & -0.04 & 0.35 & 99 & Y\\
\hline
simplest\_design & 99 & Q & 0 & estimator & (Intercept) & 0.34 & 0.10 & 3.50 & 0.00 & 0.15 & 0.54 & 99 & Y\\
\hline
simplest\_design & 100 & Q & 0 & estimator & (Intercept) & 0.18 & 0.10 & 1.71 & 0.09 & -0.03 & 0.39 & 99 & Y\\
\hline
simplest\_design & 101 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.65 & 0.51 & -0.13 & 0.25 & 99 & Y\\
\hline
simplest\_design & 102 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.94 & 0.35 & -0.29 & 0.11 & 99 & Y\\
\hline
simplest\_design & 103 & Q & 0 & estimator & (Intercept) & -0.20 & 0.11 & -1.91 & 0.06 & -0.41 & 0.01 & 99 & Y\\
\hline
simplest\_design & 104 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.23 & 0.82 & -0.22 & 0.18 & 99 & Y\\
\hline
simplest\_design & 105 & Q & 0 & estimator & (Intercept) & -0.01 & 0.11 & -0.08 & 0.94 & -0.22 & 0.20 & 99 & Y\\
\hline
simplest\_design & 106 & Q & 0 & estimator & (Intercept) & 0.07 & 0.09 & 0.82 & 0.41 & -0.10 & 0.25 & 99 & Y\\
\hline
simplest\_design & 107 & Q & 0 & estimator & (Intercept) & -0.13 & 0.09 & -1.34 & 0.18 & -0.31 & 0.06 & 99 & Y\\
\hline
simplest\_design & 108 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.60 & 0.11 & -0.36 & 0.04 & 99 & Y\\
\hline
simplest\_design & 109 & Q & 0 & estimator & (Intercept) & 0.26 & 0.09 & 2.99 & 0.00 & 0.09 & 0.43 & 99 & Y\\
\hline
simplest\_design & 110 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 0.92 & 0.36 & -0.11 & 0.30 & 99 & Y\\
\hline
simplest\_design & 111 & Q & 0 & estimator & (Intercept) & -0.18 & 0.10 & -1.78 & 0.08 & -0.37 & 0.02 & 99 & Y\\
\hline
simplest\_design & 112 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.59 & 0.56 & -0.26 & 0.14 & 99 & Y\\
\hline
simplest\_design & 113 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.51 & 0.61 & -0.25 & 0.15 & 99 & Y\\
\hline
simplest\_design & 114 & Q & 0 & estimator & (Intercept) & 0.06 & 0.09 & 0.61 & 0.55 & -0.13 & 0.24 & 99 & Y\\
\hline
simplest\_design & 115 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.80 & 0.43 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 116 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.71 & 0.48 & -0.13 & 0.28 & 99 & Y\\
\hline
simplest\_design & 117 & Q & 0 & estimator & (Intercept) & -0.03 & 0.11 & -0.29 & 0.77 & -0.24 & 0.18 & 99 & Y\\
\hline
simplest\_design & 118 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.71 & 0.48 & -0.25 & 0.12 & 99 & Y\\
\hline
simplest\_design & 119 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.42 & 0.68 & -0.25 & 0.16 & 99 & Y\\
\hline
simplest\_design & 120 & Q & 0 & estimator & (Intercept) & -0.20 & 0.10 & -1.89 & 0.06 & -0.41 & 0.01 & 99 & Y\\
\hline
simplest\_design & 121 & Q & 0 & estimator & (Intercept) & 0.06 & 0.09 & 0.69 & 0.49 & -0.11 & 0.23 & 99 & Y\\
\hline
simplest\_design & 122 & Q & 0 & estimator & (Intercept) & 0.23 & 0.10 & 2.25 & 0.03 & 0.03 & 0.43 & 99 & Y\\
\hline
simplest\_design & 123 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.20 & 0.85 & -0.21 & 0.17 & 99 & Y\\
\hline
simplest\_design & 124 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.13 & 0.26 & -0.08 & 0.30 & 99 & Y\\
\hline
simplest\_design & 125 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.81 & 0.42 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 126 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.31 & 0.76 & -0.22 & 0.16 & 99 & Y\\
\hline
simplest\_design & 127 & Q & 0 & estimator & (Intercept) & 0.02 & 0.12 & 0.16 & 0.87 & -0.21 & 0.25 & 99 & Y\\
\hline
simplest\_design & 128 & Q & 0 & estimator & (Intercept) & 0.09 & 0.09 & 1.03 & 0.31 & -0.09 & 0.28 & 99 & Y\\
\hline
simplest\_design & 129 & Q & 0 & estimator & (Intercept) & 0.21 & 0.10 & 2.19 & 0.03 & 0.02 & 0.40 & 99 & Y\\
\hline
simplest\_design & 130 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.50 & 0.62 & -0.24 & 0.15 & 99 & Y\\
\hline
simplest\_design & 131 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.50 & 0.61 & -0.25 & 0.15 & 99 & Y\\
\hline
simplest\_design & 132 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.61 & 0.54 & -0.26 & 0.14 & 99 & Y\\
\hline
simplest\_design & 133 & Q & 0 & estimator & (Intercept) & -0.06 & 0.09 & -0.66 & 0.51 & -0.25 & 0.12 & 99 & Y\\
\hline
simplest\_design & 134 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.88 & 0.38 & -0.27 & 0.10 & 99 & Y\\
\hline
simplest\_design & 135 & Q & 0 & estimator & (Intercept) & -0.15 & 0.11 & -1.39 & 0.17 & -0.36 & 0.06 & 99 & Y\\
\hline
simplest\_design & 136 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.08 & 0.28 & -0.28 & 0.08 & 99 & Y\\
\hline
simplest\_design & 137 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.48 & 0.64 & -0.23 & 0.14 & 99 & Y\\
\hline
simplest\_design & 138 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.76 & 0.45 & -0.12 & 0.26 & 99 & Y\\
\hline
simplest\_design & 139 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.15 & 0.25 & -0.32 & 0.08 & 99 & Y\\
\hline
simplest\_design & 140 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.29 & 0.20 & -0.34 & 0.07 & 99 & Y\\
\hline
simplest\_design & 141 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.75 & 0.45 & -0.29 & 0.13 & 99 & Y\\
\hline
simplest\_design & 142 & Q & 0 & estimator & (Intercept) & -0.02 & 0.11 & -0.20 & 0.84 & -0.24 & 0.20 & 99 & Y\\
\hline
simplest\_design & 143 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.23 & 0.82 & -0.17 & 0.21 & 99 & Y\\
\hline
simplest\_design & 144 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.66 & 0.51 & -0.13 & 0.27 & 99 & Y\\
\hline
simplest\_design & 145 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.94 & 0.35 & -0.29 & 0.10 & 99 & Y\\
\hline
simplest\_design & 146 & Q & 0 & estimator & (Intercept) & -0.08 & 0.09 & -0.83 & 0.41 & -0.27 & 0.11 & 99 & Y\\
\hline
simplest\_design & 147 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.60 & 0.55 & -0.14 & 0.27 & 99 & Y\\
\hline
simplest\_design & 148 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.08 & 0.28 & -0.28 & 0.08 & 99 & Y\\
\hline
simplest\_design & 149 & Q & 0 & estimator & (Intercept) & 0.10 & 0.11 & 0.91 & 0.37 & -0.12 & 0.32 & 99 & Y\\
\hline
simplest\_design & 150 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.24 & 0.81 & -0.21 & 0.17 & 99 & Y\\
\hline
simplest\_design & 151 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.70 & 0.49 & -0.29 & 0.14 & 99 & Y\\
\hline
simplest\_design & 152 & Q & 0 & estimator & (Intercept) & 0.15 & 0.10 & 1.46 & 0.15 & -0.06 & 0.36 & 99 & Y\\
\hline
simplest\_design & 153 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.23 & 0.22 & -0.32 & 0.08 & 99 & Y\\
\hline
simplest\_design & 154 & Q & 0 & estimator & (Intercept) & 0.06 & 0.09 & 0.69 & 0.49 & -0.12 & 0.24 & 99 & Y\\
\hline
simplest\_design & 155 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.63 & 0.53 & -0.14 & 0.26 & 99 & Y\\
\hline
simplest\_design & 156 & Q & 0 & estimator & (Intercept) & -0.08 & 0.09 & -0.96 & 0.34 & -0.26 & 0.09 & 99 & Y\\
\hline
simplest\_design & 157 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.70 & 0.49 & -0.13 & 0.28 & 99 & Y\\
\hline
simplest\_design & 158 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.21 & 0.83 & -0.20 & 0.25 & 99 & Y\\
\hline
simplest\_design & 159 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.33 & 0.74 & -0.17 & 0.24 & 99 & Y\\
\hline
simplest\_design & 160 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.25 & 0.80 & -0.17 & 0.22 & 99 & Y\\
\hline
simplest\_design & 161 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.34 & 0.73 & -0.17 & 0.24 & 99 & Y\\
\hline
simplest\_design & 162 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.48 & 0.63 & -0.25 & 0.15 & 99 & Y\\
\hline
simplest\_design & 163 & Q & 0 & estimator & (Intercept) & 0.05 & 0.11 & 0.47 & 0.64 & -0.16 & 0.26 & 99 & Y\\
\hline
simplest\_design & 164 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.30 & 0.76 & -0.17 & 0.23 & 99 & Y\\
\hline
simplest\_design & 165 & Q & 0 & estimator & (Intercept) & 0.05 & 0.11 & 0.46 & 0.65 & -0.16 & 0.26 & 99 & Y\\
\hline
simplest\_design & 166 & Q & 0 & estimator & (Intercept) & -0.11 & 0.09 & -1.27 & 0.21 & -0.29 & 0.06 & 99 & Y\\
\hline
simplest\_design & 167 & Q & 0 & estimator & (Intercept) & -0.07 & 0.11 & -0.67 & 0.51 & -0.29 & 0.14 & 99 & Y\\
\hline
simplest\_design & 168 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.15 & 0.88 & -0.20 & 0.17 & 99 & Y\\
\hline
simplest\_design & 169 & Q & 0 & estimator & (Intercept) & -0.08 & 0.09 & -0.84 & 0.40 & -0.26 & 0.10 & 99 & Y\\
\hline
simplest\_design & 170 & Q & 0 & estimator & (Intercept) & -0.01 & 0.11 & -0.05 & 0.96 & -0.23 & 0.21 & 99 & Y\\
\hline
simplest\_design & 171 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.46 & 0.64 & -0.15 & 0.23 & 99 & Y\\
\hline
simplest\_design & 172 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.84 & 0.41 & -0.29 & 0.12 & 99 & Y\\
\hline
simplest\_design & 173 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.41 & 0.68 & -0.15 & 0.23 & 99 & Y\\
\hline
simplest\_design & 174 & Q & 0 & estimator & (Intercept) & 0.14 & 0.11 & 1.32 & 0.19 & -0.07 & 0.36 & 99 & Y\\
\hline
simplest\_design & 175 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.73 & 0.47 & -0.26 & 0.12 & 99 & Y\\
\hline
simplest\_design & 176 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.22 & 0.83 & -0.21 & 0.17 & 99 & Y\\
\hline
simplest\_design & 177 & Q & 0 & estimator & (Intercept) & -0.20 & 0.10 & -2.01 & 0.05 & -0.40 & 0.00 & 99 & Y\\
\hline
simplest\_design & 178 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.55 & 0.59 & -0.25 & 0.14 & 99 & Y\\
\hline
simplest\_design & 179 & Q & 0 & estimator & (Intercept) & -0.16 & 0.11 & -1.36 & 0.18 & -0.38 & 0.07 & 99 & Y\\
\hline
simplest\_design & 180 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.09 & 0.93 & -0.16 & 0.18 & 99 & Y\\
\hline
simplest\_design & 181 & Q & 0 & estimator & (Intercept) & 0.15 & 0.11 & 1.39 & 0.17 & -0.06 & 0.36 & 99 & Y\\
\hline
simplest\_design & 182 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.40 & 0.69 & -0.16 & 0.24 & 99 & Y\\
\hline
simplest\_design & 183 & Q & 0 & estimator & (Intercept) & -0.10 & 0.11 & -0.94 & 0.35 & -0.31 & 0.11 & 99 & Y\\
\hline
simplest\_design & 184 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.19 & 0.85 & -0.17 & 0.20 & 99 & Y\\
\hline
simplest\_design & 185 & Q & 0 & estimator & (Intercept) & 0.06 & 0.11 & 0.57 & 0.57 & -0.16 & 0.29 & 99 & Y\\
\hline
simplest\_design & 186 & Q & 0 & estimator & (Intercept) & 0.18 & 0.09 & 2.09 & 0.04 & 0.01 & 0.35 & 99 & Y\\
\hline
simplest\_design & 187 & Q & 0 & estimator & (Intercept) & -0.15 & 0.10 & -1.47 & 0.15 & -0.35 & 0.05 & 99 & Y\\
\hline
simplest\_design & 188 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.52 & 0.60 & -0.26 & 0.15 & 99 & Y\\
\hline
simplest\_design & 189 & Q & 0 & estimator & (Intercept) & 0.13 & 0.09 & 1.41 & 0.16 & -0.05 & 0.31 & 99 & Y\\
\hline
simplest\_design & 190 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.87 & 0.39 & -0.29 & 0.12 & 99 & Y\\
\hline
simplest\_design & 191 & Q & 0 & estimator & (Intercept) & 0.08 & 0.11 & 0.72 & 0.48 & -0.14 & 0.30 & 99 & Y\\
\hline
simplest\_design & 192 & Q & 0 & estimator & (Intercept) & 0.08 & 0.09 & 0.82 & 0.42 & -0.11 & 0.26 & 99 & Y\\
\hline
simplest\_design & 193 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.14 & 0.89 & -0.18 & 0.20 & 99 & Y\\
\hline
simplest\_design & 194 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.06 & 0.29 & -0.09 & 0.31 & 99 & Y\\
\hline
simplest\_design & 195 & Q & 0 & estimator & (Intercept) & 0.06 & 0.11 & 0.55 & 0.58 & -0.15 & 0.27 & 99 & Y\\
\hline
simplest\_design & 196 & Q & 0 & estimator & (Intercept) & 0.12 & 0.10 & 1.21 & 0.23 & -0.08 & 0.32 & 99 & Y\\
\hline
simplest\_design & 197 & Q & 0 & estimator & (Intercept) & -0.05 & 0.11 & -0.49 & 0.63 & -0.27 & 0.16 & 99 & Y\\
\hline
simplest\_design & 198 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.15 & 0.88 & -0.20 & 0.23 & 99 & Y\\
\hline
simplest\_design & 199 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.73 & 0.47 & -0.25 & 0.11 & 99 & Y\\
\hline
simplest\_design & 200 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.14 & 0.89 & -0.16 & 0.19 & 99 & Y\\
\hline
simplest\_design & 201 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.67 & 0.51 & -0.13 & 0.26 & 99 & Y\\
\hline
simplest\_design & 202 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.77 & 0.44 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 203 & Q & 0 & estimator & (Intercept) & 0.12 & 0.11 & 1.16 & 0.25 & -0.09 & 0.34 & 99 & Y\\
\hline
simplest\_design & 204 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.18 & 0.86 & -0.18 & 0.22 & 99 & Y\\
\hline
simplest\_design & 205 & Q & 0 & estimator & (Intercept) & -0.18 & 0.10 & -1.70 & 0.09 & -0.39 & 0.03 & 99 & Y\\
\hline
simplest\_design & 206 & Q & 0 & estimator & (Intercept) & -0.13 & 0.11 & -1.24 & 0.22 & -0.35 & 0.08 & 99 & Y\\
\hline
simplest\_design & 207 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.62 & 0.53 & -0.25 & 0.13 & 99 & Y\\
\hline
simplest\_design & 208 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & 0.01 & 0.99 & -0.19 & 0.19 & 99 & Y\\
\hline
simplest\_design & 209 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.05 & 0.96 & -0.21 & 0.20 & 99 & Y\\
\hline
simplest\_design & 210 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.17 & 0.87 & -0.21 & 0.18 & 99 & Y\\
\hline
simplest\_design & 211 & Q & 0 & estimator & (Intercept) & -0.08 & 0.09 & -0.89 & 0.37 & -0.27 & 0.10 & 99 & Y\\
\hline
simplest\_design & 212 & Q & 0 & estimator & (Intercept) & -0.17 & 0.09 & -1.77 & 0.08 & -0.35 & 0.02 & 99 & Y\\
\hline
simplest\_design & 213 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.12 & 0.26 & -0.29 & 0.08 & 99 & Y\\
\hline
simplest\_design & 214 & Q & 0 & estimator & (Intercept) & 0.16 & 0.11 & 1.52 & 0.13 & -0.05 & 0.37 & 99 & Y\\
\hline
simplest\_design & 215 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.68 & 0.50 & -0.13 & 0.26 & 99 & Y\\
\hline
simplest\_design & 216 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.20 & 0.84 & -0.21 & 0.17 & 99 & Y\\
\hline
simplest\_design & 217 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.89 & 0.38 & -0.28 & 0.11 & 99 & Y\\
\hline
simplest\_design & 218 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.27 & 0.21 & -0.34 & 0.07 & 99 & Y\\
\hline
simplest\_design & 219 & Q & 0 & estimator & (Intercept) & -0.06 & 0.12 & -0.56 & 0.58 & -0.29 & 0.16 & 99 & Y\\
\hline
simplest\_design & 220 & Q & 0 & estimator & (Intercept) & -0.05 & 0.09 & -0.53 & 0.59 & -0.23 & 0.13 & 99 & Y\\
\hline
simplest\_design & 221 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.49 & 0.62 & -0.14 & 0.24 & 99 & Y\\
\hline
simplest\_design & 222 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.08 & 0.94 & -0.18 & 0.20 & 99 & Y\\
\hline
simplest\_design & 223 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.45 & 0.65 & -0.23 & 0.15 & 99 & Y\\
\hline
simplest\_design & 224 & Q & 0 & estimator & (Intercept) & 0.09 & 0.09 & 0.91 & 0.37 & -0.10 & 0.27 & 99 & Y\\
\hline
simplest\_design & 225 & Q & 0 & estimator & (Intercept) & 0.14 & 0.11 & 1.26 & 0.21 & -0.08 & 0.36 & 99 & Y\\
\hline
simplest\_design & 226 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.79 & 0.43 & -0.26 & 0.11 & 99 & Y\\
\hline
simplest\_design & 227 & Q & 0 & estimator & (Intercept) & -0.18 & 0.09 & -1.94 & 0.06 & -0.37 & 0.00 & 99 & Y\\
\hline
simplest\_design & 228 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.73 & 0.47 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 229 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.68 & 0.50 & -0.13 & 0.26 & 99 & Y\\
\hline
simplest\_design & 230 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.16 & 0.87 & -0.22 & 0.19 & 99 & Y\\
\hline
simplest\_design & 231 & Q & 0 & estimator & (Intercept) & -0.19 & 0.10 & -1.92 & 0.06 & -0.38 & 0.01 & 99 & Y\\
\hline
simplest\_design & 232 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.08 & 0.94 & -0.21 & 0.19 & 99 & Y\\
\hline
simplest\_design & 233 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.14 & 0.89 & -0.18 & 0.20 & 99 & Y\\
\hline
simplest\_design & 234 & Q & 0 & estimator & (Intercept) & 0.08 & 0.11 & 0.75 & 0.45 & -0.13 & 0.30 & 99 & Y\\
\hline
simplest\_design & 235 & Q & 0 & estimator & (Intercept) & -0.11 & 0.11 & -1.03 & 0.30 & -0.32 & 0.10 & 99 & Y\\
\hline
simplest\_design & 236 & Q & 0 & estimator & (Intercept) & 0.01 & 0.11 & 0.05 & 0.96 & -0.21 & 0.22 & 99 & Y\\
\hline
simplest\_design & 237 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 0.96 & 0.34 & -0.10 & 0.29 & 99 & Y\\
\hline
simplest\_design & 238 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.21 & 0.84 & -0.17 & 0.21 & 99 & Y\\
\hline
simplest\_design & 239 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.67 & 0.50 & -0.13 & 0.26 & 99 & Y\\
\hline
simplest\_design & 240 & Q & 0 & estimator & (Intercept) & -0.04 & 0.11 & -0.37 & 0.71 & -0.25 & 0.17 & 99 & Y\\
\hline
simplest\_design & 241 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.23 & 0.82 & -0.21 & 0.17 & 99 & Y\\
\hline
simplest\_design & 242 & Q & 0 & estimator & (Intercept) & 0.14 & 0.09 & 1.51 & 0.14 & -0.04 & 0.32 & 99 & Y\\
\hline
simplest\_design & 243 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.77 & 0.45 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 244 & Q & 0 & estimator & (Intercept) & 0.17 & 0.10 & 1.68 & 0.10 & -0.03 & 0.37 & 99 & Y\\
\hline
simplest\_design & 245 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.31 & 0.76 & -0.17 & 0.23 & 99 & Y\\
\hline
simplest\_design & 246 & Q & 0 & estimator & (Intercept) & 0.13 & 0.10 & 1.27 & 0.21 & -0.07 & 0.32 & 99 & Y\\
\hline
simplest\_design & 247 & Q & 0 & estimator & (Intercept) & -0.21 & 0.10 & -2.02 & 0.05 & -0.42 & 0.00 & 99 & Y\\
\hline
simplest\_design & 248 & Q & 0 & estimator & (Intercept) & -0.17 & 0.10 & -1.75 & 0.08 & -0.37 & 0.02 & 99 & Y\\
\hline
simplest\_design & 249 & Q & 0 & estimator & (Intercept) & -0.08 & 0.12 & -0.63 & 0.53 & -0.32 & 0.17 & 99 & Y\\
\hline
simplest\_design & 250 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.33 & 0.19 & -0.32 & 0.06 & 99 & Y\\
\hline
simplest\_design & 251 & Q & 0 & estimator & (Intercept) & -0.16 & 0.09 & -1.73 & 0.09 & -0.35 & 0.02 & 99 & Y\\
\hline
simplest\_design & 252 & Q & 0 & estimator & (Intercept) & -0.14 & 0.09 & -1.45 & 0.15 & -0.32 & 0.05 & 99 & Y\\
\hline
simplest\_design & 253 & Q & 0 & estimator & (Intercept) & 0.01 & 0.11 & 0.13 & 0.89 & -0.20 & 0.23 & 99 & Y\\
\hline
simplest\_design & 254 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.06 & 0.95 & -0.20 & 0.21 & 99 & Y\\
\hline
simplest\_design & 255 & Q & 0 & estimator & (Intercept) & 0.05 & 0.11 & 0.42 & 0.67 & -0.17 & 0.26 & 99 & Y\\
\hline
simplest\_design & 256 & Q & 0 & estimator & (Intercept) & 0.08 & 0.09 & 0.89 & 0.37 & -0.10 & 0.27 & 99 & Y\\
\hline
simplest\_design & 257 & Q & 0 & estimator & (Intercept) & -0.15 & 0.10 & -1.48 & 0.14 & -0.36 & 0.05 & 99 & Y\\
\hline
simplest\_design & 258 & Q & 0 & estimator & (Intercept) & -0.04 & 0.12 & -0.38 & 0.71 & -0.28 & 0.19 & 99 & Y\\
\hline
simplest\_design & 259 & Q & 0 & estimator & (Intercept) & -0.04 & 0.11 & -0.41 & 0.68 & -0.25 & 0.17 & 99 & Y\\
\hline
simplest\_design & 260 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.10 & 0.92 & -0.19 & 0.21 & 99 & Y\\
\hline
simplest\_design & 261 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.47 & 0.64 & -0.15 & 0.25 & 99 & Y\\
\hline
simplest\_design & 262 & Q & 0 & estimator & (Intercept) & 0.07 & 0.09 & 0.85 & 0.40 & -0.10 & 0.24 & 99 & Y\\
\hline
simplest\_design & 263 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.23 & 0.22 & -0.27 & 0.06 & 99 & Y\\
\hline
simplest\_design & 264 & Q & 0 & estimator & (Intercept) & -0.13 & 0.11 & -1.15 & 0.25 & -0.34 & 0.09 & 99 & Y\\
\hline
simplest\_design & 265 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.10 & 0.92 & -0.18 & 0.20 & 99 & Y\\
\hline
simplest\_design & 266 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.07 & 0.94 & -0.21 & 0.19 & 99 & Y\\
\hline
simplest\_design & 267 & Q & 0 & estimator & (Intercept) & 0.06 & 0.08 & 0.74 & 0.46 & -0.10 & 0.22 & 99 & Y\\
\hline
simplest\_design & 268 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.74 & 0.46 & -0.13 & 0.28 & 99 & Y\\
\hline
simplest\_design & 269 & Q & 0 & estimator & (Intercept) & 0.09 & 0.11 & 0.81 & 0.42 & -0.13 & 0.31 & 99 & Y\\
\hline
simplest\_design & 270 & Q & 0 & estimator & (Intercept) & 0.01 & 0.11 & 0.13 & 0.90 & -0.20 & 0.22 & 99 & Y\\
\hline
simplest\_design & 271 & Q & 0 & estimator & (Intercept) & 0.01 & 0.11 & 0.10 & 0.92 & -0.20 & 0.22 & 99 & Y\\
\hline
simplest\_design & 272 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.28 & 0.20 & -0.32 & 0.07 & 99 & Y\\
\hline
simplest\_design & 273 & Q & 0 & estimator & (Intercept) & 0.07 & 0.08 & 0.94 & 0.35 & -0.08 & 0.23 & 99 & Y\\
\hline
simplest\_design & 274 & Q & 0 & estimator & (Intercept) & 0.07 & 0.11 & 0.68 & 0.50 & -0.14 & 0.28 & 99 & Y\\
\hline
simplest\_design & 275 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.86 & 0.39 & -0.11 & 0.28 & 99 & Y\\
\hline
simplest\_design & 276 & Q & 0 & estimator & (Intercept) & 0.12 & 0.10 & 1.18 & 0.24 & -0.08 & 0.33 & 99 & Y\\
\hline
simplest\_design & 277 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.20 & 0.85 & -0.20 & 0.17 & 99 & Y\\
\hline
simplest\_design & 278 & Q & 0 & estimator & (Intercept) & -0.14 & 0.09 & -1.44 & 0.15 & -0.32 & 0.05 & 99 & Y\\
\hline
simplest\_design & 279 & Q & 0 & estimator & (Intercept) & 0.09 & 0.09 & 0.98 & 0.33 & -0.09 & 0.27 & 99 & Y\\
\hline
simplest\_design & 280 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.59 & 0.56 & -0.14 & 0.26 & 99 & Y\\
\hline
simplest\_design & 281 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.25 & 0.81 & -0.20 & 0.16 & 99 & Y\\
\hline
simplest\_design & 282 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.22 & 0.83 & -0.18 & 0.22 & 99 & Y\\
\hline
simplest\_design & 283 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & 0.02 & 0.99 & -0.19 & 0.19 & 99 & Y\\
\hline
simplest\_design & 284 & Q & 0 & estimator & (Intercept) & -0.03 & 0.09 & -0.34 & 0.74 & -0.22 & 0.15 & 99 & Y\\
\hline
simplest\_design & 285 & Q & 0 & estimator & (Intercept) & 0.20 & 0.09 & 2.17 & 0.03 & 0.02 & 0.38 & 99 & Y\\
\hline
simplest\_design & 286 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.66 & 0.51 & -0.27 & 0.14 & 99 & Y\\
\hline
simplest\_design & 287 & Q & 0 & estimator & (Intercept) & 0.07 & 0.09 & 0.74 & 0.46 & -0.11 & 0.25 & 99 & Y\\
\hline
simplest\_design & 288 & Q & 0 & estimator & (Intercept) & 0.06 & 0.09 & 0.63 & 0.53 & -0.13 & 0.24 & 99 & Y\\
\hline
simplest\_design & 289 & Q & 0 & estimator & (Intercept) & 0.12 & 0.10 & 1.20 & 0.23 & -0.08 & 0.31 & 99 & Y\\
\hline
simplest\_design & 290 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.46 & 0.65 & -0.21 & 0.13 & 99 & Y\\
\hline
simplest\_design & 291 & Q & 0 & estimator & (Intercept) & -0.18 & 0.10 & -1.91 & 0.06 & -0.37 & 0.01 & 99 & Y\\
\hline
simplest\_design & 292 & Q & 0 & estimator & (Intercept) & -0.02 & 0.11 & -0.16 & 0.87 & -0.23 & 0.20 & 99 & Y\\
\hline
simplest\_design & 293 & Q & 0 & estimator & (Intercept) & 0.05 & 0.11 & 0.48 & 0.63 & -0.16 & 0.27 & 99 & Y\\
\hline
simplest\_design & 294 & Q & 0 & estimator & (Intercept) & 0.19 & 0.11 & 1.72 & 0.09 & -0.03 & 0.40 & 99 & Y\\
\hline
simplest\_design & 295 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.55 & 0.59 & -0.13 & 0.23 & 99 & Y\\
\hline
simplest\_design & 296 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.39 & 0.70 & -0.24 & 0.16 & 99 & Y\\
\hline
simplest\_design & 297 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.98 & 0.33 & -0.28 & 0.10 & 99 & Y\\
\hline
simplest\_design & 298 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.47 & 0.64 & -0.25 & 0.15 & 99 & Y\\
\hline
simplest\_design & 299 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.97 & 0.34 & -0.10 & 0.29 & 99 & Y\\
\hline
simplest\_design & 300 & Q & 0 & estimator & (Intercept) & -0.24 & 0.09 & -2.66 & 0.01 & -0.42 & -0.06 & 99 & Y\\
\hline
simplest\_design & 301 & Q & 0 & estimator & (Intercept) & -0.25 & 0.10 & -2.50 & 0.01 & -0.44 & -0.05 & 99 & Y\\
\hline
simplest\_design & 302 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.04 & 0.97 & -0.19 & 0.18 & 99 & Y\\
\hline
simplest\_design & 303 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.44 & 0.66 & -0.25 & 0.16 & 99 & Y\\
\hline
simplest\_design & 304 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.74 & 0.46 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 305 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.25 & 0.81 & -0.15 & 0.20 & 99 & Y\\
\hline
simplest\_design & 306 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.54 & 0.59 & -0.14 & 0.25 & 99 & Y\\
\hline
simplest\_design & 307 & Q & 0 & estimator & (Intercept) & -0.17 & 0.10 & -1.83 & 0.07 & -0.36 & 0.02 & 99 & Y\\
\hline
simplest\_design & 308 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.11 & 0.91 & -0.19 & 0.22 & 99 & Y\\
\hline
simplest\_design & 309 & Q & 0 & estimator & (Intercept) & -0.11 & 0.10 & -1.06 & 0.29 & -0.30 & 0.09 & 99 & Y\\
\hline
simplest\_design & 310 & Q & 0 & estimator & (Intercept) & 0.15 & 0.10 & 1.50 & 0.14 & -0.05 & 0.35 & 99 & Y\\
\hline
simplest\_design & 311 & Q & 0 & estimator & (Intercept) & 0.15 & 0.09 & 1.68 & 0.10 & -0.03 & 0.34 & 99 & Y\\
\hline
simplest\_design & 312 & Q & 0 & estimator & (Intercept) & 0.11 & 0.09 & 1.17 & 0.24 & -0.08 & 0.30 & 99 & Y\\
\hline
simplest\_design & 313 & Q & 0 & estimator & (Intercept) & 0.17 & 0.10 & 1.73 & 0.09 & -0.02 & 0.37 & 99 & Y\\
\hline
simplest\_design & 314 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.91 & 0.37 & -0.11 & 0.28 & 99 & Y\\
\hline
simplest\_design & 315 & Q & 0 & estimator & (Intercept) & -0.30 & 0.09 & -3.21 & 0.00 & -0.49 & -0.12 & 99 & Y\\
\hline
simplest\_design & 316 & Q & 0 & estimator & (Intercept) & -0.14 & 0.11 & -1.29 & 0.20 & -0.36 & 0.08 & 99 & Y\\
\hline
simplest\_design & 317 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.34 & 0.18 & -0.33 & 0.06 & 99 & Y\\
\hline
simplest\_design & 318 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.75 & 0.46 & -0.24 & 0.11 & 99 & Y\\
\hline
simplest\_design & 319 & Q & 0 & estimator & (Intercept) & 0.18 & 0.10 & 1.86 & 0.07 & -0.01 & 0.38 & 99 & Y\\
\hline
simplest\_design & 320 & Q & 0 & estimator & (Intercept) & 0.11 & 0.11 & 1.04 & 0.30 & -0.10 & 0.33 & 99 & Y\\
\hline
simplest\_design & 321 & Q & 0 & estimator & (Intercept) & 0.04 & 0.09 & 0.44 & 0.66 & -0.14 & 0.23 & 99 & Y\\
\hline
simplest\_design & 322 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.12 & 0.90 & -0.22 & 0.19 & 99 & Y\\
\hline
simplest\_design & 323 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.74 & 0.46 & -0.12 & 0.26 & 99 & Y\\
\hline
simplest\_design & 324 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.16 & 0.87 & -0.19 & 0.22 & 99 & Y\\
\hline
simplest\_design & 325 & Q & 0 & estimator & (Intercept) & 0.12 & 0.10 & 1.22 & 0.23 & -0.08 & 0.32 & 99 & Y\\
\hline
simplest\_design & 326 & Q & 0 & estimator & (Intercept) & -0.03 & 0.11 & -0.25 & 0.81 & -0.24 & 0.18 & 99 & Y\\
\hline
simplest\_design & 327 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.12 & 0.90 & -0.19 & 0.17 & 99 & Y\\
\hline
simplest\_design & 328 & Q & 0 & estimator & (Intercept) & 0.05 & 0.11 & 0.49 & 0.62 & -0.16 & 0.27 & 99 & Y\\
\hline
simplest\_design & 329 & Q & 0 & estimator & (Intercept) & -0.03 & 0.11 & -0.28 & 0.78 & -0.25 & 0.19 & 99 & Y\\
\hline
simplest\_design & 330 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.07 & 0.95 & -0.18 & 0.17 & 99 & Y\\
\hline
simplest\_design & 331 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.07 & 0.95 & -0.22 & 0.20 & 99 & Y\\
\hline
simplest\_design & 332 & Q & 0 & estimator & (Intercept) & 0.09 & 0.11 & 0.83 & 0.41 & -0.12 & 0.30 & 99 & Y\\
\hline
simplest\_design & 333 & Q & 0 & estimator & (Intercept) & 0.17 & 0.10 & 1.70 & 0.09 & -0.03 & 0.38 & 99 & Y\\
\hline
simplest\_design & 334 & Q & 0 & estimator & (Intercept) & 0.01 & 0.11 & 0.09 & 0.93 & -0.21 & 0.23 & 99 & Y\\
\hline
simplest\_design & 335 & Q & 0 & estimator & (Intercept) & -0.03 & 0.09 & -0.29 & 0.77 & -0.21 & 0.15 & 99 & Y\\
\hline
simplest\_design & 336 & Q & 0 & estimator & (Intercept) & 0.04 & 0.11 & 0.40 & 0.69 & -0.17 & 0.26 & 99 & Y\\
\hline
simplest\_design & 337 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.10 & 0.92 & -0.18 & 0.17 & 99 & Y\\
\hline
simplest\_design & 338 & Q & 0 & estimator & (Intercept) & 0.08 & 0.11 & 0.74 & 0.46 & -0.14 & 0.30 & 99 & Y\\
\hline
simplest\_design & 339 & Q & 0 & estimator & (Intercept) & -0.23 & 0.10 & -2.25 & 0.03 & -0.44 & -0.03 & 99 & Y\\
\hline
simplest\_design & 340 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.76 & 0.45 & -0.12 & 0.28 & 99 & Y\\
\hline
simplest\_design & 341 & Q & 0 & estimator & (Intercept) & 0.07 & 0.09 & 0.79 & 0.43 & -0.11 & 0.25 & 99 & Y\\
\hline
simplest\_design & 342 & Q & 0 & estimator & (Intercept) & -0.11 & 0.08 & -1.36 & 0.18 & -0.28 & 0.05 & 99 & Y\\
\hline
simplest\_design & 343 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.44 & 0.66 & -0.24 & 0.15 & 99 & Y\\
\hline
simplest\_design & 344 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.79 & 0.43 & -0.28 & 0.12 & 99 & Y\\
\hline
simplest\_design & 345 & Q & 0 & estimator & (Intercept) & 0.23 & 0.12 & 1.95 & 0.05 & 0.00 & 0.47 & 99 & Y\\
\hline
simplest\_design & 346 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.06 & 0.95 & -0.18 & 0.20 & 99 & Y\\
\hline
simplest\_design & 347 & Q & 0 & estimator & (Intercept) & -0.10 & 0.10 & -0.97 & 0.33 & -0.31 & 0.10 & 99 & Y\\
\hline
simplest\_design & 348 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & 0.04 & 0.97 & -0.18 & 0.19 & 99 & Y\\
\hline
simplest\_design & 349 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.16 & 0.87 & -0.20 & 0.17 & 99 & Y\\
\hline
simplest\_design & 350 & Q & 0 & estimator & (Intercept) & 0.22 & 0.09 & 2.35 & 0.02 & 0.03 & 0.41 & 99 & Y\\
\hline
simplest\_design & 351 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.68 & 0.50 & -0.13 & 0.27 & 99 & Y\\
\hline
simplest\_design & 352 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.28 & 0.78 & -0.18 & 0.23 & 99 & Y\\
\hline
simplest\_design & 353 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.52 & 0.60 & -0.15 & 0.26 & 99 & Y\\
\hline
simplest\_design & 354 & Q & 0 & estimator & (Intercept) & -0.06 & 0.09 & -0.61 & 0.54 & -0.24 & 0.13 & 99 & Y\\
\hline
simplest\_design & 355 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.70 & 0.49 & -0.27 & 0.13 & 99 & Y\\
\hline
simplest\_design & 356 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.68 & 0.50 & -0.27 & 0.13 & 99 & Y\\
\hline
simplest\_design & 357 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.16 & 0.25 & -0.08 & 0.30 & 99 & Y\\
\hline
simplest\_design & 358 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.54 & 0.59 & -0.14 & 0.24 & 99 & Y\\
\hline
simplest\_design & 359 & Q & 0 & estimator & (Intercept) & 0.23 & 0.10 & 2.28 & 0.02 & 0.03 & 0.43 & 99 & Y\\
\hline
simplest\_design & 360 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.21 & 0.84 & -0.19 & 0.24 & 99 & Y\\
\hline
simplest\_design & 361 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.30 & 0.77 & -0.24 & 0.18 & 99 & Y\\
\hline
simplest\_design & 362 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.15 & 0.88 & -0.22 & 0.19 & 99 & Y\\
\hline
simplest\_design & 363 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.35 & 0.73 & -0.15 & 0.21 & 99 & Y\\
\hline
simplest\_design & 364 & Q & 0 & estimator & (Intercept) & -0.21 & 0.09 & -2.31 & 0.02 & -0.40 & -0.03 & 99 & Y\\
\hline
simplest\_design & 365 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.20 & 0.84 & -0.16 & 0.19 & 99 & Y\\
\hline
simplest\_design & 366 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.76 & 0.45 & -0.12 & 0.27 & 99 & Y\\
\hline
simplest\_design & 367 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.07 & 0.94 & -0.18 & 0.17 & 99 & Y\\
\hline
simplest\_design & 368 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.08 & 0.94 & -0.19 & 0.21 & 99 & Y\\
\hline
simplest\_design & 369 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.19 & 0.85 & -0.19 & 0.16 & 99 & Y\\
\hline
simplest\_design & 370 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & 0.00 & 1.00 & -0.21 & 0.21 & 99 & Y\\
\hline
simplest\_design & 371 & Q & 0 & estimator & (Intercept) & 0.08 & 0.09 & 0.80 & 0.43 & -0.11 & 0.26 & 99 & Y\\
\hline
simplest\_design & 372 & Q & 0 & estimator & (Intercept) & -0.22 & 0.11 & -1.98 & 0.05 & -0.44 & 0.00 & 99 & Y\\
\hline
simplest\_design & 373 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.44 & 0.66 & -0.16 & 0.25 & 99 & Y\\
\hline
simplest\_design & 374 & Q & 0 & estimator & (Intercept) & 0.15 & 0.10 & 1.54 & 0.13 & -0.04 & 0.34 & 99 & Y\\
\hline
simplest\_design & 375 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.14 & 0.89 & -0.17 & 0.19 & 99 & Y\\
\hline
simplest\_design & 376 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.83 & 0.41 & -0.27 & 0.11 & 99 & Y\\
\hline
simplest\_design & 377 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.48 & 0.63 & -0.15 & 0.25 & 99 & Y\\
\hline
simplest\_design & 378 & Q & 0 & estimator & (Intercept) & -0.06 & 0.09 & -0.64 & 0.53 & -0.24 & 0.12 & 99 & Y\\
\hline
simplest\_design & 379 & Q & 0 & estimator & (Intercept) & 0.09 & 0.11 & 0.80 & 0.43 & -0.13 & 0.30 & 99 & Y\\
\hline
simplest\_design & 380 & Q & 0 & estimator & (Intercept) & 0.14 & 0.09 & 1.59 & 0.12 & -0.04 & 0.32 & 99 & Y\\
\hline
simplest\_design & 381 & Q & 0 & estimator & (Intercept) & 0.20 & 0.10 & 1.97 & 0.05 & 0.00 & 0.40 & 99 & Y\\
\hline
simplest\_design & 382 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.58 & 0.12 & -0.36 & 0.04 & 99 & Y\\
\hline
simplest\_design & 383 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.14 & 0.89 & -0.21 & 0.18 & 99 & Y\\
\hline
simplest\_design & 384 & Q & 0 & estimator & (Intercept) & 0.09 & 0.11 & 0.78 & 0.44 & -0.13 & 0.31 & 99 & Y\\
\hline
simplest\_design & 385 & Q & 0 & estimator & (Intercept) & -0.20 & 0.09 & -2.12 & 0.04 & -0.38 & -0.01 & 99 & Y\\
\hline
simplest\_design & 386 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.33 & 0.74 & -0.22 & 0.16 & 99 & Y\\
\hline
simplest\_design & 387 & Q & 0 & estimator & (Intercept) & -0.15 & 0.11 & -1.37 & 0.17 & -0.38 & 0.07 & 99 & Y\\
\hline
simplest\_design & 388 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & 0.03 & 0.97 & -0.17 & 0.18 & 99 & Y\\
\hline
simplest\_design & 389 & Q & 0 & estimator & (Intercept) & 0.03 & 0.12 & 0.23 & 0.82 & -0.21 & 0.26 & 99 & Y\\
\hline
simplest\_design & 390 & Q & 0 & estimator & (Intercept) & 0.06 & 0.11 & 0.50 & 0.62 & -0.17 & 0.29 & 99 & Y\\
\hline
simplest\_design & 391 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.12 & 0.90 & -0.21 & 0.19 & 99 & Y\\
\hline
simplest\_design & 392 & Q & 0 & estimator & (Intercept) & -0.14 & 0.08 & -1.74 & 0.09 & -0.31 & 0.02 & 99 & Y\\
\hline
simplest\_design & 393 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.11 & 0.91 & -0.19 & 0.21 & 99 & Y\\
\hline
simplest\_design & 394 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.73 & 0.46 & -0.13 & 0.28 & 99 & Y\\
\hline
simplest\_design & 395 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.56 & 0.58 & -0.15 & 0.26 & 99 & Y\\
\hline
simplest\_design & 396 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.07 & 0.94 & -0.21 & 0.20 & 99 & Y\\
\hline
simplest\_design & 397 & Q & 0 & estimator & (Intercept) & 0.23 & 0.11 & 2.09 & 0.04 & 0.01 & 0.45 & 99 & Y\\
\hline
simplest\_design & 398 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.21 & 0.83 & -0.21 & 0.17 & 99 & Y\\
\hline
simplest\_design & 399 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.85 & 0.40 & -0.29 & 0.12 & 99 & Y\\
\hline
simplest\_design & 400 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.48 & 0.63 & -0.24 & 0.15 & 99 & Y\\
\hline
simplest\_design & 401 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.25 & 0.80 & -0.18 & 0.23 & 99 & Y\\
\hline
simplest\_design & 402 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.32 & 0.75 & -0.23 & 0.17 & 99 & Y\\
\hline
simplest\_design & 403 & Q & 0 & estimator & (Intercept) & 0.03 & 0.11 & 0.24 & 0.81 & -0.19 & 0.24 & 99 & Y\\
\hline
simplest\_design & 404 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.24 & 0.81 & -0.16 & 0.21 & 99 & Y\\
\hline
simplest\_design & 405 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.76 & 0.45 & -0.12 & 0.28 & 99 & Y\\
\hline
simplest\_design & 406 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.61 & 0.11 & -0.37 & 0.04 & 99 & Y\\
\hline
simplest\_design & 407 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.02 & 0.31 & -0.28 & 0.09 & 99 & Y\\
\hline
simplest\_design & 408 & Q & 0 & estimator & (Intercept) & -0.17 & 0.09 & -1.83 & 0.07 & -0.36 & 0.01 & 99 & Y\\
\hline
simplest\_design & 409 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.48 & 0.63 & -0.15 & 0.24 & 99 & Y\\
\hline
simplest\_design & 410 & Q & 0 & estimator & (Intercept) & -0.14 & 0.10 & -1.38 & 0.17 & -0.33 & 0.06 & 99 & Y\\
\hline
simplest\_design & 411 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.76 & 0.45 & -0.28 & 0.12 & 99 & Y\\
\hline
simplest\_design & 412 & Q & 0 & estimator & (Intercept) & 0.12 & 0.10 & 1.18 & 0.24 & -0.08 & 0.33 & 99 & Y\\
\hline
simplest\_design & 413 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 0.99 & 0.32 & -0.10 & 0.29 & 99 & Y\\
\hline
simplest\_design & 414 & Q & 0 & estimator & (Intercept) & 0.15 & 0.10 & 1.44 & 0.15 & -0.06 & 0.36 & 99 & Y\\
\hline
simplest\_design & 415 & Q & 0 & estimator & (Intercept) & -0.14 & 0.09 & -1.44 & 0.15 & -0.33 & 0.05 & 99 & Y\\
\hline
simplest\_design & 416 & Q & 0 & estimator & (Intercept) & 0.07 & 0.08 & 0.85 & 0.40 & -0.09 & 0.24 & 99 & Y\\
\hline
simplest\_design & 417 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.82 & 0.42 & -0.12 & 0.29 & 99 & Y\\
\hline
simplest\_design & 418 & Q & 0 & estimator & (Intercept) & -0.10 & 0.10 & -1.01 & 0.32 & -0.29 & 0.09 & 99 & Y\\
\hline
simplest\_design & 419 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.07 & 0.95 & -0.18 & 0.17 & 99 & Y\\
\hline
simplest\_design & 420 & Q & 0 & estimator & (Intercept) & 0.13 & 0.09 & 1.42 & 0.16 & -0.05 & 0.32 & 99 & Y\\
\hline
simplest\_design & 421 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.26 & 0.80 & -0.18 & 0.23 & 99 & Y\\
\hline
simplest\_design & 422 & Q & 0 & estimator & (Intercept) & -0.09 & 0.12 & -0.73 & 0.47 & -0.32 & 0.15 & 99 & Y\\
\hline
simplest\_design & 423 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.57 & 0.12 & -0.35 & 0.04 & 99 & Y\\
\hline
simplest\_design & 424 & Q & 0 & estimator & (Intercept) & 0.14 & 0.10 & 1.46 & 0.15 & -0.05 & 0.33 & 99 & Y\\
\hline
simplest\_design & 425 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.64 & 0.52 & -0.27 & 0.14 & 99 & Y\\
\hline
simplest\_design & 426 & Q & 0 & estimator & (Intercept) & -0.03 & 0.09 & -0.37 & 0.71 & -0.22 & 0.15 & 99 & Y\\
\hline
simplest\_design & 427 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.06 & 0.95 & -0.19 & 0.21 & 99 & Y\\
\hline
simplest\_design & 428 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.29 & 0.77 & -0.23 & 0.17 & 99 & Y\\
\hline
simplest\_design & 429 & Q & 0 & estimator & (Intercept) & 0.07 & 0.09 & 0.82 & 0.41 & -0.10 & 0.24 & 99 & Y\\
\hline
simplest\_design & 430 & Q & 0 & estimator & (Intercept) & 0.15 & 0.10 & 1.50 & 0.14 & -0.05 & 0.35 & 99 & Y\\
\hline
simplest\_design & 431 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.67 & 0.51 & -0.13 & 0.25 & 99 & Y\\
\hline
simplest\_design & 432 & Q & 0 & estimator & (Intercept) & -0.04 & 0.11 & -0.36 & 0.72 & -0.26 & 0.18 & 99 & Y\\
\hline
simplest\_design & 433 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.21 & 0.84 & -0.21 & 0.17 & 99 & Y\\
\hline
simplest\_design & 434 & Q & 0 & estimator & (Intercept) & -0.04 & 0.11 & -0.35 & 0.73 & -0.25 & 0.18 & 99 & Y\\
\hline
simplest\_design & 435 & Q & 0 & estimator & (Intercept) & 0.10 & 0.09 & 1.05 & 0.30 & -0.09 & 0.29 & 99 & Y\\
\hline
simplest\_design & 436 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.30 & 0.77 & -0.18 & 0.24 & 99 & Y\\
\hline
simplest\_design & 437 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 0.97 & 0.33 & -0.10 & 0.30 & 99 & Y\\
\hline
simplest\_design & 438 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.51 & 0.13 & -0.36 & 0.05 & 99 & Y\\
\hline
simplest\_design & 439 & Q & 0 & estimator & (Intercept) & -0.05 & 0.09 & -0.55 & 0.59 & -0.23 & 0.13 & 99 & Y\\
\hline
simplest\_design & 440 & Q & 0 & estimator & (Intercept) & -0.15 & 0.10 & -1.59 & 0.11 & -0.34 & 0.04 & 99 & Y\\
\hline
simplest\_design & 441 & Q & 0 & estimator & (Intercept) & 0.15 & 0.10 & 1.51 & 0.13 & -0.05 & 0.35 & 99 & Y\\
\hline
simplest\_design & 442 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.22 & 0.82 & -0.19 & 0.16 & 99 & Y\\
\hline
simplest\_design & 443 & Q & 0 & estimator & (Intercept) & -0.22 & 0.10 & -2.20 & 0.03 & -0.42 & -0.02 & 99 & Y\\
\hline
simplest\_design & 444 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.31 & 0.75 & -0.16 & 0.22 & 99 & Y\\
\hline
simplest\_design & 445 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.83 & 0.41 & -0.11 & 0.28 & 99 & Y\\
\hline
simplest\_design & 446 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.71 & 0.48 & -0.29 & 0.14 & 99 & Y\\
\hline
simplest\_design & 447 & Q & 0 & estimator & (Intercept) & -0.11 & 0.10 & -1.11 & 0.27 & -0.32 & 0.09 & 99 & Y\\
\hline
simplest\_design & 448 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.19 & 0.85 & -0.18 & 0.22 & 99 & Y\\
\hline
simplest\_design & 449 & Q & 0 & estimator & (Intercept) & 0.03 & 0.11 & 0.31 & 0.76 & -0.18 & 0.25 & 99 & Y\\
\hline
simplest\_design & 450 & Q & 0 & estimator & (Intercept) & -0.05 & 0.11 & -0.49 & 0.62 & -0.26 & 0.16 & 99 & Y\\
\hline
simplest\_design & 451 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.06 & 0.95 & -0.20 & 0.21 & 99 & Y\\
\hline
simplest\_design & 452 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.18 & 0.24 & -0.32 & 0.08 & 99 & Y\\
\hline
simplest\_design & 453 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.78 & 0.44 & -0.12 & 0.28 & 99 & Y\\
\hline
simplest\_design & 454 & Q & 0 & estimator & (Intercept) & 0.03 & 0.11 & 0.26 & 0.79 & -0.18 & 0.24 & 99 & Y\\
\hline
simplest\_design & 455 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.37 & 0.72 & -0.14 & 0.20 & 99 & Y\\
\hline
simplest\_design & 456 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & -0.04 & 0.97 & -0.18 & 0.18 & 99 & Y\\
\hline
simplest\_design & 457 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.16 & 0.87 & -0.17 & 0.19 & 99 & Y\\
\hline
simplest\_design & 458 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & 0.04 & 0.97 & -0.18 & 0.19 & 99 & Y\\
\hline
simplest\_design & 459 & Q & 0 & estimator & (Intercept) & -0.02 & 0.11 & -0.20 & 0.84 & -0.23 & 0.19 & 99 & Y\\
\hline
simplest\_design & 460 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.37 & 0.71 & -0.23 & 0.16 & 99 & Y\\
\hline
simplest\_design & 461 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.33 & 0.74 & -0.16 & 0.23 & 99 & Y\\
\hline
simplest\_design & 462 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.33 & 0.74 & -0.22 & 0.16 & 99 & Y\\
\hline
simplest\_design & 463 & Q & 0 & estimator & (Intercept) & 0.07 & 0.11 & 0.60 & 0.55 & -0.16 & 0.29 & 99 & Y\\
\hline
simplest\_design & 464 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.17 & 0.86 & -0.17 & 0.20 & 99 & Y\\
\hline
simplest\_design & 465 & Q & 0 & estimator & (Intercept) & 0.21 & 0.11 & 1.98 & 0.05 & 0.00 & 0.42 & 99 & Y\\
\hline
simplest\_design & 466 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.80 & 0.42 & -0.12 & 0.29 & 99 & Y\\
\hline
simplest\_design & 467 & Q & 0 & estimator & (Intercept) & 0.04 & 0.09 & 0.42 & 0.68 & -0.14 & 0.21 & 99 & Y\\
\hline
simplest\_design & 468 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.76 & 0.45 & -0.28 & 0.12 & 99 & Y\\
\hline
simplest\_design & 469 & Q & 0 & estimator & (Intercept) & 0.08 & 0.11 & 0.74 & 0.46 & -0.14 & 0.30 & 99 & Y\\
\hline
simplest\_design & 470 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.80 & 0.42 & -0.28 & 0.12 & 99 & Y\\
\hline
simplest\_design & 471 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.70 & 0.48 & -0.26 & 0.12 & 99 & Y\\
\hline
simplest\_design & 472 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.09 & 0.28 & -0.09 & 0.32 & 99 & Y\\
\hline
simplest\_design & 473 & Q & 0 & estimator & (Intercept) & 0.12 & 0.09 & 1.45 & 0.15 & -0.05 & 0.30 & 99 & Y\\
\hline
simplest\_design & 474 & Q & 0 & estimator & (Intercept) & 0.15 & 0.10 & 1.49 & 0.14 & -0.05 & 0.35 & 99 & Y\\
\hline
simplest\_design & 475 & Q & 0 & estimator & (Intercept) & -0.16 & 0.11 & -1.45 & 0.15 & -0.38 & 0.06 & 99 & Y\\
\hline
simplest\_design & 476 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.61 & 0.54 & -0.25 & 0.13 & 99 & Y\\
\hline
simplest\_design & 477 & Q & 0 & estimator & (Intercept) & 0.04 & 0.09 & 0.46 & 0.64 & -0.14 & 0.22 & 99 & Y\\
\hline
simplest\_design & 478 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.21 & 0.83 & -0.16 & 0.20 & 99 & Y\\
\hline
simplest\_design & 479 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.72 & 0.48 & -0.28 & 0.13 & 99 & Y\\
\hline
simplest\_design & 480 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.12 & 0.90 & -0.18 & 0.20 & 99 & Y\\
\hline
simplest\_design & 481 & Q & 0 & estimator & (Intercept) & 0.20 & 0.10 & 2.09 & 0.04 & 0.01 & 0.39 & 99 & Y\\
\hline
simplest\_design & 482 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.84 & 0.40 & -0.28 & 0.11 & 99 & Y\\
\hline
simplest\_design & 483 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.28 & 0.78 & -0.17 & 0.22 & 99 & Y\\
\hline
simplest\_design & 484 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & -0.02 & 0.98 & -0.19 & 0.18 & 99 & Y\\
\hline
simplest\_design & 485 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.70 & 0.09 & -0.35 & 0.03 & 99 & Y\\
\hline
simplest\_design & 486 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.15 & 0.88 & -0.19 & 0.23 & 99 & Y\\
\hline
simplest\_design & 487 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.18 & 0.24 & -0.08 & 0.31 & 99 & Y\\
\hline
simplest\_design & 488 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 1.02 & 0.31 & -0.09 & 0.29 & 99 & Y\\
\hline
simplest\_design & 489 & Q & 0 & estimator & (Intercept) & 0.06 & 0.11 & 0.59 & 0.56 & -0.15 & 0.28 & 99 & Y\\
\hline
simplest\_design & 490 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.52 & 0.60 & -0.15 & 0.26 & 99 & Y\\
\hline
simplest\_design & 491 & Q & 0 & estimator & (Intercept) & -0.06 & 0.09 & -0.59 & 0.55 & -0.24 & 0.13 & 99 & Y\\
\hline
simplest\_design & 492 & Q & 0 & estimator & (Intercept) & -0.17 & 0.10 & -1.68 & 0.10 & -0.37 & 0.03 & 99 & Y\\
\hline
simplest\_design & 493 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.14 & 0.26 & -0.29 & 0.08 & 99 & Y\\
\hline
simplest\_design & 494 & Q & 0 & estimator & (Intercept) & -0.06 & 0.11 & -0.53 & 0.60 & -0.27 & 0.16 & 99 & Y\\
\hline
simplest\_design & 495 & Q & 0 & estimator & (Intercept) & 0.15 & 0.10 & 1.54 & 0.13 & -0.04 & 0.35 & 99 & Y\\
\hline
simplest\_design & 496 & Q & 0 & estimator & (Intercept) & -0.11 & 0.10 & -1.12 & 0.27 & -0.31 & 0.09 & 99 & Y\\
\hline
simplest\_design & 497 & Q & 0 & estimator & (Intercept) & 0.10 & 0.11 & 0.94 & 0.35 & -0.12 & 0.32 & 99 & Y\\
\hline
simplest\_design & 498 & Q & 0 & estimator & (Intercept) & 0.09 & 0.09 & 1.06 & 0.29 & -0.08 & 0.27 & 99 & Y\\
\hline
simplest\_design & 499 & Q & 0 & estimator & (Intercept) & -0.16 & 0.09 & -1.82 & 0.07 & -0.33 & 0.01 & 99 & Y\\
\hline
simplest\_design & 500 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.08 & 0.28 & -0.09 & 0.30 & 99 & Y\\
\hline
simplest\_design & 501 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.22 & 0.83 & -0.20 & 0.24 & 99 & Y\\
\hline
simplest\_design & 502 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.36 & 0.72 & -0.16 & 0.24 & 99 & Y\\
\hline
simplest\_design & 503 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.25 & 0.80 & -0.23 & 0.17 & 99 & Y\\
\hline
simplest\_design & 504 & Q & 0 & estimator & (Intercept) & 0.11 & 0.09 & 1.20 & 0.23 & -0.07 & 0.30 & 99 & Y\\
\hline
simplest\_design & 505 & Q & 0 & estimator & (Intercept) & -0.06 & 0.12 & -0.50 & 0.62 & -0.29 & 0.17 & 99 & Y\\
\hline
simplest\_design & 506 & Q & 0 & estimator & (Intercept) & 0.03 & 0.11 & 0.33 & 0.74 & -0.17 & 0.24 & 99 & Y\\
\hline
simplest\_design & 507 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.37 & 0.72 & -0.23 & 0.16 & 99 & Y\\
\hline
simplest\_design & 508 & Q & 0 & estimator & (Intercept) & 0.07 & 0.08 & 0.86 & 0.39 & -0.09 & 0.23 & 99 & Y\\
\hline
simplest\_design & 509 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.85 & 0.40 & -0.27 & 0.11 & 99 & Y\\
\hline
simplest\_design & 510 & Q & 0 & estimator & (Intercept) & -0.15 & 0.12 & -1.25 & 0.21 & -0.38 & 0.09 & 99 & Y\\
\hline
simplest\_design & 511 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.02 & 0.99 & -0.20 & 0.20 & 99 & Y\\
\hline
simplest\_design & 512 & Q & 0 & estimator & (Intercept) & -0.29 & 0.10 & -2.95 & 0.00 & -0.48 & -0.09 & 99 & Y\\
\hline
simplest\_design & 513 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.75 & 0.46 & -0.29 & 0.13 & 99 & Y\\
\hline
simplest\_design & 514 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.19 & 0.24 & -0.33 & 0.08 & 99 & Y\\
\hline
simplest\_design & 515 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.44 & 0.66 & -0.15 & 0.24 & 99 & Y\\
\hline
simplest\_design & 516 & Q & 0 & estimator & (Intercept) & 0.16 & 0.10 & 1.53 & 0.13 & -0.05 & 0.36 & 99 & Y\\
\hline
simplest\_design & 517 & Q & 0 & estimator & (Intercept) & 0.21 & 0.09 & 2.41 & 0.02 & 0.04 & 0.38 & 99 & Y\\
\hline
simplest\_design & 518 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.90 & 0.37 & -0.11 & 0.29 & 99 & Y\\
\hline
simplest\_design & 519 & Q & 0 & estimator & (Intercept) & -0.11 & 0.09 & -1.21 & 0.23 & -0.28 & 0.07 & 99 & Y\\
\hline
simplest\_design & 520 & Q & 0 & estimator & (Intercept) & -0.10 & 0.10 & -0.96 & 0.34 & -0.29 & 0.10 & 99 & Y\\
\hline
simplest\_design & 521 & Q & 0 & estimator & (Intercept) & 0.03 & 0.11 & 0.23 & 0.82 & -0.19 & 0.25 & 99 & Y\\
\hline
simplest\_design & 522 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.40 & 0.69 & -0.23 & 0.15 & 99 & Y\\
\hline
simplest\_design & 523 & Q & 0 & estimator & (Intercept) & 0.00 & 0.11 & -0.04 & 0.97 & -0.22 & 0.21 & 99 & Y\\
\hline
simplest\_design & 524 & Q & 0 & estimator & (Intercept) & 0.16 & 0.10 & 1.60 & 0.11 & -0.04 & 0.36 & 99 & Y\\
\hline
simplest\_design & 525 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.72 & 0.47 & -0.13 & 0.28 & 99 & Y\\
\hline
simplest\_design & 526 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.57 & 0.57 & -0.26 & 0.14 & 99 & Y\\
\hline
simplest\_design & 527 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.09 & 0.93 & -0.18 & 0.20 & 99 & Y\\
\hline
simplest\_design & 528 & Q & 0 & estimator & (Intercept) & 0.07 & 0.09 & 0.71 & 0.48 & -0.12 & 0.25 & 99 & Y\\
\hline
simplest\_design & 529 & Q & 0 & estimator & (Intercept) & -0.12 & 0.11 & -1.07 & 0.29 & -0.33 & 0.10 & 99 & Y\\
\hline
simplest\_design & 530 & Q & 0 & estimator & (Intercept) & -0.25 & 0.10 & -2.51 & 0.01 & -0.45 & -0.05 & 99 & Y\\
\hline
simplest\_design & 531 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.66 & 0.51 & -0.13 & 0.25 & 99 & Y\\
\hline
simplest\_design & 532 & Q & 0 & estimator & (Intercept) & 0.14 & 0.11 & 1.30 & 0.20 & -0.07 & 0.35 & 99 & Y\\
\hline
simplest\_design & 533 & Q & 0 & estimator & (Intercept) & 0.03 & 0.11 & 0.25 & 0.81 & -0.19 & 0.24 & 99 & Y\\
\hline
simplest\_design & 534 & Q & 0 & estimator & (Intercept) & -0.15 & 0.10 & -1.44 & 0.15 & -0.35 & 0.06 & 99 & Y\\
\hline
simplest\_design & 535 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.53 & 0.60 & -0.13 & 0.23 & 99 & Y\\
\hline
simplest\_design & 536 & Q & 0 & estimator & (Intercept) & 0.18 & 0.10 & 1.73 & 0.09 & -0.03 & 0.39 & 99 & Y\\
\hline
simplest\_design & 537 & Q & 0 & estimator & (Intercept) & 0.03 & 0.11 & 0.24 & 0.81 & -0.19 & 0.24 & 99 & Y\\
\hline
simplest\_design & 538 & Q & 0 & estimator & (Intercept) & -0.14 & 0.10 & -1.40 & 0.16 & -0.34 & 0.06 & 99 & Y\\
\hline
simplest\_design & 539 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 1.02 & 0.31 & -0.09 & 0.30 & 99 & Y\\
\hline
simplest\_design & 540 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.31 & 0.76 & -0.24 & 0.17 & 99 & Y\\
\hline
simplest\_design & 541 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.34 & 0.74 & -0.23 & 0.16 & 99 & Y\\
\hline
simplest\_design & 542 & Q & 0 & estimator & (Intercept) & 0.23 & 0.09 & 2.51 & 0.01 & 0.05 & 0.41 & 99 & Y\\
\hline
simplest\_design & 543 & Q & 0 & estimator & (Intercept) & -0.17 & 0.11 & -1.55 & 0.13 & -0.39 & 0.05 & 99 & Y\\
\hline
simplest\_design & 544 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.07 & 0.94 & -0.20 & 0.19 & 99 & Y\\
\hline
simplest\_design & 545 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.16 & 0.87 & -0.22 & 0.18 & 99 & Y\\
\hline
simplest\_design & 546 & Q & 0 & estimator & (Intercept) & 0.21 & 0.10 & 2.04 & 0.04 & 0.01 & 0.42 & 99 & Y\\
\hline
simplest\_design & 547 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.19 & 0.24 & -0.33 & 0.08 & 99 & Y\\
\hline
simplest\_design & 548 & Q & 0 & estimator & (Intercept) & 0.07 & 0.09 & 0.79 & 0.43 & -0.11 & 0.26 & 99 & Y\\
\hline
simplest\_design & 549 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 1.04 & 0.30 & -0.09 & 0.29 & 99 & Y\\
\hline
simplest\_design & 550 & Q & 0 & estimator & (Intercept) & 0.10 & 0.11 & 0.88 & 0.38 & -0.12 & 0.31 & 99 & Y\\
\hline
simplest\_design & 551 & Q & 0 & estimator & (Intercept) & -0.01 & 0.11 & -0.12 & 0.91 & -0.23 & 0.21 & 99 & Y\\
\hline
simplest\_design & 552 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.71 & 0.48 & -0.13 & 0.27 & 99 & Y\\
\hline
simplest\_design & 553 & Q & 0 & estimator & (Intercept) & 0.17 & 0.11 & 1.50 & 0.14 & -0.05 & 0.39 & 99 & Y\\
\hline
simplest\_design & 554 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.01 & 0.99 & -0.20 & 0.20 & 99 & Y\\
\hline
simplest\_design & 555 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.74 & 0.46 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 556 & Q & 0 & estimator & (Intercept) & -0.05 & 0.09 & -0.51 & 0.61 & -0.22 & 0.13 & 99 & Y\\
\hline
simplest\_design & 557 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.09 & 0.93 & -0.21 & 0.19 & 99 & Y\\
\hline
simplest\_design & 558 & Q & 0 & estimator & (Intercept) & 0.05 & 0.11 & 0.48 & 0.63 & -0.17 & 0.28 & 99 & Y\\
\hline
simplest\_design & 559 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.56 & 0.58 & -0.14 & 0.25 & 99 & Y\\
\hline
simplest\_design & 560 & Q & 0 & estimator & (Intercept) & 0.18 & 0.10 & 1.89 & 0.06 & -0.01 & 0.37 & 99 & Y\\
\hline
simplest\_design & 561 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.25 & 0.80 & -0.22 & 0.17 & 99 & Y\\
\hline
simplest\_design & 562 & Q & 0 & estimator & (Intercept) & -0.08 & 0.09 & -0.92 & 0.36 & -0.26 & 0.09 & 99 & Y\\
\hline
simplest\_design & 563 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.10 & 0.92 & -0.20 & 0.18 & 99 & Y\\
\hline
simplest\_design & 564 & Q & 0 & estimator & (Intercept) & 0.14 & 0.10 & 1.51 & 0.14 & -0.05 & 0.33 & 99 & Y\\
\hline
simplest\_design & 565 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.08 & 0.93 & -0.21 & 0.19 & 99 & Y\\
\hline
simplest\_design & 566 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.10 & 0.92 & -0.17 & 0.19 & 99 & Y\\
\hline
simplest\_design & 567 & Q & 0 & estimator & (Intercept) & -0.06 & 0.09 & -0.62 & 0.53 & -0.25 & 0.13 & 99 & Y\\
\hline
simplest\_design & 568 & Q & 0 & estimator & (Intercept) & -0.15 & 0.10 & -1.54 & 0.13 & -0.35 & 0.04 & 99 & Y\\
\hline
simplest\_design & 569 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.70 & 0.48 & -0.26 & 0.12 & 99 & Y\\
\hline
simplest\_design & 570 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.04 & 0.30 & -0.10 & 0.31 & 99 & Y\\
\hline
simplest\_design & 571 & Q & 0 & estimator & (Intercept) & 0.13 & 0.10 & 1.36 & 0.18 & -0.06 & 0.33 & 99 & Y\\
\hline
simplest\_design & 572 & Q & 0 & estimator & (Intercept) & -0.18 & 0.11 & -1.69 & 0.09 & -0.40 & 0.03 & 99 & Y\\
\hline
simplest\_design & 573 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.31 & 0.76 & -0.17 & 0.24 & 99 & Y\\
\hline
simplest\_design & 574 & Q & 0 & estimator & (Intercept) & 0.06 & 0.11 & 0.53 & 0.60 & -0.17 & 0.29 & 99 & Y\\
\hline
simplest\_design & 575 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.20 & 0.85 & -0.19 & 0.23 & 99 & Y\\
\hline
simplest\_design & 576 & Q & 0 & estimator & (Intercept) & 0.06 & 0.09 & 0.68 & 0.50 & -0.11 & 0.23 & 99 & Y\\
\hline
simplest\_design & 577 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.11 & 0.92 & -0.19 & 0.21 & 99 & Y\\
\hline
simplest\_design & 578 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.74 & 0.46 & -0.12 & 0.26 & 99 & Y\\
\hline
simplest\_design & 579 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.35 & 0.18 & -0.32 & 0.06 & 99 & Y\\
\hline
simplest\_design & 580 & Q & 0 & estimator & (Intercept) & -0.14 & 0.09 & -1.51 & 0.13 & -0.33 & 0.05 & 99 & Y\\
\hline
simplest\_design & 581 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.75 & 0.45 & -0.29 & 0.13 & 99 & Y\\
\hline
simplest\_design & 582 & Q & 0 & estimator & (Intercept) & 0.06 & 0.09 & 0.62 & 0.53 & -0.13 & 0.24 & 99 & Y\\
\hline
simplest\_design & 583 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.68 & 0.50 & -0.14 & 0.28 & 99 & Y\\
\hline
simplest\_design & 584 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.65 & 0.51 & -0.28 & 0.14 & 99 & Y\\
\hline
simplest\_design & 585 & Q & 0 & estimator & (Intercept) & 0.06 & 0.08 & 0.73 & 0.47 & -0.10 & 0.23 & 99 & Y\\
\hline
simplest\_design & 586 & Q & 0 & estimator & (Intercept) & 0.04 & 0.09 & 0.48 & 0.63 & -0.13 & 0.22 & 99 & Y\\
\hline
simplest\_design & 587 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.71 & 0.48 & -0.28 & 0.13 & 99 & Y\\
\hline
simplest\_design & 588 & Q & 0 & estimator & (Intercept) & -0.20 & 0.10 & -1.95 & 0.05 & -0.40 & 0.00 & 99 & Y\\
\hline
simplest\_design & 589 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.92 & 0.36 & -0.11 & 0.30 & 99 & Y\\
\hline
simplest\_design & 590 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.14 & 0.89 & -0.19 & 0.17 & 99 & Y\\
\hline
simplest\_design & 591 & Q & 0 & estimator & (Intercept) & 0.15 & 0.09 & 1.60 & 0.11 & -0.04 & 0.33 & 99 & Y\\
\hline
simplest\_design & 592 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.17 & 0.87 & -0.22 & 0.19 & 99 & Y\\
\hline
simplest\_design & 593 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 1.00 & 0.32 & -0.10 & 0.29 & 99 & Y\\
\hline
simplest\_design & 594 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.81 & 0.42 & -0.29 & 0.12 & 99 & Y\\
\hline
simplest\_design & 595 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.31 & 0.76 & -0.17 & 0.23 & 99 & Y\\
\hline
simplest\_design & 596 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 0.99 & 0.32 & -0.10 & 0.31 & 99 & Y\\
\hline
simplest\_design & 597 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.90 & 0.37 & -0.28 & 0.11 & 99 & Y\\
\hline
simplest\_design & 598 & Q & 0 & estimator & (Intercept) & 0.14 & 0.10 & 1.38 & 0.17 & -0.06 & 0.34 & 99 & Y\\
\hline
simplest\_design & 599 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.12 & 0.91 & -0.21 & 0.19 & 99 & Y\\
\hline
simplest\_design & 600 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.85 & 0.40 & -0.28 & 0.11 & 99 & Y\\
\hline
simplest\_design & 601 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.24 & 0.81 & -0.21 & 0.16 & 99 & Y\\
\hline
simplest\_design & 602 & Q & 0 & estimator & (Intercept) & 0.10 & 0.11 & 0.90 & 0.37 & -0.11 & 0.31 & 99 & Y\\
\hline
simplest\_design & 603 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & -0.01 & 0.99 & -0.19 & 0.18 & 99 & Y\\
\hline
simplest\_design & 604 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & 0.01 & 0.99 & -0.19 & 0.19 & 99 & Y\\
\hline
simplest\_design & 605 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.80 & 0.42 & -0.27 & 0.12 & 99 & Y\\
\hline
simplest\_design & 606 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.81 & 0.42 & -0.12 & 0.27 & 99 & Y\\
\hline
simplest\_design & 607 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.30 & 0.20 & -0.34 & 0.07 & 99 & Y\\
\hline
simplest\_design & 608 & Q & 0 & estimator & (Intercept) & -0.11 & 0.10 & -1.12 & 0.27 & -0.30 & 0.08 & 99 & Y\\
\hline
simplest\_design & 609 & Q & 0 & estimator & (Intercept) & -0.13 & 0.09 & -1.35 & 0.18 & -0.31 & 0.06 & 99 & Y\\
\hline
simplest\_design & 610 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.25 & 0.80 & -0.23 & 0.18 & 99 & Y\\
\hline
simplest\_design & 611 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.51 & 0.61 & -0.24 & 0.14 & 99 & Y\\
\hline
simplest\_design & 612 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.28 & 0.20 & -0.31 & 0.07 & 99 & Y\\
\hline
simplest\_design & 613 & Q & 0 & estimator & (Intercept) & 0.10 & 0.09 & 1.08 & 0.28 & -0.08 & 0.28 & 99 & Y\\
\hline
simplest\_design & 614 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.40 & 0.69 & -0.15 & 0.23 & 99 & Y\\
\hline
simplest\_design & 615 & Q & 0 & estimator & (Intercept) & 0.19 & 0.10 & 1.92 & 0.06 & -0.01 & 0.38 & 99 & Y\\
\hline
simplest\_design & 616 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.43 & 0.67 & -0.23 & 0.15 & 99 & Y\\
\hline
simplest\_design & 617 & Q & 0 & estimator & (Intercept) & -0.11 & 0.09 & -1.26 & 0.21 & -0.29 & 0.07 & 99 & Y\\
\hline
simplest\_design & 618 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.20 & 0.84 & -0.23 & 0.18 & 99 & Y\\
\hline
simplest\_design & 619 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.32 & 0.75 & -0.22 & 0.16 & 99 & Y\\
\hline
simplest\_design & 620 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.49 & 0.63 & -0.15 & 0.25 & 99 & Y\\
\hline
simplest\_design & 621 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.70 & 0.48 & -0.13 & 0.28 & 99 & Y\\
\hline
simplest\_design & 622 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.15 & 0.88 & -0.19 & 0.23 & 99 & Y\\
\hline
simplest\_design & 623 & Q & 0 & estimator & (Intercept) & -0.03 & 0.11 & -0.33 & 0.74 & -0.24 & 0.17 & 99 & Y\\
\hline
simplest\_design & 624 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.16 & 0.25 & -0.32 & 0.08 & 99 & Y\\
\hline
simplest\_design & 625 & Q & 0 & estimator & (Intercept) & 0.16 & 0.11 & 1.48 & 0.14 & -0.05 & 0.37 & 99 & Y\\
\hline
simplest\_design & 626 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.92 & 0.36 & -0.29 & 0.11 & 99 & Y\\
\hline
simplest\_design & 627 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.44 & 0.66 & -0.25 & 0.16 & 99 & Y\\
\hline
simplest\_design & 628 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.51 & 0.61 & -0.15 & 0.25 & 99 & Y\\
\hline
simplest\_design & 629 & Q & 0 & estimator & (Intercept) & 0.01 & 0.12 & 0.08 & 0.94 & -0.23 & 0.25 & 99 & Y\\
\hline
simplest\_design & 630 & Q & 0 & estimator & (Intercept) & 0.07 & 0.11 & 0.64 & 0.52 & -0.14 & 0.28 & 99 & Y\\
\hline
simplest\_design & 631 & Q & 0 & estimator & (Intercept) & -0.05 & 0.11 & -0.41 & 0.68 & -0.27 & 0.18 & 99 & Y\\
\hline
simplest\_design & 632 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.37 & 0.71 & -0.16 & 0.24 & 99 & Y\\
\hline
simplest\_design & 633 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.11 & 0.91 & -0.21 & 0.19 & 99 & Y\\
\hline
simplest\_design & 634 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.10 & 0.92 & -0.19 & 0.21 & 99 & Y\\
\hline
simplest\_design & 635 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.23 & 0.82 & -0.23 & 0.18 & 99 & Y\\
\hline
simplest\_design & 636 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.40 & 0.69 & -0.25 & 0.16 & 99 & Y\\
\hline
simplest\_design & 637 & Q & 0 & estimator & (Intercept) & 0.04 & 0.09 & 0.37 & 0.71 & -0.15 & 0.22 & 99 & Y\\
\hline
simplest\_design & 638 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.41 & 0.68 & -0.15 & 0.23 & 99 & Y\\
\hline
simplest\_design & 639 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.11 & 0.92 & -0.20 & 0.22 & 99 & Y\\
\hline
simplest\_design & 640 & Q & 0 & estimator & (Intercept) & 0.06 & 0.09 & 0.74 & 0.46 & -0.11 & 0.24 & 99 & Y\\
\hline
simplest\_design & 641 & Q & 0 & estimator & (Intercept) & -0.15 & 0.10 & -1.52 & 0.13 & -0.35 & 0.05 & 99 & Y\\
\hline
simplest\_design & 642 & Q & 0 & estimator & (Intercept) & 0.14 & 0.11 & 1.29 & 0.20 & -0.08 & 0.36 & 99 & Y\\
\hline
simplest\_design & 643 & Q & 0 & estimator & (Intercept) & -0.17 & 0.09 & -1.87 & 0.06 & -0.36 & 0.01 & 99 & Y\\
\hline
simplest\_design & 644 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.19 & 0.85 & -0.22 & 0.18 & 99 & Y\\
\hline
simplest\_design & 645 & Q & 0 & estimator & (Intercept) & -0.17 & 0.09 & -1.89 & 0.06 & -0.35 & 0.01 & 99 & Y\\
\hline
simplest\_design & 646 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.17 & 0.87 & -0.20 & 0.24 & 99 & Y\\
\hline
simplest\_design & 647 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.27 & 0.21 & -0.33 & 0.07 & 99 & Y\\
\hline
simplest\_design & 648 & Q & 0 & estimator & (Intercept) & 0.13 & 0.11 & 1.19 & 0.24 & -0.09 & 0.35 & 99 & Y\\
\hline
simplest\_design & 649 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.64 & 0.52 & -0.26 & 0.14 & 99 & Y\\
\hline
simplest\_design & 650 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.42 & 0.68 & -0.23 & 0.15 & 99 & Y\\
\hline
simplest\_design & 651 & Q & 0 & estimator & (Intercept) & -0.12 & 0.09 & -1.35 & 0.18 & -0.29 & 0.06 & 99 & Y\\
\hline
simplest\_design & 652 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.23 & 0.82 & -0.22 & 0.17 & 99 & Y\\
\hline
simplest\_design & 653 & Q & 0 & estimator & (Intercept) & 0.16 & 0.11 & 1.39 & 0.17 & -0.07 & 0.38 & 99 & Y\\
\hline
simplest\_design & 654 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.27 & 0.79 & -0.18 & 0.24 & 99 & Y\\
\hline
simplest\_design & 655 & Q & 0 & estimator & (Intercept) & -0.07 & 0.11 & -0.63 & 0.53 & -0.27 & 0.14 & 99 & Y\\
\hline
simplest\_design & 656 & Q & 0 & estimator & (Intercept) & 0.14 & 0.11 & 1.30 & 0.20 & -0.07 & 0.36 & 99 & Y\\
\hline
simplest\_design & 657 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.08 & 0.94 & -0.19 & 0.20 & 99 & Y\\
\hline
simplest\_design & 658 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.43 & 0.67 & -0.22 & 0.14 & 99 & Y\\
\hline
simplest\_design & 659 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.24 & 0.81 & -0.23 & 0.18 & 99 & Y\\
\hline
simplest\_design & 660 & Q & 0 & estimator & (Intercept) & -0.19 & 0.09 & -2.10 & 0.04 & -0.36 & -0.01 & 99 & Y\\
\hline
simplest\_design & 661 & Q & 0 & estimator & (Intercept) & -0.17 & 0.09 & -1.79 & 0.08 & -0.35 & 0.02 & 99 & Y\\
\hline
simplest\_design & 662 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.60 & 0.55 & -0.14 & 0.26 & 99 & Y\\
\hline
simplest\_design & 663 & Q & 0 & estimator & (Intercept) & 0.01 & 0.11 & 0.06 & 0.95 & -0.21 & 0.22 & 99 & Y\\
\hline
simplest\_design & 664 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.23 & 0.82 & -0.23 & 0.18 & 99 & Y\\
\hline
simplest\_design & 665 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.05 & 0.96 & -0.21 & 0.20 & 99 & Y\\
\hline
simplest\_design & 666 & Q & 0 & estimator & (Intercept) & 0.00 & 0.11 & 0.04 & 0.97 & -0.21 & 0.22 & 99 & Y\\
\hline
simplest\_design & 667 & Q & 0 & estimator & (Intercept) & -0.11 & 0.09 & -1.17 & 0.24 & -0.29 & 0.07 & 99 & Y\\
\hline
simplest\_design & 668 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.66 & 0.51 & -0.27 & 0.13 & 99 & Y\\
\hline
simplest\_design & 669 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.20 & 0.84 & -0.19 & 0.23 & 99 & Y\\
\hline
simplest\_design & 670 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.08 & 0.94 & -0.18 & 0.19 & 99 & Y\\
\hline
simplest\_design & 671 & Q & 0 & estimator & (Intercept) & 0.08 & 0.09 & 0.82 & 0.41 & -0.11 & 0.26 & 99 & Y\\
\hline
simplest\_design & 672 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.49 & 0.63 & -0.23 & 0.14 & 99 & Y\\
\hline
simplest\_design & 673 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.22 & 0.83 & -0.17 & 0.21 & 99 & Y\\
\hline
simplest\_design & 674 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.30 & 0.77 & -0.17 & 0.22 & 99 & Y\\
\hline
simplest\_design & 675 & Q & 0 & estimator & (Intercept) & -0.13 & 0.11 & -1.24 & 0.22 & -0.35 & 0.08 & 99 & Y\\
\hline
simplest\_design & 676 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.40 & 0.69 & -0.16 & 0.24 & 99 & Y\\
\hline
simplest\_design & 677 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.07 & 0.94 & -0.19 & 0.21 & 99 & Y\\
\hline
simplest\_design & 678 & Q & 0 & estimator & (Intercept) & -0.19 & 0.10 & -1.89 & 0.06 & -0.40 & 0.01 & 99 & Y\\
\hline
simplest\_design & 679 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.85 & 0.40 & -0.12 & 0.29 & 99 & Y\\
\hline
simplest\_design & 680 & Q & 0 & estimator & (Intercept) & -0.23 & 0.11 & -2.04 & 0.04 & -0.46 & -0.01 & 99 & Y\\
\hline
simplest\_design & 681 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.30 & 0.77 & -0.16 & 0.22 & 99 & Y\\
\hline
simplest\_design & 682 & Q & 0 & estimator & (Intercept) & 0.10 & 0.12 & 0.89 & 0.37 & -0.13 & 0.33 & 99 & Y\\
\hline
simplest\_design & 683 & Q & 0 & estimator & (Intercept) & -0.22 & 0.11 & -1.99 & 0.05 & -0.43 & 0.00 & 99 & Y\\
\hline
simplest\_design & 684 & Q & 0 & estimator & (Intercept) & 0.06 & 0.11 & 0.57 & 0.57 & -0.15 & 0.27 & 99 & Y\\
\hline
simplest\_design & 685 & Q & 0 & estimator & (Intercept) & -0.06 & 0.11 & -0.54 & 0.59 & -0.27 & 0.15 & 99 & Y\\
\hline
simplest\_design & 686 & Q & 0 & estimator & (Intercept) & -0.15 & 0.10 & -1.43 & 0.16 & -0.35 & 0.06 & 99 & Y\\
\hline
simplest\_design & 687 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.40 & 0.69 & -0.16 & 0.24 & 99 & Y\\
\hline
simplest\_design & 688 & Q & 0 & estimator & (Intercept) & -0.02 & 0.11 & -0.14 & 0.89 & -0.23 & 0.20 & 99 & Y\\
\hline
simplest\_design & 689 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.35 & 0.73 & -0.16 & 0.22 & 99 & Y\\
\hline
simplest\_design & 690 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.69 & 0.49 & -0.13 & 0.26 & 99 & Y\\
\hline
simplest\_design & 691 & Q & 0 & estimator & (Intercept) & -0.18 & 0.10 & -1.79 & 0.08 & -0.38 & 0.02 & 99 & Y\\
\hline
simplest\_design & 692 & Q & 0 & estimator & (Intercept) & -0.06 & 0.08 & -0.69 & 0.49 & -0.22 & 0.11 & 99 & Y\\
\hline
simplest\_design & 693 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.04 & 0.97 & -0.20 & 0.20 & 99 & Y\\
\hline
simplest\_design & 694 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.46 & 0.65 & -0.21 & 0.13 & 99 & Y\\
\hline
simplest\_design & 695 & Q & 0 & estimator & (Intercept) & 0.04 & 0.11 & 0.38 & 0.70 & -0.17 & 0.26 & 99 & Y\\
\hline
simplest\_design & 696 & Q & 0 & estimator & (Intercept) & -0.04 & 0.11 & -0.36 & 0.72 & -0.25 & 0.17 & 99 & Y\\
\hline
simplest\_design & 697 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.49 & 0.63 & -0.14 & 0.23 & 99 & Y\\
\hline
simplest\_design & 698 & Q & 0 & estimator & (Intercept) & 0.16 & 0.11 & 1.52 & 0.13 & -0.05 & 0.37 & 99 & Y\\
\hline
simplest\_design & 699 & Q & 0 & estimator & (Intercept) & 0.08 & 0.11 & 0.77 & 0.44 & -0.13 & 0.30 & 99 & Y\\
\hline
simplest\_design & 700 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.57 & 0.57 & -0.14 & 0.25 & 99 & Y\\
\hline
simplest\_design & 701 & Q & 0 & estimator & (Intercept) & -0.08 & 0.09 & -0.89 & 0.38 & -0.26 & 0.10 & 99 & Y\\
\hline
simplest\_design & 702 & Q & 0 & estimator & (Intercept) & -0.06 & 0.12 & -0.47 & 0.64 & -0.29 & 0.18 & 99 & Y\\
\hline
simplest\_design & 703 & Q & 0 & estimator & (Intercept) & -0.02 & 0.11 & -0.20 & 0.84 & -0.24 & 0.20 & 99 & Y\\
\hline
simplest\_design & 704 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.19 & 0.85 & -0.16 & 0.20 & 99 & Y\\
\hline
simplest\_design & 705 & Q & 0 & estimator & (Intercept) & 0.21 & 0.10 & 2.11 & 0.04 & 0.01 & 0.42 & 99 & Y\\
\hline
simplest\_design & 706 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.49 & 0.63 & -0.15 & 0.25 & 99 & Y\\
\hline
simplest\_design & 707 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.48 & 0.64 & -0.15 & 0.24 & 99 & Y\\
\hline
simplest\_design & 708 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.21 & 0.84 & -0.20 & 0.24 & 99 & Y\\
\hline
simplest\_design & 709 & Q & 0 & estimator & (Intercept) & 0.14 & 0.08 & 1.71 & 0.09 & -0.02 & 0.30 & 99 & Y\\
\hline
simplest\_design & 710 & Q & 0 & estimator & (Intercept) & 0.15 & 0.09 & 1.69 & 0.09 & -0.03 & 0.33 & 99 & Y\\
\hline
simplest\_design & 711 & Q & 0 & estimator & (Intercept) & 0.25 & 0.11 & 2.28 & 0.02 & 0.03 & 0.46 & 99 & Y\\
\hline
simplest\_design & 712 & Q & 0 & estimator & (Intercept) & -0.11 & 0.10 & -1.11 & 0.27 & -0.31 & 0.09 & 99 & Y\\
\hline
simplest\_design & 713 & Q & 0 & estimator & (Intercept) & 0.16 & 0.10 & 1.58 & 0.12 & -0.04 & 0.37 & 99 & Y\\
\hline
simplest\_design & 714 & Q & 0 & estimator & (Intercept) & -0.16 & 0.11 & -1.44 & 0.15 & -0.38 & 0.06 & 99 & Y\\
\hline
simplest\_design & 715 & Q & 0 & estimator & (Intercept) & 0.18 & 0.10 & 1.75 & 0.08 & -0.02 & 0.38 & 99 & Y\\
\hline
simplest\_design & 716 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.24 & 0.81 & -0.23 & 0.18 & 99 & Y\\
\hline
simplest\_design & 717 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & 0.02 & 0.98 & -0.18 & 0.18 & 99 & Y\\
\hline
simplest\_design & 718 & Q & 0 & estimator & (Intercept) & -0.07 & 0.11 & -0.69 & 0.49 & -0.28 & 0.14 & 99 & Y\\
\hline
simplest\_design & 719 & Q & 0 & estimator & (Intercept) & 0.11 & 0.09 & 1.30 & 0.20 & -0.06 & 0.29 & 99 & Y\\
\hline
simplest\_design & 720 & Q & 0 & estimator & (Intercept) & 0.21 & 0.10 & 1.98 & 0.05 & 0.00 & 0.41 & 99 & Y\\
\hline
simplest\_design & 721 & Q & 0 & estimator & (Intercept) & -0.10 & 0.11 & -0.88 & 0.38 & -0.32 & 0.12 & 99 & Y\\
\hline
simplest\_design & 722 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.38 & 0.71 & -0.15 & 0.22 & 99 & Y\\
\hline
simplest\_design & 723 & Q & 0 & estimator & (Intercept) & -0.05 & 0.09 & -0.54 & 0.59 & -0.22 & 0.13 & 99 & Y\\
\hline
simplest\_design & 724 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.23 & 0.82 & -0.19 & 0.15 & 99 & Y\\
\hline
simplest\_design & 725 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.54 & 0.59 & -0.25 & 0.14 & 99 & Y\\
\hline
simplest\_design & 726 & Q & 0 & estimator & (Intercept) & 0.07 & 0.11 & 0.66 & 0.51 & -0.14 & 0.29 & 99 & Y\\
\hline
simplest\_design & 727 & Q & 0 & estimator & (Intercept) & -0.21 & 0.11 & -1.90 & 0.06 & -0.42 & 0.01 & 99 & Y\\
\hline
simplest\_design & 728 & Q & 0 & estimator & (Intercept) & -0.01 & 0.11 & -0.09 & 0.93 & -0.23 & 0.22 & 99 & Y\\
\hline
simplest\_design & 729 & Q & 0 & estimator & (Intercept) & -0.14 & 0.10 & -1.44 & 0.15 & -0.34 & 0.05 & 99 & Y\\
\hline
simplest\_design & 730 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.12 & 0.27 & -0.08 & 0.30 & 99 & Y\\
\hline
simplest\_design & 731 & Q & 0 & estimator & (Intercept) & 0.27 & 0.09 & 2.87 & 0.01 & 0.08 & 0.46 & 99 & Y\\
\hline
simplest\_design & 732 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.26 & 0.79 & -0.17 & 0.22 & 99 & Y\\
\hline
simplest\_design & 733 & Q & 0 & estimator & (Intercept) & 0.13 & 0.09 & 1.47 & 0.15 & -0.05 & 0.30 & 99 & Y\\
\hline
simplest\_design & 734 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.39 & 0.70 & -0.14 & 0.21 & 99 & Y\\
\hline
simplest\_design & 735 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & -0.02 & 0.99 & -0.21 & 0.20 & 99 & Y\\
\hline
simplest\_design & 736 & Q & 0 & estimator & (Intercept) & -0.02 & 0.11 & -0.18 & 0.86 & -0.24 & 0.20 & 99 & Y\\
\hline
simplest\_design & 737 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.90 & 0.37 & -0.11 & 0.29 & 99 & Y\\
\hline
simplest\_design & 738 & Q & 0 & estimator & (Intercept) & 0.31 & 0.11 & 2.96 & 0.00 & 0.10 & 0.52 & 99 & Y\\
\hline
simplest\_design & 739 & Q & 0 & estimator & (Intercept) & -0.06 & 0.09 & -0.58 & 0.56 & -0.24 & 0.13 & 99 & Y\\
\hline
simplest\_design & 740 & Q & 0 & estimator & (Intercept) & -0.02 & 0.11 & -0.24 & 0.81 & -0.23 & 0.18 & 99 & Y\\
\hline
simplest\_design & 741 & Q & 0 & estimator & (Intercept) & -0.17 & 0.09 & -1.84 & 0.07 & -0.35 & 0.01 & 99 & Y\\
\hline
simplest\_design & 742 & Q & 0 & estimator & (Intercept) & 0.23 & 0.10 & 2.26 & 0.03 & 0.03 & 0.44 & 99 & Y\\
\hline
simplest\_design & 743 & Q & 0 & estimator & (Intercept) & -0.10 & 0.11 & -0.98 & 0.33 & -0.32 & 0.11 & 99 & Y\\
\hline
simplest\_design & 744 & Q & 0 & estimator & (Intercept) & -0.10 & 0.11 & -0.95 & 0.35 & -0.32 & 0.11 & 99 & Y\\
\hline
simplest\_design & 745 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.19 & 0.85 & -0.20 & 0.25 & 99 & Y\\
\hline
simplest\_design & 746 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.84 & 0.40 & -0.29 & 0.12 & 99 & Y\\
\hline
simplest\_design & 747 & Q & 0 & estimator & (Intercept) & -0.06 & 0.11 & -0.52 & 0.60 & -0.28 & 0.16 & 99 & Y\\
\hline
simplest\_design & 748 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.69 & 0.49 & -0.27 & 0.13 & 99 & Y\\
\hline
simplest\_design & 749 & Q & 0 & estimator & (Intercept) & 0.11 & 0.11 & 0.96 & 0.34 & -0.11 & 0.33 & 99 & Y\\
\hline
simplest\_design & 750 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.43 & 0.67 & -0.15 & 0.23 & 99 & Y\\
\hline
simplest\_design & 751 & Q & 0 & estimator & (Intercept) & 0.25 & 0.10 & 2.57 & 0.01 & 0.06 & 0.44 & 99 & Y\\
\hline
simplest\_design & 752 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.81 & 0.42 & -0.28 & 0.12 & 99 & Y\\
\hline
simplest\_design & 753 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.56 & 0.58 & -0.14 & 0.25 & 99 & Y\\
\hline
simplest\_design & 754 & Q & 0 & estimator & (Intercept) & 0.04 & 0.11 & 0.33 & 0.74 & -0.18 & 0.26 & 99 & Y\\
\hline
simplest\_design & 755 & Q & 0 & estimator & (Intercept) & -0.11 & 0.10 & -1.19 & 0.24 & -0.31 & 0.08 & 99 & Y\\
\hline
simplest\_design & 756 & Q & 0 & estimator & (Intercept) & 0.04 & 0.09 & 0.43 & 0.67 & -0.14 & 0.22 & 99 & Y\\
\hline
simplest\_design & 757 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.35 & 0.73 & -0.14 & 0.21 & 99 & Y\\
\hline
simplest\_design & 758 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.49 & 0.63 & -0.15 & 0.25 & 99 & Y\\
\hline
simplest\_design & 759 & Q & 0 & estimator & (Intercept) & 0.13 & 0.10 & 1.27 & 0.21 & -0.07 & 0.33 & 99 & Y\\
\hline
simplest\_design & 760 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.40 & 0.69 & -0.14 & 0.21 & 99 & Y\\
\hline
simplest\_design & 761 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.05 & 0.96 & -0.21 & 0.19 & 99 & Y\\
\hline
simplest\_design & 762 & Q & 0 & estimator & (Intercept) & 0.12 & 0.09 & 1.24 & 0.22 & -0.07 & 0.30 & 99 & Y\\
\hline
simplest\_design & 763 & Q & 0 & estimator & (Intercept) & -0.15 & 0.10 & -1.53 & 0.13 & -0.35 & 0.05 & 99 & Y\\
\hline
simplest\_design & 764 & Q & 0 & estimator & (Intercept) & -0.14 & 0.10 & -1.44 & 0.15 & -0.34 & 0.05 & 99 & Y\\
\hline
simplest\_design & 765 & Q & 0 & estimator & (Intercept) & 0.11 & 0.09 & 1.17 & 0.24 & -0.08 & 0.29 & 99 & Y\\
\hline
simplest\_design & 766 & Q & 0 & estimator & (Intercept) & -0.07 & 0.11 & -0.66 & 0.51 & -0.28 & 0.14 & 99 & Y\\
\hline
simplest\_design & 767 & Q & 0 & estimator & (Intercept) & 0.03 & 0.11 & 0.27 & 0.79 & -0.19 & 0.25 & 99 & Y\\
\hline
simplest\_design & 768 & Q & 0 & estimator & (Intercept) & -0.15 & 0.10 & -1.41 & 0.16 & -0.36 & 0.06 & 99 & Y\\
\hline
simplest\_design & 769 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.49 & 0.63 & -0.26 & 0.16 & 99 & Y\\
\hline
simplest\_design & 770 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & 0.03 & 0.97 & -0.19 & 0.20 & 99 & Y\\
\hline
simplest\_design & 771 & Q & 0 & estimator & (Intercept) & 0.05 & 0.11 & 0.41 & 0.68 & -0.18 & 0.27 & 99 & Y\\
\hline
simplest\_design & 772 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.13 & 0.90 & -0.19 & 0.22 & 99 & Y\\
\hline
simplest\_design & 773 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.52 & 0.60 & -0.14 & 0.24 & 99 & Y\\
\hline
simplest\_design & 774 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.57 & 0.57 & -0.27 & 0.15 & 99 & Y\\
\hline
simplest\_design & 775 & Q & 0 & estimator & (Intercept) & 0.06 & 0.09 & 0.62 & 0.53 & -0.13 & 0.24 & 99 & Y\\
\hline
simplest\_design & 776 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.14 & 0.89 & -0.18 & 0.20 & 99 & Y\\
\hline
simplest\_design & 777 & Q & 0 & estimator & (Intercept) & 0.07 & 0.09 & 0.76 & 0.45 & -0.11 & 0.25 & 99 & Y\\
\hline
simplest\_design & 778 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.64 & 0.52 & -0.14 & 0.27 & 99 & Y\\
\hline
simplest\_design & 779 & Q & 0 & estimator & (Intercept) & -0.23 & 0.11 & -2.19 & 0.03 & -0.44 & -0.02 & 99 & Y\\
\hline
simplest\_design & 780 & Q & 0 & estimator & (Intercept) & 0.04 & 0.11 & 0.41 & 0.68 & -0.17 & 0.26 & 99 & Y\\
\hline
simplest\_design & 781 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.77 & 0.44 & -0.29 & 0.13 & 99 & Y\\
\hline
simplest\_design & 782 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.76 & 0.45 & -0.29 & 0.13 & 99 & Y\\
\hline
simplest\_design & 783 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.43 & 0.67 & -0.25 & 0.16 & 99 & Y\\
\hline
simplest\_design & 784 & Q & 0 & estimator & (Intercept) & 0.14 & 0.09 & 1.53 & 0.13 & -0.04 & 0.31 & 99 & Y\\
\hline
simplest\_design & 785 & Q & 0 & estimator & (Intercept) & 0.01 & 0.09 & 0.08 & 0.93 & -0.17 & 0.18 & 99 & Y\\
\hline
simplest\_design & 786 & Q & 0 & estimator & (Intercept) & -0.16 & 0.09 & -1.64 & 0.10 & -0.34 & 0.03 & 99 & Y\\
\hline
simplest\_design & 787 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.71 & 0.48 & -0.28 & 0.13 & 99 & Y\\
\hline
simplest\_design & 788 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.06 & 0.95 & -0.19 & 0.18 & 99 & Y\\
\hline
simplest\_design & 789 & Q & 0 & estimator & (Intercept) & -0.04 & 0.11 & -0.41 & 0.69 & -0.25 & 0.17 & 99 & Y\\
\hline
simplest\_design & 790 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.51 & 0.61 & -0.13 & 0.23 & 99 & Y\\
\hline
simplest\_design & 791 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.81 & 0.42 & -0.25 & 0.11 & 99 & Y\\
\hline
simplest\_design & 792 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.50 & 0.62 & -0.15 & 0.25 & 99 & Y\\
\hline
simplest\_design & 793 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.78 & 0.44 & -0.26 & 0.11 & 99 & Y\\
\hline
simplest\_design & 794 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.22 & 0.83 & -0.22 & 0.18 & 99 & Y\\
\hline
simplest\_design & 795 & Q & 0 & estimator & (Intercept) & 0.02 & 0.11 & 0.21 & 0.83 & -0.19 & 0.24 & 99 & Y\\
\hline
simplest\_design & 796 & Q & 0 & estimator & (Intercept) & 0.16 & 0.10 & 1.64 & 0.10 & -0.03 & 0.34 & 99 & Y\\
\hline
simplest\_design & 797 & Q & 0 & estimator & (Intercept) & -0.05 & 0.09 & -0.56 & 0.58 & -0.22 & 0.12 & 99 & Y\\
\hline
simplest\_design & 798 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.53 & 0.60 & -0.14 & 0.24 & 99 & Y\\
\hline
simplest\_design & 799 & Q & 0 & estimator & (Intercept) & -0.18 & 0.11 & -1.70 & 0.09 & -0.39 & 0.03 & 99 & Y\\
\hline
simplest\_design & 800 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.75 & 0.45 & -0.26 & 0.12 & 99 & Y\\
\hline
simplest\_design & 801 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.91 & 0.37 & -0.11 & 0.29 & 99 & Y\\
\hline
simplest\_design & 802 & Q & 0 & estimator & (Intercept) & -0.19 & 0.09 & -2.09 & 0.04 & -0.37 & -0.01 & 99 & Y\\
\hline
simplest\_design & 803 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.84 & 0.40 & -0.12 & 0.29 & 99 & Y\\
\hline
simplest\_design & 804 & Q & 0 & estimator & (Intercept) & 0.06 & 0.09 & 0.70 & 0.48 & -0.12 & 0.25 & 99 & Y\\
\hline
simplest\_design & 805 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.12 & 0.91 & -0.20 & 0.18 & 99 & Y\\
\hline
simplest\_design & 806 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & -0.01 & 0.99 & -0.17 & 0.17 & 99 & Y\\
\hline
simplest\_design & 807 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.03 & 0.31 & -0.10 & 0.31 & 99 & Y\\
\hline
simplest\_design & 808 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.91 & 0.36 & -0.29 & 0.11 & 99 & Y\\
\hline
simplest\_design & 809 & Q & 0 & estimator & (Intercept) & 0.13 & 0.09 & 1.48 & 0.14 & -0.04 & 0.30 & 99 & Y\\
\hline
simplest\_design & 810 & Q & 0 & estimator & (Intercept) & 0.09 & 0.10 & 0.87 & 0.39 & -0.11 & 0.29 & 99 & Y\\
\hline
simplest\_design & 811 & Q & 0 & estimator & (Intercept) & 0.13 & 0.11 & 1.19 & 0.24 & -0.09 & 0.35 & 99 & Y\\
\hline
simplest\_design & 812 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.43 & 0.67 & -0.23 & 0.15 & 99 & Y\\
\hline
simplest\_design & 813 & Q & 0 & estimator & (Intercept) & 0.12 & 0.09 & 1.27 & 0.21 & -0.07 & 0.30 & 99 & Y\\
\hline
simplest\_design & 814 & Q & 0 & estimator & (Intercept) & 0.03 & 0.11 & 0.29 & 0.77 & -0.18 & 0.24 & 99 & Y\\
\hline
simplest\_design & 815 & Q & 0 & estimator & (Intercept) & 0.10 & 0.09 & 1.17 & 0.24 & -0.07 & 0.27 & 99 & Y\\
\hline
simplest\_design & 816 & Q & 0 & estimator & (Intercept) & 0.05 & 0.11 & 0.48 & 0.63 & -0.16 & 0.27 & 99 & Y\\
\hline
simplest\_design & 817 & Q & 0 & estimator & (Intercept) & -0.23 & 0.09 & -2.53 & 0.01 & -0.42 & -0.05 & 99 & Y\\
\hline
simplest\_design & 818 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.74 & 0.46 & -0.25 & 0.11 & 99 & Y\\
\hline
simplest\_design & 819 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.08 & 0.94 & -0.20 & 0.21 & 99 & Y\\
\hline
simplest\_design & 820 & Q & 0 & estimator & (Intercept) & -0.18 & 0.09 & -1.86 & 0.07 & -0.36 & 0.01 & 99 & Y\\
\hline
simplest\_design & 821 & Q & 0 & estimator & (Intercept) & -0.07 & 0.11 & -0.61 & 0.54 & -0.29 & 0.15 & 99 & Y\\
\hline
simplest\_design & 822 & Q & 0 & estimator & (Intercept) & 0.04 & 0.11 & 0.39 & 0.70 & -0.17 & 0.25 & 99 & Y\\
\hline
simplest\_design & 823 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.42 & 0.68 & -0.23 & 0.15 & 99 & Y\\
\hline
simplest\_design & 824 & Q & 0 & estimator & (Intercept) & -0.13 & 0.11 & -1.27 & 0.21 & -0.34 & 0.08 & 99 & Y\\
\hline
simplest\_design & 825 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.42 & 0.67 & -0.23 & 0.15 & 99 & Y\\
\hline
simplest\_design & 826 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.25 & 0.81 & -0.16 & 0.20 & 99 & Y\\
\hline
simplest\_design & 827 & Q & 0 & estimator & (Intercept) & -0.06 & 0.11 & -0.57 & 0.57 & -0.28 & 0.15 & 99 & Y\\
\hline
simplest\_design & 828 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.55 & 0.58 & -0.25 & 0.14 & 99 & Y\\
\hline
simplest\_design & 829 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.43 & 0.67 & -0.22 & 0.14 & 99 & Y\\
\hline
simplest\_design & 830 & Q & 0 & estimator & (Intercept) & -0.10 & 0.10 & -1.03 & 0.30 & -0.31 & 0.10 & 99 & Y\\
\hline
simplest\_design & 831 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.21 & 0.84 & -0.20 & 0.16 & 99 & Y\\
\hline
simplest\_design & 832 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.50 & 0.62 & -0.14 & 0.24 & 99 & Y\\
\hline
simplest\_design & 833 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.21 & 0.83 & -0.23 & 0.18 & 99 & Y\\
\hline
simplest\_design & 834 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.81 & 0.42 & -0.11 & 0.27 & 99 & Y\\
\hline
simplest\_design & 835 & Q & 0 & estimator & (Intercept) & -0.03 & 0.11 & -0.29 & 0.77 & -0.25 & 0.18 & 99 & Y\\
\hline
simplest\_design & 836 & Q & 0 & estimator & (Intercept) & -0.06 & 0.12 & -0.52 & 0.60 & -0.30 & 0.17 & 99 & Y\\
\hline
simplest\_design & 837 & Q & 0 & estimator & (Intercept) & 0.04 & 0.09 & 0.41 & 0.68 & -0.15 & 0.23 & 99 & Y\\
\hline
simplest\_design & 838 & Q & 0 & estimator & (Intercept) & -0.13 & 0.11 & -1.19 & 0.24 & -0.35 & 0.09 & 99 & Y\\
\hline
simplest\_design & 839 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.17 & 0.24 & -0.32 & 0.08 & 99 & Y\\
\hline
simplest\_design & 840 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.92 & 0.36 & -0.28 & 0.10 & 99 & Y\\
\hline
simplest\_design & 841 & Q & 0 & estimator & (Intercept) & 0.04 & 0.12 & 0.38 & 0.70 & -0.19 & 0.28 & 99 & Y\\
\hline
simplest\_design & 842 & Q & 0 & estimator & (Intercept) & -0.25 & 0.10 & -2.42 & 0.02 & -0.45 & -0.04 & 99 & Y\\
\hline
simplest\_design & 843 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.28 & 0.78 & -0.23 & 0.17 & 99 & Y\\
\hline
simplest\_design & 844 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.81 & 0.42 & -0.11 & 0.27 & 99 & Y\\
\hline
simplest\_design & 845 & Q & 0 & estimator & (Intercept) & -0.18 & 0.10 & -1.89 & 0.06 & -0.37 & 0.01 & 99 & Y\\
\hline
simplest\_design & 846 & Q & 0 & estimator & (Intercept) & -0.07 & 0.11 & -0.63 & 0.53 & -0.28 & 0.15 & 99 & Y\\
\hline
simplest\_design & 847 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.47 & 0.64 & -0.22 & 0.14 & 99 & Y\\
\hline
simplest\_design & 848 & Q & 0 & estimator & (Intercept) & -0.07 & 0.11 & -0.62 & 0.54 & -0.28 & 0.15 & 99 & Y\\
\hline
simplest\_design & 849 & Q & 0 & estimator & (Intercept) & 0.15 & 0.09 & 1.55 & 0.12 & -0.04 & 0.33 & 99 & Y\\
\hline
simplest\_design & 850 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.42 & 0.68 & -0.22 & 0.14 & 99 & Y\\
\hline
simplest\_design & 851 & Q & 0 & estimator & (Intercept) & -0.14 & 0.09 & -1.57 & 0.12 & -0.32 & 0.04 & 99 & Y\\
\hline
simplest\_design & 852 & Q & 0 & estimator & (Intercept) & 0.08 & 0.09 & 0.93 & 0.36 & -0.09 & 0.25 & 99 & Y\\
\hline
simplest\_design & 853 & Q & 0 & estimator & (Intercept) & -0.03 & 0.09 & -0.30 & 0.76 & -0.20 & 0.15 & 99 & Y\\
\hline
simplest\_design & 854 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.10 & 0.92 & -0.19 & 0.20 & 99 & Y\\
\hline
simplest\_design & 855 & Q & 0 & estimator & (Intercept) & 0.14 & 0.09 & 1.48 & 0.14 & -0.05 & 0.33 & 99 & Y\\
\hline
simplest\_design & 856 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.61 & 0.55 & -0.27 & 0.14 & 99 & Y\\
\hline
simplest\_design & 857 & Q & 0 & estimator & (Intercept) & 0.13 & 0.11 & 1.20 & 0.23 & -0.08 & 0.34 & 99 & Y\\
\hline
simplest\_design & 858 & Q & 0 & estimator & (Intercept) & -0.05 & 0.11 & -0.50 & 0.62 & -0.26 & 0.16 & 99 & Y\\
\hline
simplest\_design & 859 & Q & 0 & estimator & (Intercept) & -0.08 & 0.10 & -0.80 & 0.42 & -0.29 & 0.12 & 99 & Y\\
\hline
simplest\_design & 860 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.59 & 0.12 & -0.36 & 0.04 & 99 & Y\\
\hline
simplest\_design & 861 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.19 & 0.23 & -0.31 & 0.08 & 99 & Y\\
\hline
simplest\_design & 862 & Q & 0 & estimator & (Intercept) & 0.09 & 0.09 & 1.00 & 0.32 & -0.09 & 0.28 & 99 & Y\\
\hline
simplest\_design & 863 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.75 & 0.46 & -0.13 & 0.29 & 99 & Y\\
\hline
simplest\_design & 864 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.55 & 0.58 & -0.26 & 0.15 & 99 & Y\\
\hline
simplest\_design & 865 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.41 & 0.68 & -0.15 & 0.23 & 99 & Y\\
\hline
simplest\_design & 866 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.42 & 0.68 & -0.16 & 0.25 & 99 & Y\\
\hline
simplest\_design & 867 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.66 & 0.51 & -0.27 & 0.13 & 99 & Y\\
\hline
simplest\_design & 868 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.13 & 0.90 & -0.18 & 0.21 & 99 & Y\\
\hline
simplest\_design & 869 & Q & 0 & estimator & (Intercept) & 0.07 & 0.09 & 0.84 & 0.40 & -0.10 & 0.25 & 99 & Y\\
\hline
simplest\_design & 870 & Q & 0 & estimator & (Intercept) & -0.06 & 0.09 & -0.61 & 0.54 & -0.24 & 0.13 & 99 & Y\\
\hline
simplest\_design & 871 & Q & 0 & estimator & (Intercept) & -0.12 & 0.09 & -1.31 & 0.19 & -0.29 & 0.06 & 99 & Y\\
\hline
simplest\_design & 872 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.66 & 0.51 & -0.25 & 0.13 & 99 & Y\\
\hline
simplest\_design & 873 & Q & 0 & estimator & (Intercept) & -0.03 & 0.09 & -0.30 & 0.77 & -0.21 & 0.15 & 99 & Y\\
\hline
simplest\_design & 874 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.60 & 0.55 & -0.13 & 0.23 & 99 & Y\\
\hline
simplest\_design & 875 & Q & 0 & estimator & (Intercept) & -0.04 & 0.09 & -0.40 & 0.69 & -0.22 & 0.15 & 99 & Y\\
\hline
simplest\_design & 876 & Q & 0 & estimator & (Intercept) & 0.23 & 0.10 & 2.35 & 0.02 & 0.04 & 0.43 & 99 & Y\\
\hline
simplest\_design & 877 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.73 & 0.47 & -0.12 & 0.26 & 99 & Y\\
\hline
simplest\_design & 878 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.31 & 0.76 & -0.24 & 0.17 & 99 & Y\\
\hline
simplest\_design & 879 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.80 & 0.42 & -0.11 & 0.27 & 99 & Y\\
\hline
simplest\_design & 880 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.42 & 0.68 & -0.24 & 0.15 & 99 & Y\\
\hline
simplest\_design & 881 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.89 & 0.37 & -0.30 & 0.11 & 99 & Y\\
\hline
simplest\_design & 882 & Q & 0 & estimator & (Intercept) & -0.15 & 0.09 & -1.69 & 0.09 & -0.32 & 0.03 & 99 & Y\\
\hline
simplest\_design & 883 & Q & 0 & estimator & (Intercept) & 0.11 & 0.09 & 1.15 & 0.25 & -0.08 & 0.29 & 99 & Y\\
\hline
simplest\_design & 884 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.17 & 0.86 & -0.18 & 0.22 & 99 & Y\\
\hline
simplest\_design & 885 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.58 & 0.56 & -0.25 & 0.14 & 99 & Y\\
\hline
simplest\_design & 886 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.12 & 0.90 & -0.20 & 0.18 & 99 & Y\\
\hline
simplest\_design & 887 & Q & 0 & estimator & (Intercept) & -0.13 & 0.09 & -1.38 & 0.17 & -0.31 & 0.06 & 99 & Y\\
\hline
simplest\_design & 888 & Q & 0 & estimator & (Intercept) & 0.11 & 0.09 & 1.27 & 0.21 & -0.06 & 0.29 & 99 & Y\\
\hline
simplest\_design & 889 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.67 & 0.51 & -0.14 & 0.27 & 99 & Y\\
\hline
simplest\_design & 890 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.17 & 0.86 & -0.20 & 0.17 & 99 & Y\\
\hline
simplest\_design & 891 & Q & 0 & estimator & (Intercept) & -0.16 & 0.08 & -1.93 & 0.06 & -0.33 & 0.00 & 99 & Y\\
\hline
simplest\_design & 892 & Q & 0 & estimator & (Intercept) & 0.07 & 0.11 & 0.70 & 0.49 & -0.14 & 0.28 & 99 & Y\\
\hline
simplest\_design & 893 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.60 & 0.55 & -0.26 & 0.14 & 99 & Y\\
\hline
simplest\_design & 894 & Q & 0 & estimator & (Intercept) & 0.05 & 0.11 & 0.45 & 0.66 & -0.16 & 0.26 & 99 & Y\\
\hline
simplest\_design & 895 & Q & 0 & estimator & (Intercept) & 0.15 & 0.09 & 1.59 & 0.11 & -0.04 & 0.34 & 99 & Y\\
\hline
simplest\_design & 896 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.50 & 0.62 & -0.14 & 0.23 & 99 & Y\\
\hline
simplest\_design & 897 & Q & 0 & estimator & (Intercept) & -0.06 & 0.11 & -0.54 & 0.59 & -0.29 & 0.17 & 99 & Y\\
\hline
simplest\_design & 898 & Q & 0 & estimator & (Intercept) & -0.23 & 0.11 & -2.02 & 0.05 & -0.46 & 0.00 & 99 & Y\\
\hline
simplest\_design & 899 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.14 & 0.89 & -0.19 & 0.21 & 99 & Y\\
\hline
simplest\_design & 900 & Q & 0 & estimator & (Intercept) & -0.07 & 0.10 & -0.68 & 0.50 & -0.26 & 0.13 & 99 & Y\\
\hline
simplest\_design & 901 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & 0.04 & 0.97 & -0.17 & 0.18 & 99 & Y\\
\hline
simplest\_design & 902 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.20 & 0.84 & -0.17 & 0.20 & 99 & Y\\
\hline
simplest\_design & 903 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.76 & 0.45 & -0.26 & 0.11 & 99 & Y\\
\hline
simplest\_design & 904 & Q & 0 & estimator & (Intercept) & -0.10 & 0.10 & -1.08 & 0.28 & -0.30 & 0.09 & 99 & Y\\
\hline
simplest\_design & 905 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.17 & 0.86 & -0.18 & 0.21 & 99 & Y\\
\hline
simplest\_design & 906 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.41 & 0.68 & -0.24 & 0.16 & 99 & Y\\
\hline
simplest\_design & 907 & Q & 0 & estimator & (Intercept) & 0.04 & 0.09 & 0.48 & 0.63 & -0.14 & 0.23 & 99 & Y\\
\hline
simplest\_design & 908 & Q & 0 & estimator & (Intercept) & 0.07 & 0.10 & 0.67 & 0.51 & -0.13 & 0.27 & 99 & Y\\
\hline
simplest\_design & 909 & Q & 0 & estimator & (Intercept) & -0.11 & 0.11 & -1.04 & 0.30 & -0.33 & 0.10 & 99 & Y\\
\hline
simplest\_design & 910 & Q & 0 & estimator & (Intercept) & 0.10 & 0.09 & 1.11 & 0.27 & -0.08 & 0.29 & 99 & Y\\
\hline
simplest\_design & 911 & Q & 0 & estimator & (Intercept) & 0.11 & 0.11 & 0.99 & 0.32 & -0.11 & 0.32 & 99 & Y\\
\hline
simplest\_design & 912 & Q & 0 & estimator & (Intercept) & 0.18 & 0.10 & 1.90 & 0.06 & -0.01 & 0.37 & 99 & Y\\
\hline
simplest\_design & 913 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.26 & 0.79 & -0.16 & 0.21 & 99 & Y\\
\hline
simplest\_design & 914 & Q & 0 & estimator & (Intercept) & 0.04 & 0.11 & 0.38 & 0.70 & -0.17 & 0.25 & 99 & Y\\
\hline
simplest\_design & 915 & Q & 0 & estimator & (Intercept) & 0.08 & 0.09 & 0.96 & 0.34 & -0.09 & 0.25 & 99 & Y\\
\hline
simplest\_design & 916 & Q & 0 & estimator & (Intercept) & -0.12 & 0.09 & -1.31 & 0.19 & -0.31 & 0.06 & 99 & Y\\
\hline
simplest\_design & 917 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.24 & 0.81 & -0.22 & 0.17 & 99 & Y\\
\hline
simplest\_design & 918 & Q & 0 & estimator & (Intercept) & 0.02 & 0.09 & 0.27 & 0.79 & -0.16 & 0.21 & 99 & Y\\
\hline
simplest\_design & 919 & Q & 0 & estimator & (Intercept) & 0.00 & 0.10 & 0.02 & 0.98 & -0.20 & 0.20 & 99 & Y\\
\hline
simplest\_design & 920 & Q & 0 & estimator & (Intercept) & -0.14 & 0.10 & -1.40 & 0.16 & -0.33 & 0.06 & 99 & Y\\
\hline
simplest\_design & 921 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.62 & 0.53 & -0.14 & 0.26 & 99 & Y\\
\hline
simplest\_design & 922 & Q & 0 & estimator & (Intercept) & -0.13 & 0.11 & -1.19 & 0.24 & -0.35 & 0.09 & 99 & Y\\
\hline
simplest\_design & 923 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.35 & 0.73 & -0.15 & 0.22 & 99 & Y\\
\hline
simplest\_design & 924 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.30 & 0.77 & -0.17 & 0.23 & 99 & Y\\
\hline
simplest\_design & 925 & Q & 0 & estimator & (Intercept) & 0.05 & 0.10 & 0.46 & 0.65 & -0.16 & 0.25 & 99 & Y\\
\hline
simplest\_design & 926 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.86 & 0.39 & -0.29 & 0.12 & 99 & Y\\
\hline
simplest\_design & 927 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.07 & 0.29 & -0.28 & 0.08 & 99 & Y\\
\hline
simplest\_design & 928 & Q & 0 & estimator & (Intercept) & 0.11 & 0.11 & 0.97 & 0.33 & -0.11 & 0.33 & 99 & Y\\
\hline
simplest\_design & 929 & Q & 0 & estimator & (Intercept) & 0.15 & 0.09 & 1.55 & 0.12 & -0.04 & 0.34 & 99 & Y\\
\hline
simplest\_design & 930 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.74 & 0.46 & -0.30 & 0.14 & 99 & Y\\
\hline
simplest\_design & 931 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.09 & 0.93 & -0.20 & 0.18 & 99 & Y\\
\hline
simplest\_design & 932 & Q & 0 & estimator & (Intercept) & 0.18 & 0.10 & 1.79 & 0.08 & -0.02 & 0.38 & 99 & Y\\
\hline
simplest\_design & 933 & Q & 0 & estimator & (Intercept) & -0.10 & 0.09 & -1.08 & 0.28 & -0.28 & 0.08 & 99 & Y\\
\hline
simplest\_design & 934 & Q & 0 & estimator & (Intercept) & -0.11 & 0.10 & -1.15 & 0.25 & -0.30 & 0.08 & 99 & Y\\
\hline
simplest\_design & 935 & Q & 0 & estimator & (Intercept) & -0.19 & 0.10 & -1.88 & 0.06 & -0.40 & 0.01 & 99 & Y\\
\hline
simplest\_design & 936 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.16 & 0.25 & -0.08 & 0.31 & 99 & Y\\
\hline
simplest\_design & 937 & Q & 0 & estimator & (Intercept) & -0.13 & 0.09 & -1.42 & 0.16 & -0.31 & 0.05 & 99 & Y\\
\hline
simplest\_design & 938 & Q & 0 & estimator & (Intercept) & 0.20 & 0.10 & 2.06 & 0.04 & 0.01 & 0.40 & 99 & Y\\
\hline
simplest\_design & 939 & Q & 0 & estimator & (Intercept) & -0.01 & 0.11 & -0.10 & 0.92 & -0.23 & 0.20 & 99 & Y\\
\hline
simplest\_design & 940 & Q & 0 & estimator & (Intercept) & 0.08 & 0.10 & 0.83 & 0.41 & -0.11 & 0.27 & 99 & Y\\
\hline
simplest\_design & 941 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.22 & 0.83 & -0.23 & 0.18 & 99 & Y\\
\hline
simplest\_design & 942 & Q & 0 & estimator & (Intercept) & 0.20 & 0.10 & 2.11 & 0.04 & 0.01 & 0.39 & 99 & Y\\
\hline
simplest\_design & 943 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.25 & 0.80 & -0.21 & 0.17 & 99 & Y\\
\hline
simplest\_design & 944 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.31 & 0.75 & -0.18 & 0.24 & 99 & Y\\
\hline
simplest\_design & 945 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.06 & 0.95 & -0.20 & 0.19 & 99 & Y\\
\hline
simplest\_design & 946 & Q & 0 & estimator & (Intercept) & -0.03 & 0.11 & -0.28 & 0.78 & -0.24 & 0.18 & 99 & Y\\
\hline
simplest\_design & 947 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.29 & 0.20 & -0.34 & 0.07 & 99 & Y\\
\hline
simplest\_design & 948 & Q & 0 & estimator & (Intercept) & -0.07 & 0.09 & -0.73 & 0.47 & -0.25 & 0.12 & 99 & Y\\
\hline
simplest\_design & 949 & Q & 0 & estimator & (Intercept) & 0.18 & 0.10 & 1.76 & 0.08 & -0.02 & 0.37 & 99 & Y\\
\hline
simplest\_design & 950 & Q & 0 & estimator & (Intercept) & 0.01 & 0.10 & 0.11 & 0.91 & -0.19 & 0.22 & 99 & Y\\
\hline
simplest\_design & 951 & Q & 0 & estimator & (Intercept) & 0.10 & 0.11 & 0.92 & 0.36 & -0.12 & 0.33 & 99 & Y\\
\hline
simplest\_design & 952 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.41 & 0.68 & -0.23 & 0.15 & 99 & Y\\
\hline
simplest\_design & 953 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.10 & 0.92 & -0.18 & 0.17 & 99 & Y\\
\hline
simplest\_design & 954 & Q & 0 & estimator & (Intercept) & -0.05 & 0.10 & -0.47 & 0.64 & -0.24 & 0.15 & 99 & Y\\
\hline
simplest\_design & 955 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.62 & 0.54 & -0.14 & 0.26 & 99 & Y\\
\hline
simplest\_design & 956 & Q & 0 & estimator & (Intercept) & 0.04 & 0.11 & 0.37 & 0.71 & -0.17 & 0.25 & 99 & Y\\
\hline
simplest\_design & 957 & Q & 0 & estimator & (Intercept) & 0.09 & 0.11 & 0.80 & 0.42 & -0.13 & 0.30 & 99 & Y\\
\hline
simplest\_design & 958 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.08 & 0.28 & -0.09 & 0.30 & 99 & Y\\
\hline
simplest\_design & 959 & Q & 0 & estimator & (Intercept) & 0.15 & 0.10 & 1.51 & 0.14 & -0.05 & 0.35 & 99 & Y\\
\hline
simplest\_design & 960 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.55 & 0.59 & -0.14 & 0.24 & 99 & Y\\
\hline
simplest\_design & 961 & Q & 0 & estimator & (Intercept) & 0.16 & 0.10 & 1.61 & 0.11 & -0.04 & 0.35 & 99 & Y\\
\hline
simplest\_design & 962 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.15 & 0.25 & -0.33 & 0.09 & 99 & Y\\
\hline
simplest\_design & 963 & Q & 0 & estimator & (Intercept) & 0.05 & 0.09 & 0.60 & 0.55 & -0.12 & 0.23 & 99 & Y\\
\hline
simplest\_design & 964 & Q & 0 & estimator & (Intercept) & 0.12 & 0.10 & 1.13 & 0.26 & -0.09 & 0.32 & 99 & Y\\
\hline
simplest\_design & 965 & Q & 0 & estimator & (Intercept) & 0.07 & 0.11 & 0.68 & 0.50 & -0.14 & 0.28 & 99 & Y\\
\hline
simplest\_design & 966 & Q & 0 & estimator & (Intercept) & -0.02 & 0.09 & -0.16 & 0.87 & -0.20 & 0.17 & 99 & Y\\
\hline
simplest\_design & 967 & Q & 0 & estimator & (Intercept) & -0.04 & 0.10 & -0.45 & 0.65 & -0.24 & 0.15 & 99 & Y\\
\hline
simplest\_design & 968 & Q & 0 & estimator & (Intercept) & -0.09 & 0.09 & -1.00 & 0.32 & -0.27 & 0.09 & 99 & Y\\
\hline
simplest\_design & 969 & Q & 0 & estimator & (Intercept) & -0.06 & 0.09 & -0.73 & 0.47 & -0.23 & 0.11 & 99 & Y\\
\hline
simplest\_design & 970 & Q & 0 & estimator & (Intercept) & -0.07 & 0.11 & -0.65 & 0.52 & -0.28 & 0.14 & 99 & Y\\
\hline
simplest\_design & 971 & Q & 0 & estimator & (Intercept) & 0.24 & 0.10 & 2.42 & 0.02 & 0.04 & 0.44 & 99 & Y\\
\hline
simplest\_design & 972 & Q & 0 & estimator & (Intercept) & 0.16 & 0.10 & 1.71 & 0.09 & -0.03 & 0.35 & 99 & Y\\
\hline
simplest\_design & 973 & Q & 0 & estimator & (Intercept) & -0.01 & 0.10 & -0.08 & 0.94 & -0.20 & 0.18 & 99 & Y\\
\hline
simplest\_design & 974 & Q & 0 & estimator & (Intercept) & -0.06 & 0.10 & -0.61 & 0.54 & -0.25 & 0.13 & 99 & Y\\
\hline
simplest\_design & 975 & Q & 0 & estimator & (Intercept) & -0.13 & 0.10 & -1.37 & 0.17 & -0.32 & 0.06 & 99 & Y\\
\hline
simplest\_design & 976 & Q & 0 & estimator & (Intercept) & -0.12 & 0.10 & -1.13 & 0.26 & -0.32 & 0.09 & 99 & Y\\
\hline
simplest\_design & 977 & Q & 0 & estimator & (Intercept) & -0.01 & 0.09 & -0.16 & 0.87 & -0.20 & 0.17 & 99 & Y\\
\hline
simplest\_design & 978 & Q & 0 & estimator & (Intercept) & -0.09 & 0.10 & -0.91 & 0.36 & -0.29 & 0.11 & 99 & Y\\
\hline
simplest\_design & 979 & Q & 0 & estimator & (Intercept) & -0.12 & 0.11 & -1.12 & 0.27 & -0.33 & 0.09 & 99 & Y\\
\hline
simplest\_design & 980 & Q & 0 & estimator & (Intercept) & 0.11 & 0.10 & 1.10 & 0.27 & -0.09 & 0.32 & 99 & Y\\
\hline
simplest\_design & 981 & Q & 0 & estimator & (Intercept) & 0.00 & 0.09 & 0.05 & 0.96 & -0.18 & 0.19 & 99 & Y\\
\hline
simplest\_design & 982 & Q & 0 & estimator & (Intercept) & -0.02 & 0.10 & -0.20 & 0.84 & -0.21 & 0.17 & 99 & Y\\
\hline
simplest\_design & 983 & Q & 0 & estimator & (Intercept) & -0.03 & 0.10 & -0.28 & 0.78 & -0.23 & 0.17 & 99 & Y\\
\hline
simplest\_design & 984 & Q & 0 & estimator & (Intercept) & 0.10 & 0.09 & 1.14 & 0.26 & -0.08 & 0.29 & 99 & Y\\
\hline
simplest\_design & 985 & Q & 0 & estimator & (Intercept) & 0.12 & 0.11 & 1.06 & 0.29 & -0.10 & 0.33 & 99 & Y\\
\hline
simplest\_design & 986 & Q & 0 & estimator & (Intercept) & 0.10 & 0.10 & 1.06 & 0.29 & -0.09 & 0.30 & 99 & Y\\
\hline
simplest\_design & 987 & Q & 0 & estimator & (Intercept) & 0.06 & 0.08 & 0.66 & 0.51 & -0.11 & 0.22 & 99 & Y\\
\hline
simplest\_design & 988 & Q & 0 & estimator & (Intercept) & 0.03 & 0.10 & 0.34 & 0.74 & -0.16 & 0.23 & 99 & Y\\
\hline
simplest\_design & 989 & Q & 0 & estimator & (Intercept) & 0.09 & 0.09 & 0.93 & 0.36 & -0.10 & 0.27 & 99 & Y\\
\hline
simplest\_design & 990 & Q & 0 & estimator & (Intercept) & 0.06 & 0.10 & 0.61 & 0.54 & -0.14 & 0.26 & 99 & Y\\
\hline
simplest\_design & 991 & Q & 0 & estimator & (Intercept) & 0.11 & 0.11 & 1.01 & 0.32 & -0.11 & 0.32 & 99 & Y\\
\hline
simplest\_design & 992 & Q & 0 & estimator & (Intercept) & 0.02 & 0.10 & 0.23 & 0.82 & -0.18 & 0.23 & 99 & Y\\
\hline
simplest\_design & 993 & Q & 0 & estimator & (Intercept) & -0.03 & 0.09 & -0.27 & 0.78 & -0.21 & 0.16 & 99 & Y\\
\hline
simplest\_design & 994 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.32 & 0.75 & -0.16 & 0.22 & 99 & Y\\
\hline
simplest\_design & 995 & Q & 0 & estimator & (Intercept) & -0.14 & 0.10 & -1.46 & 0.15 & -0.33 & 0.05 & 99 & Y\\
\hline
simplest\_design & 996 & Q & 0 & estimator & (Intercept) & 0.01 & 0.11 & 0.10 & 0.92 & -0.21 & 0.23 & 99 & Y\\
\hline
simplest\_design & 997 & Q & 0 & estimator & (Intercept) & 0.21 & 0.10 & 2.09 & 0.04 & 0.01 & 0.41 & 99 & Y\\
\hline
simplest\_design & 998 & Q & 0 & estimator & (Intercept) & -0.19 & 0.11 & -1.81 & 0.07 & -0.40 & 0.02 & 99 & Y\\
\hline
simplest\_design & 999 & Q & 0 & estimator & (Intercept) & 0.14 & 0.10 & 1.33 & 0.19 & -0.07 & 0.35 & 99 & Y\\
\hline
simplest\_design & 1000 & Q & 0 & estimator & (Intercept) & 0.04 & 0.10 & 0.41 & 0.68 & -0.16 & 0.24 & 99 & Y\\
\hline
\end{tabular}
\end{frame}

\begin{frame}{The simplest possible design?: Diagnosis}
\protect\hypertarget{the-simplest-possible-design-diagnosis}{}
Once you have simulated many times you can ``diagnose''.

This is the next topic
\end{frame}

\hypertarget{design-declaration-diagnosis-redesign-workflow-diagnosis}{%
\subsection{Design declaration-diagnosis-redesign workflow:
Diagnosis}\label{design-declaration-diagnosis-redesign-workflow-diagnosis}}

\begin{frame}[fragile]{Diagnosis by hand}
\protect\hypertarget{diagnosis-by-hand}{}
Once you have simulated many times you can ``diagnose''.

For instance we can ask about bias: the average difference between the
estimand and the estimate:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{some\_runs }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{error =}\NormalTok{ estimate }\SpecialCharTok{{-}}\NormalTok{ estimand) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean\_estimate =} \FunctionTok{mean}\NormalTok{(estimate), }
            \AttributeTok{mean\_estimand =} \FunctionTok{mean}\NormalTok{(estimand), }
            \AttributeTok{bias =} \FunctionTok{mean}\NormalTok{(error)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits=} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r}
\hline
mean\_estimate & mean\_estimand & bias\\
\hline
0 & 0 & 0\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{The simplest possible design?}
\protect\hypertarget{the-simplest-possible-design-1}{}
\texttt{diagnose\_design()} does this in one step for a set of common
``diagnosands'':

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnosis }\OtherTok{\textless{}{-}}
\NormalTok{  simplest\_design }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{diagnose\_design}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{table}
\centering
\begin{tabular}{l|l|l|l|l|l|l|l|l}
\hline
Design & N Sims & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
simplest\_design & 500 & 0.00 & -0.00 & -0.00 & 0.10 & 0.10 & 0.05 & 0.95\\
\hline
 &  & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.01) & (0.01)\\
\hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}[fragile]{What is the diagnosis object?}
\protect\hypertarget{what-is-the-diagnosis-object}{}
The diagnosis object is also a list; of class \texttt{diagnosis}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(diagnosis)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "simulations_df"       "diagnosands_df"       "diagnosand_names"    
[4] "group_by_set"         "parameters_df"        "bootstrap_replicates"
[7] "bootstrap_sims"       "duration"            
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{class}\NormalTok{(diagnosis)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "diagnosis"
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{What is the diagnosis object?}
\protect\hypertarget{what-is-the-diagnosis-object-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnosis}\SpecialCharTok{$}\NormalTok{simulations\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|r|l|l|r|r|r|r|r|r|r|l}
\hline
design & sim\_ID & inquiry & estimand & estimator & term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
simplest\_design & 1 & Q & 0 & estimator & (Intercept) & 0.03 & 0.09 & 0.31 & 0.76 & -0.16 & 0.21 & 99 & Y\\
\hline
simplest\_design & 2 & Q & 0 & estimator & (Intercept) & 0.10 & 0.09 & 1.07 & 0.29 & -0.09 & 0.29 & 99 & Y\\
\hline
simplest\_design & 3 & Q & 0 & estimator & (Intercept) & -0.16 & 0.10 & -1.54 & 0.13 & -0.37 & 0.05 & 99 & Y\\
\hline
simplest\_design & 4 & Q & 0 & estimator & (Intercept) & -0.08 & 0.11 & -0.72 & 0.48 & -0.30 & 0.14 & 99 & Y\\
\hline
simplest\_design & 5 & Q & 0 & estimator & (Intercept) & -0.14 & 0.10 & -1.34 & 0.18 & -0.34 & 0.07 & 99 & Y\\
\hline
simplest\_design & 6 & Q & 0 & estimator & (Intercept) & -0.08 & 0.09 & -0.90 & 0.37 & -0.26 & 0.10 & 99 & Y\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{What is the diagnosis object?}
\protect\hypertarget{what-is-the-diagnosis-object-2}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnosis}\SpecialCharTok{$}\NormalTok{diagnosands\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r}
\hline
design & inquiry & estimator & outcome & term & mean\_estimand & se(mean\_estimand) & mean\_estimate & se(mean\_estimate) & bias & se(bias) & sd\_estimate & se(sd\_estimate) & rmse & se(rmse) & power & se(power) & coverage & se(coverage) & n\_sims\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & 0 & 0 & 0 & 0 & 0 & 0 & 0.1 & 0 & 0.1 & 0 & 0.05 & 0.01 & 0.95 & 0.01 & 500\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{What is the diagnosis object?}
\protect\hypertarget{what-is-the-diagnosis-object-3}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnosis}\SpecialCharTok{$}\NormalTok{bootstrap\_replicates }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{head}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|l|l|l|r|r|r|r|r|r|r}
\hline
design & bootstrap\_id & inquiry & estimator & outcome & term & mean\_estimand & mean\_estimate & bias & sd\_estimate & rmse & power & coverage\\
\hline
simplest\_design & 1 & Q & estimator & Y & (Intercept) & 0 & 0.00 & 0.00 & 0.1 & 0.10 & 0.05 & 0.95\\
\hline
simplest\_design & 2 & Q & estimator & Y & (Intercept) & 0 & -0.01 & -0.01 & 0.1 & 0.11 & 0.06 & 0.94\\
\hline
simplest\_design & 3 & Q & estimator & Y & (Intercept) & 0 & -0.01 & -0.01 & 0.1 & 0.10 & 0.05 & 0.95\\
\hline
simplest\_design & 4 & Q & estimator & Y & (Intercept) & 0 & -0.01 & -0.01 & 0.1 & 0.10 & 0.05 & 0.95\\
\hline
simplest\_design & 5 & Q & estimator & Y & (Intercept) & 0 & 0.00 & 0.00 & 0.1 & 0.10 & 0.05 & 0.95\\
\hline
simplest\_design & 6 & Q & estimator & Y & (Intercept) & 0 & 0.00 & 0.00 & 0.1 & 0.10 & 0.05 & 0.95\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Diagnosis: Bootstraps}
\protect\hypertarget{diagnosis-bootstraps}{}
\begin{itemize}
\item
  The bootstraps dataframe is produced by resampling from the
  simulations dataframe and producing a diagnosis dataframe from each
  resampling.
\item
  This lets us generate estimates of uncertainty around our diagnosands.
\item
  It can be controlled thus:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{diagnose\_design}\NormalTok{(}
\NormalTok{  ...,}
  \AttributeTok{bootstrap\_sims =} \DecValTok{100}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{After Diagnosis}
\protect\hypertarget{after-diagnosis}{}
It's reshapeable: as a tidy dataframe, ready for graphing

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnosis }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|r|r|r|r}
\hline
design & inquiry & estimator & outcome & term & diagnosand & estimate & std.error & conf.low & conf.high\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & mean\_estimand & 0.00 & 0.00 & 0.00 & 0.00\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & mean\_estimate & 0.00 & 0.00 & -0.01 & 0.00\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & bias & 0.00 & 0.00 & -0.01 & 0.00\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & sd\_estimate & 0.10 & 0.00 & 0.10 & 0.11\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & rmse & 0.10 & 0.00 & 0.10 & 0.11\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & power & 0.05 & 0.01 & 0.03 & 0.07\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & coverage & 0.95 & 0.01 & 0.93 & 0.97\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{After Diagnosis}
\protect\hypertarget{after-diagnosis-1}{}
It's reshapeable: as a tidy dataframe, ready for graphing

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnosis }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(estimate, diagnosand)) }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{geom\_errorbarh}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xmax =}\NormalTok{ conf.high, }\AttributeTok{xmin =}\NormalTok{ conf.low, }\AttributeTok{height =}\NormalTok{ .}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-40-1.pdf}
\end{frame}

\begin{frame}[fragile]{After Diagnosis: Tables}
\protect\hypertarget{after-diagnosis-tables}{}
Or turn into a formatted table:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnosis }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{reshape\_diagnosis}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l|l|l|l|l|l}
\hline
Design & Inquiry & Estimator & Outcome & Term & N Sims & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & 500 & 0.00 & -0.00 & -0.00 & 0.10 & 0.10 & 0.05 & 0.95\\
\hline
 &  &  &  &  &  & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.01) & (0.01)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Advanced Diagnosis: Variations}
\protect\hypertarget{advanced-diagnosis-variations}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{DeclareDesign}\SpecialCharTok{:::}\NormalTok{default\_diagnosands}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{    mean\_estimand }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(estimand)}
\NormalTok{    mean\_estimate }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(estimate)}
\NormalTok{    bias }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(estimate }\SpecialCharTok{{-}}\NormalTok{ estimand)}
\NormalTok{    sd\_estimate }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(estimate)}
\NormalTok{    rmse }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((estimate }\SpecialCharTok{{-}}\NormalTok{ estimand)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{    power }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(p.value }\SpecialCharTok{\textless{}=}\NormalTok{ alpha)}
\NormalTok{    coverage }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(estimand }\SpecialCharTok{\textless{}=}\NormalTok{ conf.high }\SpecialCharTok{\&}\NormalTok{ estimand }\SpecialCharTok{\textgreater{}=}\NormalTok{ conf.low)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Advanced Diagnosis: Other diagnosands}
\protect\hypertarget{advanced-diagnosis-other-diagnosands}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{    mean\_se }\OtherTok{=} \FunctionTok{mean}\NormalTok{(std.error)}
\NormalTok{    type\_s\_rate }\OtherTok{=} \FunctionTok{mean}\NormalTok{((}\FunctionTok{sign}\NormalTok{(estimate) }\SpecialCharTok{!=} \FunctionTok{sign}\NormalTok{(estimand))[p.value }\SpecialCharTok{\textless{}=}\NormalTok{ alpha])}
\NormalTok{    exaggeration\_ratio }\OtherTok{=} \FunctionTok{mean}\NormalTok{((estimate}\SpecialCharTok{/}\NormalTok{estimand)[p.value }\SpecialCharTok{\textless{}=}\NormalTok{ alpha])}
\NormalTok{    var\_estimate }\OtherTok{=} \FunctionTok{pop.var}\NormalTok{(estimate)}
\NormalTok{    mean\_var\_hat }\OtherTok{=} \FunctionTok{mean}\NormalTok{(std.error}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{    prop\_pos\_sig }\OtherTok{=}\NormalTok{ estimate }\SpecialCharTok{\textgreater{}} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ p.value }\SpecialCharTok{\textless{}=}\NormalTok{ alpha}
\NormalTok{    mean\_ci\_length }\OtherTok{=} \FunctionTok{mean}\NormalTok{(conf.high }\SpecialCharTok{{-}}\NormalTok{ conf.low)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Advanced Diagnosis: Custom diagnosands}
\protect\hypertarget{advanced-diagnosis-custom-diagnosands}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_diagnosands }\OtherTok{\textless{}{-}}
  \FunctionTok{declare\_diagnosands}\NormalTok{(}\AttributeTok{median\_bias =} \FunctionTok{median}\NormalTok{(estimate }\SpecialCharTok{{-}}\NormalTok{ estimand))}

\FunctionTok{diagnose\_design}\NormalTok{(simplest\_design, }\AttributeTok{diagnosands =}\NormalTok{ my\_diagnosands, }\AttributeTok{sims =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{reshape\_diagnosis}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l}
\hline
Design & Inquiry & Estimator & Outcome & Term & N Sims & Median Bias\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & 10 & -0.02\\
\hline
 &  &  &  &  &  & (0.04)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Advanced Diagnosis: Adding diagnosands to a
design}
\protect\hypertarget{advanced-diagnosis-adding-diagnosands-to-a-design}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simplest\_design }\OtherTok{\textless{}{-}} 
  \FunctionTok{set\_diagnosands}\NormalTok{(simplest\_design, my\_diagnosands)}

\NormalTok{simplest\_design }\SpecialCharTok{|\textgreater{}} \FunctionTok{diagnose\_design}\NormalTok{(}\AttributeTok{sims =} \DecValTok{10}\NormalTok{)}\SpecialCharTok{|\textgreater{}}
  \FunctionTok{reshape\_diagnosis}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l}
\hline
Design & Inquiry & Estimator & Outcome & Term & N Sims & Median Bias\\
\hline
simplest\_design & Q & estimator & Y & (Intercept) & 10 & -0.01\\
\hline
 &  &  &  &  &  & (0.04)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Advanced Diagnosis: Diagnosing multiple designs}
\protect\hypertarget{advanced-diagnosis-diagnosing-multiple-designs}{}
You can diagnose multiple designs or a list of designs

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{list}\NormalTok{(}\AttributeTok{dum =}\NormalTok{ simplest\_design, }\AttributeTok{dee =}\NormalTok{ simplest\_design) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{diagnose\_design}\NormalTok{(}\AttributeTok{sims =} \DecValTok{5}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{reshape\_diagnosis}\NormalTok{() }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l}
\hline
Design & Inquiry & Estimator & Outcome & Term & N Sims & Median Bias\\
\hline
dum & Q & estimator & Y & (Intercept) & 5 & -0.08\\
\hline
 &  &  &  &  &  & (0.08)\\
\hline
dee & Q & estimator & Y & (Intercept) & 5 & -0.08\\
\hline
 &  &  &  &  &  & (0.08)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Advanced Diagnosis: Diagnosing in groups}
\protect\hypertarget{advanced-diagnosis-diagnosing-in-groups}{}
You can partition the simulations data frame into groups before
calculating diagnosands.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grouped\_diagnosis }\OtherTok{\textless{}{-}} 
  
\NormalTok{  simplest\_design }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{diagnose\_design}\NormalTok{(}
    \AttributeTok{make\_groups =} \FunctionTok{vars}\NormalTok{(}\AttributeTok{significant =}\NormalTok{ p.value }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{),}
    \AttributeTok{sims =} \DecValTok{500}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l|l|l}
\hline
Design & Significant & N Sims & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
design\_1 & FALSE & 474 & 0.00 & -0.00 & -0.00 & 0.09 & 0.09 & 0.00 & 1.00\\
\hline
 &  &  & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
design\_1 & TRUE & 26 & 0.00 & -0.02 & -0.02 & 0.23 & 0.23 & 1.00 & 0.00\\
\hline
 &  &  & (0.00) & (0.04) & (0.04) & (0.01) & (0.01) & (0.00) & (0.00)\\
\hline
\end{tabular}

Note especially the mean estimate, the power, the coverage, the RMSE,
and the bias. (Bias is not large because we have both under and over
estimates)
\end{frame}

\begin{frame}[fragile]{Significance filter}
\protect\hypertarget{significance-filter}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grouped\_diagnosis}\SpecialCharTok{$}\NormalTok{simulations\_df }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(estimate, p.value, }\AttributeTok{color =}\NormalTok{ significant)) }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-50-1.pdf}
\end{frame}

\begin{frame}[fragile]{Advanced Diagnosis: Multistage simulation}
\protect\hypertarget{advanced-diagnosis-multistage-simulation}{}
\begin{itemize}
\tightlist
\item
  Usually a design simulation simulates ``from the top'': going from the
  beginning to the end of the design in each run and repeating
\item
  But sometimes you might want to follow a tree like structure and
  simulate different steps a different number of times
\end{itemize}

Consider for instance this sampling design:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sampling\_design }\OtherTok{\textless{}{-}} 
  
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{500}\NormalTok{, }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{sd =} \DecValTok{10}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q =} \FunctionTok{mean}\NormalTok{(Y)) }\SpecialCharTok{+}
  \FunctionTok{declare\_sampling}\NormalTok{(}\AttributeTok{S =} \FunctionTok{complete\_rs}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{n =} \DecValTok{100}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Advanced Diagnosis: Multistage simulation}
\protect\hypertarget{advanced-diagnosis-multistage-simulation-1}{}
Compare these two diagnoses:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnosis\_1 }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(sampling\_design, }\AttributeTok{sims =} \FunctionTok{c}\NormalTok{(}\DecValTok{5000}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)) }
\NormalTok{diagnosis\_2 }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(sampling\_design, }\AttributeTok{sims =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5000}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l|l}
\hline
diagnosis & N Sims & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
diagnosis\_1 & 5000 & 0.00 & 0.00 & -0.00 & 1.01 & 0.90 & 0.05 & 0.97\\
\hline
diagnosis\_1 &  & (0.01) & (0.01) & (0.01) & (0.01) & (0.01) & (0.00) & (0.00)\\
\hline
diagnosis\_2 & 5000 & 0.22 & 0.22 & -0.00 & 0.91 & 0.91 & 0.03 & 0.97\\
\hline
diagnosis\_2 &  & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Spotting design problems with diagnosis}
\protect\hypertarget{spotting-design-problems-with-diagnosis}{}
Diagnosis alerts to problems in a design. Consider the following simple
alternative design.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simplest\_design\_2 }\OtherTok{\textless{}{-}} 
  
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{100}\NormalTok{, }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q =} \FunctionTok{mean}\NormalTok{(Y)) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Here we define the inquiry as the average \(Y\), but otherwise things
stay the same.

What do we think of this design?
\end{frame}

\begin{frame}{Spotting design problems with diagnosis}
\protect\hypertarget{spotting-design-problems-with-diagnosis-1}{}
Here is the diagnosis

\begin{tabular}{l|l|l|l|l|l|l|l|l}
\hline
Design & N Sims & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
simplest\_design\_2 & 500 & -0.00 & -0.00 & 0.00 & 0.10 & 0.00 & 0.04 & 1.00\\
\hline
 &  & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.01) & (0.00)\\
\hline
\end{tabular}

\begin{itemize}
\tightlist
\item
  Why is power 5\%? is that OK?
\item
  Why is coverage so high? is that OK?
\item
  Why is the RMSE 0 but the mean standard error \textgreater{} 0? is
  that OK?

  \begin{itemize}
  \tightlist
  \item
    Is it because the RMSE is too low?
  \item
    Or the standard error is too large?
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{It depends on the inquiry}
\protect\hypertarget{it-depends-on-the-inquiry}{}
\begin{itemize}
\tightlist
\item
  If we are really interested in the sample average then our standard
  error is too low.
\item
  If we are really interested in the population average then our inquiry
  is badly defined.
\end{itemize}
\end{frame}

\hypertarget{design-declaration-diagnosis-redesign-workflow-redesign}{%
\subsection{Design declaration-diagnosis-redesign workflow:
Redesign}\label{design-declaration-diagnosis-redesign-workflow-redesign}}

\begin{frame}[fragile]{Redesign}
\protect\hypertarget{redesign-1}{}
Redesign is the process of taking a design and modifying it in some way.

There are a few ways to do this:

\begin{enumerate}
\tightlist
\item
  Just make a new design using modified code
\item
  Take a design and alter some steps using \texttt{replace\_step},
  \texttt{insert\_step} or \texttt{delete\_step}
\item
  Modify a design \emph{parameter} using \texttt{redesign}
\end{enumerate}

we will focus on the third approach
\end{frame}

\begin{frame}[fragile]{Redesign}
\protect\hypertarget{redesign-2}{}
\begin{itemize}
\item
  A design parameter is a modifiable quantity of a design.
\item
  These quantities are objects that were in your global environment when
  you made your design, get referred to explicitly in your design, and
  got scooped up when the design was formed.
\item
  In our simplest design above we had a fixed \texttt{N}, but we could
  make \texttt{N} a modifiable quantity like this:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}

\NormalTok{simplest\_design\_N }\OtherTok{\textless{}{-}} 
  
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Redesign}
\protect\hypertarget{redesign-3}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}

\NormalTok{simplest\_design\_N }\OtherTok{\textless{}{-}} 
  
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that \texttt{N} is defined in memory; and it gets called in one of
the steps. It has now become a parameter of the design and it can be
modified using redesign.
\end{frame}

\begin{frame}[fragile]{Simple Redesign}
\protect\hypertarget{simple-redesign}{}
Here is a version of the design with \texttt{N\ =\ 200}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_200 }\OtherTok{\textless{}{-}}\NormalTok{ simplest\_design\_N }\SpecialCharTok{|\textgreater{}} \FunctionTok{redesign}\NormalTok{(}\AttributeTok{N =} \DecValTok{200}\NormalTok{)}
  
\NormalTok{design\_200 }\SpecialCharTok{|\textgreater{}} \FunctionTok{draw\_data}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{nrow}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 200
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Redesigning to a list}
\protect\hypertarget{redesigning-to-a-list}{}
Here is a list of three different designs with different \emph{N}s.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_Ns }\OtherTok{\textless{}{-}}\NormalTok{ simplest\_design\_N }\SpecialCharTok{|\textgreater{}} \FunctionTok{redesign}\NormalTok{(}\AttributeTok{N =} \FunctionTok{c}\NormalTok{(}\DecValTok{200}\NormalTok{, }\DecValTok{400}\NormalTok{, }\DecValTok{800}\NormalTok{))}

\NormalTok{design\_Ns }\SpecialCharTok{|\textgreater{}} \FunctionTok{lapply}\NormalTok{(draw\_data) }\SpecialCharTok{|\textgreater{}} \FunctionTok{lapply}\NormalTok{(nrow)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$design_1
[1] 200

$design_2
[1] 400

$design_3
[1] 800
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Redesigning to a list}
\protect\hypertarget{redesigning-to-a-list-1}{}
The good thing here is that it is now easy to diagnose over multiple
designs and compare diagnoses. The parameter names then end up in the
\texttt{diagnosis\_df}

Consider this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{m }\OtherTok{\textless{}{-}} \DecValTok{0}

\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N, m)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q =}\NormalTok{ m) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

Then:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{designs }\OtherTok{\textless{}{-}}  \FunctionTok{redesign}\NormalTok{(design, }\AttributeTok{N =} \FunctionTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{300}\NormalTok{), }\AttributeTok{m =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{1}\NormalTok{, .}\DecValTok{2}\NormalTok{))}
  
\NormalTok{designs }\SpecialCharTok{|\textgreater{}} \FunctionTok{diagnose\_design}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{tidy}\NormalTok{() }
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Redesigning to a list}
\protect\hypertarget{redesigning-to-a-list-2}{}
Output:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{designs }\SpecialCharTok{|\textgreater{}} \FunctionTok{diagnose\_design}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{tidy}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|l|r|r|r|r}
\hline
N & m & diagnosand & estimate & std.error & conf.low & conf.high\\
\hline
100 & 0.0 & mean\_estimand & 0.0 & 0 & 0.00 & 0.00\\
\hline
100 & 0.0 & mean\_estimate & 0.0 & 0 & -0.01 & 0.01\\
\hline
200 & 0.0 & mean\_estimand & 0.0 & 0 & 0.00 & 0.00\\
\hline
200 & 0.0 & mean\_estimate & 0.0 & 0 & -0.01 & 0.00\\
\hline
200 & 0.1 & mean\_estimand & 0.1 & 0 & 0.10 & 0.10\\
\hline
200 & 0.1 & mean\_estimate & 0.1 & 0 & 0.09 & 0.10\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Redesigning to a list}
\protect\hypertarget{redesigning-to-a-list-3}{}
Graphing after redesign is especially easy:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{designs }\SpecialCharTok{|\textgreater{}} \FunctionTok{diagnose\_design}\NormalTok{() }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(diagnosand }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"power"}\NormalTok{, }\StringTok{"rmse"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(N, estimate, }\AttributeTok{color =} \FunctionTok{factor}\NormalTok{(m))) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{diagnosand)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-66-1.pdf}

}

\caption{Power depends on N and m, rmse depends on N only}

\end{figure}
\end{frame}

\begin{frame}[fragile]{Redesign with vector arguments}
\protect\hypertarget{redesign-with-vector-arguments}{}
When redesigning with arguments that are vectors, use \texttt{list()} in
redesign, with each list item representing a design you wish to create

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob\_each }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(.}\DecValTok{1}\NormalTok{, .}\DecValTok{5}\NormalTok{, .}\DecValTok{4}\NormalTok{)}

\NormalTok{design\_multi  }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{complete\_ra}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{prob\_each =}\NormalTok{ prob\_each))}

\DocumentationTok{\#\# returns two designs}

\NormalTok{designs }\OtherTok{\textless{}{-}}\NormalTok{ design\_multi }\SpecialCharTok{|\textgreater{}} \FunctionTok{redesign}\NormalTok{(}\AttributeTok{prob\_each =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(.}\DecValTok{2}\NormalTok{, .}\DecValTok{5}\NormalTok{, .}\DecValTok{3}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{5}\NormalTok{, .}\DecValTok{5}\NormalTok{)))}
  
\NormalTok{designs }\SpecialCharTok{|\textgreater{}} \FunctionTok{lapply}\NormalTok{(draw\_data)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Redesign warnings}
\protect\hypertarget{redesign-warnings}{}
A parameter has to be called correctly. And you get no warning if you
misname.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simplest\_design\_N  }\SpecialCharTok{|\textgreater{}} \FunctionTok{redesign}\NormalTok{(}\AttributeTok{n =} \DecValTok{200}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \FunctionTok{draw\_data}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{nrow}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 100
\end{verbatim}

why not 200?
\end{frame}

\begin{frame}[fragile]{Redesign warnings}
\protect\hypertarget{redesign-warnings-1}{}
A parameter has to be called explicitly

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}

\NormalTok{my\_N }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(}\AttributeTok{n =}\NormalTok{ N) n}

\NormalTok{simplest\_design\_N2 }\OtherTok{\textless{}{-}} 
  
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \FunctionTok{my\_N}\NormalTok{(), }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{)}

\NormalTok{simplest\_design\_N2 }\SpecialCharTok{|\textgreater{}} \FunctionTok{redesign}\NormalTok{(}\AttributeTok{N =} \DecValTok{200}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \FunctionTok{draw\_data}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{nrow}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 100
\end{verbatim}

why not 200?
\end{frame}

\begin{frame}[fragile]{Redesign warnings}
\protect\hypertarget{redesign-warnings-2}{}
A parameter has to be called explicitly

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}

\NormalTok{my\_N }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(}\AttributeTok{n =}\NormalTok{ N) n}

\NormalTok{simplest\_design\_N2 }\OtherTok{\textless{}{-}} 
  
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \FunctionTok{my\_N}\NormalTok{(N), }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{)}

\NormalTok{simplest\_design\_N2 }\SpecialCharTok{|\textgreater{}} \FunctionTok{redesign}\NormalTok{(}\AttributeTok{N =} \DecValTok{200}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \FunctionTok{draw\_data}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{nrow}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 200
\end{verbatim}

OK
\end{frame}

\begin{frame}[fragile]{Redesign with a function}
\protect\hypertarget{redesign-with-a-function}{}
Here is an example of redesigning where the ``parameter'' is a function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_N }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n, }\AttributeTok{factor =} \FloatTok{1.31}\NormalTok{) n}\SpecialCharTok{*}\NormalTok{factor}

\NormalTok{simplest\_design\_N2 }\SpecialCharTok{|\textgreater{}} \FunctionTok{redesign}\NormalTok{(}\AttributeTok{my\_N =}\NormalTok{ new\_N) }\SpecialCharTok{|\textgreater{}} \FunctionTok{draw\_data}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{nrow}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 131
\end{verbatim}
\end{frame}

\hypertarget{using-a-design}{%
\subsection{Using a design}\label{using-a-design}}

\begin{frame}[fragile]{Using a design}
What can you do with a design once you have it?

We will start with a very simple experimental design (more on the
components of this later)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OtherTok{\textless{}{-}}\DecValTok{1}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{U =} \FunctionTok{rnorm}\NormalTok{(N), }\FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ U)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{simple\_ra}\NormalTok{(N), }\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }\AttributeTok{.method =}\NormalTok{ lm\_robust)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Make data from the design}
\protect\hypertarget{make-data-from-the-design}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{draw\_data}\NormalTok{(design)}

\NormalTok{data }\SpecialCharTok{|\textgreater{}} \FunctionTok{head}\NormalTok{ () }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r}
\hline
ID & U & Y\_Z\_0 & Y\_Z\_1 & Z & Y\\
\hline
001 & 0.8939241 & 0.8939241 & 1.8939241 & 1 & 1.8939241\\
\hline
002 & 1.3350334 & 1.3350334 & 2.3350334 & 1 & 2.3350334\\
\hline
003 & 0.8329075 & 0.8329075 & 1.8329075 & 1 & 1.8329075\\
\hline
004 & -0.2886946 & -0.2886946 & 0.7113054 & 0 & -0.2886946\\
\hline
005 & -0.3062044 & -0.3062044 & 0.6937956 & 1 & 0.6937956\\
\hline
006 & 0.6443779 & 0.6443779 & 1.6443779 & 1 & 1.6443779\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Make data from the design}
\protect\hypertarget{make-data-from-the-design-1}{}
Play with the data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ data) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
(Intercept) & -0.21 & 0.14 & -1.50 & 0.14 & -0.48 & 0.07 & 98 & Y\\
\hline
Z & 1.27 & 0.19 & 6.69 & 0.00 & 0.89 & 1.65 & 98 & Y\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Draw estimands}
\protect\hypertarget{draw-estimands}{}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{draw\_estimands}\NormalTok{(design) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in UseMethod("tidy"): no applicable method for 'tidy' applied to an object of class "data.frame"
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Draw estimates}
\protect\hypertarget{draw-estimates}{}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{draw\_estimates}\NormalTok{(design) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in UseMethod("tidy"): no applicable method for 'tidy' applied to an object of class "data.frame"
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Get estimates}
\protect\hypertarget{get-estimates}{}
Using your actual data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get\_estimates}\NormalTok{(design, data) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in UseMethod("tidy"): no applicable method for 'tidy' applied to an object of class "data.frame"
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Simulate design}
\protect\hypertarget{simulate-design}{}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{simulate\_design}\NormalTok{(design, }\AttributeTok{sims =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|r|l|l|r|r|r|r|r|r|r|l}
\hline
design & sim\_ID & inquiry & estimand & estimator & term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
design & 1 & ate & 1 & estimator & Z & 1.50 & 0.19 & 7.92 & 0 & 1.12 & 1.88 & 98 & Y\\
\hline
design & 2 & ate & 1 & estimator & Z & 1.27 & 0.19 & 6.64 & 0 & 0.89 & 1.65 & 98 & Y\\
\hline
design & 3 & ate & 1 & estimator & Z & 0.87 & 0.19 & 4.58 & 0 & 0.49 & 1.24 & 98 & Y\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Diagnose design}
\protect\hypertarget{diagnose-design}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{diagnose\_design}\NormalTok{(}\AttributeTok{sims =} \DecValTok{100}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l}
\hline
Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
1.00 & 0.00 & 0.19 & 0.19 & 1.00 & 0.95\\
\hline
(0.02) & (0.02) & (0.01) & (0.01) & (0.00) & (0.02)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Redesign}
\protect\hypertarget{redesign-4}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_design }\OtherTok{\textless{}{-}}
  
\NormalTok{  design }\SpecialCharTok{|\textgreater{}} \FunctionTok{redesign}\NormalTok{(}\AttributeTok{b =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Modify any arguments that are explicitly called on by design steps.
\item
  Or add, remove, or replace steps
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Compare designs}
\protect\hypertarget{compare-designs}{}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{redesign}\NormalTok{(design, }\AttributeTok{N =} \DecValTok{50}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  
  \FunctionTok{compare\_diagnoses}\NormalTok{(design) }
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r}
\hline
diagnosand & mean\_1 & mean\_2 & mean\_difference & conf.low & conf.high\\
\hline
mean\_estimand & 0.50 & 0.50 & 0.00 & 0.00 & 0.00\\
\hline
mean\_estimate & 0.48 & 0.50 & 0.02 & -0.01 & 0.04\\
\hline
bias & -0.02 & 0.00 & 0.02 & -0.01 & 0.04\\
\hline
sd\_estimate & 0.28 & 0.20 & -0.08 & -0.10 & -0.06\\
\hline
rmse & 0.28 & 0.20 & -0.08 & -0.10 & -0.06\\
\hline
power & 0.38 & 0.71 & 0.32 & 0.26 & 0.37\\
\hline
coverage & 0.97 & 0.96 & -0.01 & -0.04 & 0.01\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Illustration of power calculation}
\protect\hypertarget{illustration-of-power-calculation}{}
Recall?: The power of a design is the \emph{probability} that you will
reject a null hypothesis

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{b }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}

\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }
    \AttributeTok{U =} \FunctionTok{rnorm}\NormalTok{(N),}
    \FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ U)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{simple\_ra}\NormalTok{(N),}
                     \AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }\AttributeTok{.method =}\NormalTok{ lm\_robust)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{``Run'' the design once}
\protect\hypertarget{run-the-design-once}{}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{run\_design}\NormalTok{(design)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{Summary of a single 'run' of the design}
\centering
\begin{tabular}[t]{l|r|l|l|r|r|r|r|r|r|r|l}
\hline
inquiry & estimand & estimator & term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
ate & 0.5 & estimator & Z & 0.57 & 0.2 & 2.88 & 0 & 0.18 & 0.96 & 98 & Y\\
\hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}[fragile]{Run it many times}
\protect\hypertarget{run-it-many-times}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims\_1 }\OtherTok{\textless{}{-}} \FunctionTok{simulate\_design}\NormalTok{(design) }

\NormalTok{sims\_1 }\SpecialCharTok{|\textgreater{}} \FunctionTok{select}\NormalTok{(sim\_ID, estimate, p.value)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r}
\hline
sim\_ID & estimate & p.value\\
\hline
1 & 0.81 & 0.00\\
\hline
2 & 0.40 & 0.04\\
\hline
3 & 0.88 & 0.00\\
\hline
4 & 0.72 & 0.00\\
\hline
5 & 0.38 & 0.05\\
\hline
6 & 0.44 & 0.02\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Power is mass of the sampling distribution of
decisions under the model}
\protect\hypertarget{power-is-mass-of-the-sampling-distribution-of-decisions-under-the-model}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims\_1 }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(p.value)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ .}\DecValTok{05}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-89-1.pdf}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-91-1.pdf}
\end{frame}

\begin{frame}[fragile]{Design diagnosis does it all (over multiple
designs)}
\protect\hypertarget{design-diagnosis-does-it-all-over-multiple-designs}{}
\begin{Shaded}
\begin{Highlighting}[]
  \FunctionTok{diagnose\_design}\NormalTok{(design)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l}
\hline
Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
0.50 & 0.00 & 0.20 & 0.20 & 0.70 & 0.95\\
\hline
(0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Design diagnosis does it all}
\protect\hypertarget{design-diagnosis-does-it-all}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{redesign}\NormalTok{(}\AttributeTok{b =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{diagnose\_design}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l}
\hline
b & Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
0 & -0.00 & -0.00 & 0.20 & 0.20 & 0.05 & 0.95\\
\hline
 & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
0.25 & 0.25 & -0.00 & 0.20 & 0.20 & 0.23 & 0.95\\
\hline
 & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
0.5 & 0.50 & 0.00 & 0.20 & 0.20 & 0.70 & 0.95\\
\hline
 & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
1 & 1.00 & 0.00 & 0.20 & 0.20 & 1.00 & 0.95\\
\hline
 & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
\end{tabular}
\end{frame}

\hypertarget{declaration-a-deeper-dive-reference}{%
\subsection{Declaration a deeper dive
(Reference)}\label{declaration-a-deeper-dive-reference}}

\begin{frame}[fragile]{Declaration a deeper dive (Reference)}
We start with a simple experimental design and then show ways to extend.

\begin{itemize}
\tightlist
\item
  Variations to \emph{M} and \emph{I} are supported by the
  \texttt{fabricatr} package (and others)
\item
  Variations to \emph{D} are supported by the \texttt{randomizr} package
  (and others)
\item
  Variations to \emph{A} are supported by the \texttt{estimatr} package
  (and others)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Steps: A simple experimental design}
\protect\hypertarget{steps-a-simple-experimental-design}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{b }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}

\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{U =} \FunctionTok{rnorm}\NormalTok{(N), }
                \FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ U)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{simple\_ra}\NormalTok{(N), }\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }\AttributeTok{.method =}\NormalTok{ lm\_robust)}
\end{Highlighting}
\end{Shaded}

A few new elements here:

\begin{itemize}
\tightlist
\item
  \texttt{declare\_model} can be used much like \texttt{mutate} with
  multiple columns created in sequence
\item
  the \texttt{potential\_outcomes} function is a special function that
  creates potential outcome columns
\item
  when you assign a treatment that affects an outcome you can use
  \texttt{reveal\_outcome} to reveal the outcome; \texttt{Z} and
  \texttt{Y} are default
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Steps: A simple experimental design}
\protect\hypertarget{steps-a-simple-experimental-design-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{b }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}

\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{U =} \FunctionTok{rnorm}\NormalTok{(N), }
                \FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ U)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{simple\_ra}\NormalTok{(N), }\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }\AttributeTok{.method =}\NormalTok{ lm\_robust, }\AttributeTok{label =} \StringTok{"estimator 1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A few new elements here:

\begin{itemize}
\tightlist
\item
  when you declare an estimator you should normally associate an inquiry
  with the estimator and provide the method to be used;
  \texttt{lm\_robust} is default
\item
  you should generally label estimators as you may have many
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Steps: Order matters}
\protect\hypertarget{steps-order-matters}{}
e.g.~If you sample before defining the inquiry you get a different
inquiry to if you sample after you define the inquiry

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_1 }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{1000}\NormalTok{, }\AttributeTok{X =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, N}\SpecialCharTok{/}\DecValTok{2}\NormalTok{), }\AttributeTok{Y =}\NormalTok{ X }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(N)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_sampling}\NormalTok{(}\AttributeTok{S=} \FunctionTok{strata\_rs}\NormalTok{(}\AttributeTok{strata =}\NormalTok{ X, }\AttributeTok{strata\_prob =} \FunctionTok{c}\NormalTok{(.}\DecValTok{2}\NormalTok{, .}\DecValTok{8}\NormalTok{))) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{m =} \FunctionTok{mean}\NormalTok{(Y))}

\NormalTok{design\_1 }\SpecialCharTok{|\textgreater{}} \FunctionTok{draw\_estimands}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  inquiry  estimand
1       m 0.7907839
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Steps: Order matters}
\protect\hypertarget{steps-order-matters-1}{}
e.g.~If you sample before defining the inquiry you get a different
inquiry to if you sample after you define the inquiry

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_2 }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{1000}\NormalTok{, }\AttributeTok{X =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, N}\SpecialCharTok{/}\DecValTok{2}\NormalTok{), }\AttributeTok{Y =}\NormalTok{ X }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(N)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{m =} \FunctionTok{mean}\NormalTok{(Y)) }\SpecialCharTok{+}
  \FunctionTok{declare\_sampling}\NormalTok{(}\AttributeTok{S=} \FunctionTok{strata\_rs}\NormalTok{(}\AttributeTok{strata =}\NormalTok{ X, }\AttributeTok{strata\_prob =} \FunctionTok{c}\NormalTok{(.}\DecValTok{2}\NormalTok{, .}\DecValTok{8}\NormalTok{))) }

\NormalTok{design\_2 }\SpecialCharTok{|\textgreater{}} \FunctionTok{draw\_estimands}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  inquiry  estimand
1       m 0.5467558
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Key extensions to model declaration}
\protect\hypertarget{key-extensions-to-model-declaration}{}
You can generate hierarchical data like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}
    \AttributeTok{households =} \FunctionTok{add\_level}\NormalTok{(}
      \AttributeTok{N =} \DecValTok{100}\NormalTok{, }
      \AttributeTok{N\_members =} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{), N, }
                         \AttributeTok{prob =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.25}\NormalTok{, }\FloatTok{0.25}\NormalTok{), }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{    ),}
    \AttributeTok{individuals =} \FunctionTok{add\_level}\NormalTok{(}
      \AttributeTok{N =}\NormalTok{ N\_members, }
      \AttributeTok{age =} \FunctionTok{sample}\NormalTok{(}\DecValTok{18}\SpecialCharTok{:}\DecValTok{90}\NormalTok{, N, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Key extensions to model declaration}
\protect\hypertarget{key-extensions-to-model-declaration-1}{}
You can generate hierarchical data like this: ::: \{.cell\}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{M}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{head}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|r}
\hline
households & N\_members & individuals & age\\
\hline
001 & 1 & 001 & 57\\
\hline
002 & 4 & 002 & 34\\
\hline
002 & 4 & 003 & 40\\
\hline
002 & 4 & 004 & 57\\
\hline
002 & 4 & 005 & 31\\
\hline
003 & 3 & 006 & 41\\
\hline
\end{tabular}

:::
\end{frame}

\begin{frame}[fragile]{Key extensions to model declaration}
\protect\hypertarget{key-extensions-to-model-declaration-2}{}
You can generate panel data like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}
    \AttributeTok{countries =} \FunctionTok{add\_level}\NormalTok{(}
      \AttributeTok{N =} \DecValTok{196}\NormalTok{, }
      \AttributeTok{country\_shock =} \FunctionTok{rnorm}\NormalTok{(N)}
\NormalTok{    ),}
    \AttributeTok{years =} \FunctionTok{add\_level}\NormalTok{(}
      \AttributeTok{N =} \DecValTok{100}\NormalTok{, }
      \AttributeTok{time\_trend =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{N,}
      \AttributeTok{year\_shock =} \FunctionTok{runif}\NormalTok{(N, }\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{), }
      \AttributeTok{nest =} \ConstantTok{FALSE}
\NormalTok{    ),}
    \AttributeTok{observation =} \FunctionTok{cross\_levels}\NormalTok{(}
      \AttributeTok{by =} \FunctionTok{join\_using}\NormalTok{(countries, years),}
      \AttributeTok{observation\_shock =} \FunctionTok{rnorm}\NormalTok{(N),}
      \AttributeTok{Y =} \FloatTok{0.01} \SpecialCharTok{*}\NormalTok{ time\_trend }\SpecialCharTok{+}\NormalTok{ country\_shock }\SpecialCharTok{+}\NormalTok{ year\_shock }\SpecialCharTok{+}\NormalTok{ observation\_shock }
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Key extensions to model declaration}
\protect\hypertarget{key-extensions-to-model-declaration-3}{}
You can generate panel data like this: ::: \{.cell\}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{M}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{head}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|r|r|l|r|r}
\hline
countries & country\_shock & years & time\_trend & year\_shock & observation & observation\_shock & Y\\
\hline
001 & -1.01 & 001 & 1 & 7.24 & 00001 & 0.14 & 6.38\\
\hline
002 & 1.59 & 001 & 1 & 7.24 & 00002 & 1.10 & 9.94\\
\hline
003 & 0.18 & 001 & 1 & 7.24 & 00003 & 0.94 & 8.37\\
\hline
004 & -2.07 & 001 & 1 & 7.24 & 00004 & 0.21 & 5.40\\
\hline
005 & 0.22 & 001 & 1 & 7.24 & 00005 & 1.08 & 8.55\\
\hline
006 & -0.37 & 001 & 1 & 7.24 & 00006 & 1.22 & 8.11\\
\hline
\end{tabular}

:::
\end{frame}

\begin{frame}[fragile]{You can pull in preexisting data}
\protect\hypertarget{you-can-pull-in-preexisting-data}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}
    \AttributeTok{data =}\NormalTok{ baseline\_data,}
    \AttributeTok{attitudes =} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, N, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{A simple experimental design}
\protect\hypertarget{a-simple-experimental-design}{}
You can repeat steps and play with the order, always conscious of the
direction of the pipe

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{X =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, N}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{U =} \FunctionTok{rnorm}\NormalTok{(N), }\FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ Z }\SpecialCharTok{*}\NormalTok{ X }\SpecialCharTok{+}\NormalTok{ U)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ X), }\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{cate =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1[X}\SpecialCharTok{==}\DecValTok{0}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0[X}\SpecialCharTok{==}\DecValTok{0}\NormalTok{])) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }\AttributeTok{label =} \StringTok{"ols"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z}\SpecialCharTok{*}\NormalTok{X, }\AttributeTok{inquiry =} \StringTok{"cate"}\NormalTok{, }\AttributeTok{label =} \StringTok{"fe"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{You can generate multiple columns together}
\protect\hypertarget{you-can-generate-multiple-columns-together}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M2 }\OtherTok{\textless{}{-}}
  \FunctionTok{declare\_model}\NormalTok{(}
    \FunctionTok{draw\_multivariate}\NormalTok{(}\FunctionTok{c}\NormalTok{(X1, X2) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{mvrnorm}\NormalTok{(}
      \AttributeTok{n =} \DecValTok{1000}\NormalTok{,}
      \AttributeTok{mu =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{),}
      \AttributeTok{Sigma =} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{)}
\NormalTok{    )))}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{You can generate multiple columns together}
\protect\hypertarget{you-can-generate-multiple-columns-together-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{M2}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{head}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r}
\hline
X1 & X2\\
\hline
-1.3706858 & -0.9653579\\
\hline
1.3264821 & -0.0392575\\
\hline
-0.5585624 & 1.3270622\\
\hline
0.2907566 & -1.2893750\\
\hline
0.4111638 & -0.5837608\\
\hline
-1.2206595 & -1.1646952\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Cluster structures with cluster correlations}
\protect\hypertarget{cluster-structures-with-cluster-correlations}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}}
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{households =} \FunctionTok{add\_level}\NormalTok{(}\AttributeTok{N =} \DecValTok{1000}\NormalTok{),}
                \AttributeTok{individuals =} \FunctionTok{add\_level}\NormalTok{(}
                  \AttributeTok{N =} \DecValTok{4}\NormalTok{,}
                  \AttributeTok{X =} \FunctionTok{draw\_normal\_icc}\NormalTok{(}
                    \AttributeTok{mean =} \DecValTok{0}\NormalTok{,}
                    \AttributeTok{clusters =}\NormalTok{ households,}
                    \AttributeTok{ICC =} \FloatTok{0.65}
\NormalTok{                  )}
\NormalTok{                ))}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Cluster structures with cluster correlations}
\protect\hypertarget{cluster-structures-with-cluster-correlations-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{lm\_robust}\NormalTok{(X }\SpecialCharTok{\textasciitilde{}}\NormalTok{ households, }\AttributeTok{data =} \FunctionTok{M}\NormalTok{())}
\NormalTok{model}\SpecialCharTok{$}\NormalTok{adj.r.squared}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.6709427
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Assignment schemes}
\protect\hypertarget{assignment-schemes}{}
The \texttt{randomizr} package has a set of functions for different
types of block and cluster assignments.

\begin{itemize}
\tightlist
\item
  Simple random assignment: ``Coin flip'' or Bernoulli random
  assignment. All units have the same probability of assignment:
  \texttt{simple\_ra(N\ =\ 100,\ prob\ =\ 0.25)}
\item
  Complete random assignment: Exactly m of N units are assigned to
  treatment, and all units have the same probability of assignment m/N
  \texttt{complete\_ra(N\ =\ 100,\ m\ =\ 40)}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Assignment schemes}
\protect\hypertarget{assignment-schemes-1}{}
\begin{itemize}
\tightlist
\item
  Block random assignment: Complete random assignment within pre-defined
  blocks. Units within the same block have the same probability of
  assignment m\_b / N\_b \texttt{block\_ra(blocks\ =\ regions)}
\item
  Cluster random assignment: Whole groups of units are assigned to the
  same treatment condition.
  \texttt{cluster\_ra(clusters\ =\ households)} * Block-and-cluster
  assignment: Cluster random assignment within blocks of clusters
  \texttt{block\_and\_cluster\_ra(blocks\ =\ regions,\ clusters\ =\ villages)}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Assignment schemes}
\protect\hypertarget{assignment-schemes-2}{}
You can combine these in various ways. For examples with saturation
random assignment first clusters are assigned to a saturation level,
then units within clusters are assigned to treatment conditions
according to the saturation level:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{saturation }\OtherTok{=} \FunctionTok{cluster\_ra}\NormalTok{(}\AttributeTok{clusters =}\NormalTok{ villages, }\AttributeTok{conditions =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.75}\NormalTok{))}
\FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ villages, }\AttributeTok{prob\_unit =}\NormalTok{ saturation)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Inquiries}
\protect\hypertarget{inquiries}{}
Many causal inquiries are simple summaries of potential outcomes:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3392}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2807}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3801}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Inquiry
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Units
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Code
\end{minipage} \\
\midrule\noalign{}
\endhead
Average treatment effect in a finite population (PATE) & Units in the
population & \texttt{mean(Y\_D\_1\ -\ Y\_D\_0)} \\
Conditional average treatment effect (CATE) for X = 1 & Units for whom X
= 1 & \texttt{mean(Y\_D\_1{[}X\ ==\ 1{]}\ -\ Y\_D\_0{[}X\ ==\ 1{]})} \\
Complier average causal effect (CACE) & Complier units &
\texttt{mean(Y\_D\_1{[}D\_Z\_1\ \textgreater{}\ D\_Z\_0{]}\ -\ Y\_D\_0{[}D\_Z\_1\ \textgreater{}\ D\_Z\_0{]})} \\
Causal interactions of \(D_1\) and \(D_2\) & Units in the population &
\texttt{mean((Y\_D1\_1\_D2\_1\ -\ Y\_D1\_0\_D2\_1)\ -\ (Y\_D1\_1\_D2\_0\ -\ Y\_D1\_0\_D2\_0))} \\
\bottomrule\noalign{}
\end{longtable}

Generating potential outcomes columns gets you far
\end{frame}

\begin{frame}{Inquiries}
\protect\hypertarget{inquiries-1}{}
Often though we need to define inquiries as a function of continuous
variables. For this generating a potential outcomes function can make
life easier. This helps for:

\begin{itemize}
\tightlist
\item
  Continuous quantities
\item
  Spillover quantities
\item
  Complex counterfactuals
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Inquiries: Complex counterfactuals}
\protect\hypertarget{inquiries-complex-counterfactuals}{}
Here is an example of using functions to define complex counterfactuals:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_M }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X, UM) }\DecValTok{1}\SpecialCharTok{*}\NormalTok{(UM }\SpecialCharTok{\textless{}}\NormalTok{ X)}
\NormalTok{f\_Y }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X, M, UY) X }\SpecialCharTok{+}\NormalTok{ M }\SpecialCharTok{{-}}\NormalTok{ .}\DecValTok{4}\SpecialCharTok{*}\NormalTok{X}\SpecialCharTok{*}\NormalTok{M }\SpecialCharTok{+}\NormalTok{ UY}

\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{100}\NormalTok{,}
                \AttributeTok{X =} \FunctionTok{simple\_rs}\NormalTok{(N),}
                \AttributeTok{UM =} \FunctionTok{runif}\NormalTok{(N),}
                \AttributeTok{UY =} \FunctionTok{rnorm}\NormalTok{(N),}
                \AttributeTok{M =} \FunctionTok{f\_M}\NormalTok{(X, UM),}
                \AttributeTok{Y =} \FunctionTok{f\_Y}\NormalTok{(X, M, UY)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{Q1 =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{f\_Y}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{f\_M}\NormalTok{(}\DecValTok{0}\NormalTok{, UM), UY) }\SpecialCharTok{{-}} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{f\_M}\NormalTok{(}\DecValTok{0}\NormalTok{, UM), UY)))}

\NormalTok{design }\SpecialCharTok{|\textgreater{}} \FunctionTok{draw\_estimands}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r}
\hline
inquiry & estimand\\
\hline
Q1 & 1\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Inquiries: Complex counterfactuals}
\protect\hypertarget{inquiries-complex-counterfactuals-1}{}
Here is an example of using functions to define effects of continuous
treatments.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_Y }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X, UY) X }\SpecialCharTok{{-}}\NormalTok{ .}\DecValTok{25}\SpecialCharTok{*}\NormalTok{X}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ UY}

\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{100}\NormalTok{,}
                \AttributeTok{X  =} \FunctionTok{rnorm}\NormalTok{(N),}
                \AttributeTok{UY =} \FunctionTok{rnorm}\NormalTok{(N),}
                \AttributeTok{Y =} \FunctionTok{f\_Y}\NormalTok{(X, UY)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}
    \AttributeTok{Q1 =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{f\_Y}\NormalTok{(X}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, UY) }\SpecialCharTok{{-}} \FunctionTok{f\_Y}\NormalTok{(X, UY)),}
    \AttributeTok{Q2 =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{f\_Y}\NormalTok{(}\DecValTok{1}\NormalTok{, UY) }\SpecialCharTok{{-}} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, UY)),}
    \AttributeTok{Q3 =}\NormalTok{ (}\FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X)}\SpecialCharTok{|\textgreater{}} \FunctionTok{tidy}\NormalTok{())[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{]}
\NormalTok{    )}

\NormalTok{design }\SpecialCharTok{|\textgreater{}} \FunctionTok{draw\_estimands}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r}
\hline
inquiry & estimand\\
\hline
Q1 & 0.857143\\
\hline
Q2 & 0.750000\\
\hline
Q3 & 1.363886\\
\hline
\end{tabular}

which one is the ATE?
\end{frame}

\begin{frame}[fragile]{Answers: terms}
\protect\hypertarget{answers-terms}{}
By default \texttt{declare\_estimates()} assumes you are interested in
the \emph{first term after the constant} from the output of an
estimation procedure.

But you can say what you are interested in directly using \texttt{term}
and you can also associate different terms with different quantities of
interest using \texttt{inquiry}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\OtherTok{\textless{}{-}}
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{100}\NormalTok{,}
                \AttributeTok{X1 =} \FunctionTok{rnorm}\NormalTok{(N),}
                \AttributeTok{X2 =} \FunctionTok{rnorm}\NormalTok{(N),}
                \AttributeTok{X3 =} \FunctionTok{rnorm}\NormalTok{(N),}
                \AttributeTok{Y =}\NormalTok{ X1 }\SpecialCharTok{{-}}\NormalTok{ X2 }\SpecialCharTok{+}\NormalTok{ X3 }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(N)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiries}\NormalTok{(}\AttributeTok{ate\_2 =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\AttributeTok{ate\_3 =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X1 }\SpecialCharTok{+}\NormalTok{ X2 }\SpecialCharTok{+}\NormalTok{ X3, }\AttributeTok{term =} \FunctionTok{c}\NormalTok{(}\StringTok{"X2"}\NormalTok{, }\StringTok{"X3"}\NormalTok{), }\AttributeTok{inquiry =} \FunctionTok{c}\NormalTok{(}\StringTok{"ate\_2"}\NormalTok{, }\StringTok{"ate\_3"}\NormalTok{))}

\NormalTok{design  }\SpecialCharTok{|\textgreater{}} \FunctionTok{run\_design}\NormalTok{()  }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|l|r|r|r|r|r|r|r|l}
\hline
inquiry & estimand & term & estimator & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
ate\_2 & -1 & X2 & estimator & -0.85 & 0.09 & -9.80 & 0 & -1.02 & -0.68 & 96 & Y\\
\hline
ate\_3 & 1 & X3 & estimator & 0.99 & 0.10 & 9.87 & 0 & 0.79 & 1.18 & 96 & Y\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Answers: terms}
\protect\hypertarget{answers-terms-1}{}
Sometimes it can be confusing what the names of a term is but you can
figure this by running the estimation strategy directly. Here's an
example where the names of a term might be confusing.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ A}\SpecialCharTok{*}\NormalTok{B, }
          \AttributeTok{data =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{A =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{,  }\StringTok{"b"}\NormalTok{), }\DecValTok{3}\NormalTok{), }
                            \AttributeTok{B =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"p"}\NormalTok{, }\StringTok{"q"}\NormalTok{), }\AttributeTok{each =} \DecValTok{3}\NormalTok{), }
                            \AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{6}\NormalTok{))) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{coef}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r}
\hline
  & x\\
\hline
(Intercept) & 0.984547\\
\hline
Ab & -1.172676\\
\hline
Bq & -1.976603\\
\hline
Ab:Bq & 2.115862\\
\hline
\end{tabular}

The names are they appear in the output here is the name of the term
that \texttt{declare\_estimator} will look for.
\end{frame}

\begin{frame}[fragile]{Answers: other packages}
\protect\hypertarget{answers-other-packages}{}
\texttt{DeclareDesign} works natively with \texttt{estimatr} but you you
can use whatever packages you like. You do have to make sure though that
estimatr gets as input a nice tidy dataframe of estimates, and that
might require some tidying.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{1000}\NormalTok{, }\AttributeTok{U =} \FunctionTok{runif}\NormalTok{(N), }
                \FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.numeric}\NormalTok{(U }\SpecialCharTok{\textless{}}\NormalTok{ .}\DecValTok{5} \SpecialCharTok{+}\NormalTok{ Z}\SpecialCharTok{/}\DecValTok{3}\NormalTok{))) }\SpecialCharTok{+} 
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{simple\_ra}\NormalTok{(N), }\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }
                    \AttributeTok{.method =}\NormalTok{ glm, }
                    \AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"probit"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Note that we passed additional arguments to \texttt{glm}; that's easy.

It's not a good design though. Just look at the diagnosis:
\end{frame}

\begin{frame}[fragile]{Answers: other packages}
\protect\hypertarget{answers-other-packages-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{diagnose\_design}\NormalTok{(design)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{(run)}
  \FunctionTok{diagnose\_design}\NormalTok{(design) }\SpecialCharTok{|\textgreater{}} \FunctionTok{write\_rds}\NormalTok{(}\StringTok{"saved/probit.rds"}\NormalTok{)}

\FunctionTok{read\_rds}\NormalTok{(}\StringTok{"saved/probit.rds"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \FunctionTok{reshape\_diagnosis}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l|l|l|l|l}
\hline
Design & Inquiry & Estimator & Term & N Sims & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
design & ate & estimator & Z & 500 & 0.33 & 0.97 & 0.64 & 0.09 & 0.64 & 1.00 & 0.00\\
\hline
 &  &  &  &  & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
\end{tabular}

Why is it so terrible?
\end{frame}

\begin{frame}[fragile]{Answers: other packages}
\protect\hypertarget{answers-other-packages-2}{}
Because the probit estimate does not target the ATE directly; you need
to do more work to get there.

You essentially have to write a function to get the estimates, calculate
the quantity of interest and other stats, and turn these into a nice
dataframe.

Luckily you can use the \texttt{margins} package with \texttt{tidy} to
create a \texttt{.summary} function which you can pass to
\texttt{declare\_estimator} to do all this for you

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_margins }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{(margins}\SpecialCharTok{::}\FunctionTok{margins}\NormalTok{(x, }\AttributeTok{data =}\NormalTok{ x}\SpecialCharTok{$}\NormalTok{data), }\AttributeTok{conf.int =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{design }\OtherTok{\textless{}{-}}\NormalTok{ design }\SpecialCharTok{+}  
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }
                    \AttributeTok{.method =}\NormalTok{ glm, }
                    \AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"probit"}\NormalTok{),}
                    \AttributeTok{.summary =}\NormalTok{ tidy\_margins,}
                    \AttributeTok{label =} \StringTok{"margins"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Answers: other packages}
\protect\hypertarget{answers-other-packages-3}{}
\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{(run)}
  \FunctionTok{diagnose\_design}\NormalTok{(design) }\SpecialCharTok{|\textgreater{}} \FunctionTok{write\_rds}\NormalTok{(}\StringTok{"saved/probit\_2.rds"}\NormalTok{)}

\FunctionTok{read\_rds}\NormalTok{(}\StringTok{"saved/probit\_2.rds"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} \FunctionTok{reshape\_diagnosis}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l|l|l|l|l|l}
\hline
Design & Inquiry & Estimator & Term & N Sims & Mean Estimand & Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
design & ate & estimator & Z & 500 & 0.33 & 0.97 & 0.64 & 0.09 & 0.64 & 1.00 & 0.00\\
\hline
 &  &  &  &  & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
design & ate & margins & Z & 500 & 0.33 & 0.31 & -0.02 & 0.02 & 0.03 & 1.00 & 0.90\\
\hline
 &  &  &  &  & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.01)\\
\hline
\end{tabular}

Much better
\end{frame}

\hypertarget{causality.-whats-a-cause}{%
\section{\texorpdfstring{Causality. What's a cause?
\label{L_cause}}{Causality. What's a cause? }}\label{causality.-whats-a-cause}}

\hypertarget{potential-outcomes-and-the-counterfactual-approach}{%
\subsection{Potential outcomes and the counterfactual
approach}\label{potential-outcomes-and-the-counterfactual-approach}}

\begin{frame}{Potential outcomes and the counterfactual approach}
\emph{Causation as difference making}
\end{frame}

\begin{frame}{Motivation \label{po}}
\protect\hypertarget{motivation}{}
The \emph{intervention} based motivation for understanding causal
effects:

\begin{itemize}
\tightlist
\item
  We want to know if a particular intervention (like aid) caused a
  particular outcome (like reduced corruption).
\item
  We need to know:

  \begin{enumerate}
  \tightlist
  \item
    What happened?
  \item
    What would the outcome have been if there were no intervention?
  \end{enumerate}
\item
  The problem:

  \begin{enumerate}
  \tightlist
  \item
    \ldots{} this is hard
  \item
    \ldots{} this is impossible
  \end{enumerate}
\end{itemize}

The problem in 2 is that you need to know what would have happened if
things were different. You need information on a
\textbf{counterfactual}.
\end{frame}

\begin{frame}{Potential Outcomes}
\protect\hypertarget{potential-outcomes}{}
\begin{itemize}
\tightlist
\item
  For each unit, we assume that there are two \textbf{post-treatment}
  outcomes: \(Y_i(1)\) and \(Y_i(0)\).
\item
  For example, \(Y(1)\) is the outcome that \emph{would} obtain
  \emph{if} the unit received the treatment.
\item
  The \textbf{causal effect} of Treatment (relative to Control) is:
  \(\tau_i = Y_i(1) - Y_i(0)\)
\item
  Note:

  \begin{itemize}
  \tightlist
  \item
    The causal effect is defined at the \emph{individual level}.
  \item
    There is no ``data generating process'' or functional form.
  \item
    The causal effect is defined relative to something else, so a
    counterfactual must be conceivable (did Germany cause the second
    world war?).
  \item
    Are there any substantive assumptions made here so far?
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Potential Outcomes}
\protect\hypertarget{potential-outcomes-1}{}
\textbf{Idea}: A causal claim is (in part) a claim about something that
did not happen. This makes it metaphysical.
\end{frame}

\begin{frame}{Potential Outcomes}
\protect\hypertarget{potential-outcomes-2}{}
Now that we have a concept of causal effects available, let's answer two
\textbf{questions}:

\begin{itemize}
\tightlist
\item
  TRANSITIVITY: If for a given unit \(A\) causes \(B\) and \(B\) causes
  \(C\), does that mean that \(A\) causes \(C\)?
\end{itemize}
\end{frame}

\begin{frame}{Potential Outcomes}
\protect\hypertarget{potential-outcomes-3}{}
Now that we have a concept of causal effects available, let's answer two
\textbf{questions}:

\begin{itemize}
\item
  TRANSITIVITY: If for a given unit \(A\) causes \(B\) and \(B\) causes
  \(C\), does that mean that \(A\) causes \(C\)?
\item
  A boulder is flying down a mountain. You duck. This saves your life.
\item
  So the boulder caused the ducking and the ducking caused you to
  survive.
\item
  So: \emph{did the boulder cause you to survive?}
\end{itemize}
\end{frame}

\begin{frame}{Potential Outcomes}
\protect\hypertarget{potential-outcomes-4}{}
CONNECTEDNESS Say \(A\) causes \(B\) --- does that mean that there is a
spatiotemporally continuous sequence of causal intermediates?
\end{frame}

\begin{frame}{Potential Outcomes}
\protect\hypertarget{potential-outcomes-5}{}
CONNECTEDNESS Say \(A\) causes \(B\) --- does that mean that there is a
spatiotemporally continuous sequence of causal intermediates?

\begin{itemize}
\tightlist
\item
  Person A is planning some action \(Y\); Person B sets out to stop
  them; person X intervenes and prevents person B from stopping person
  A. In this case Person A may complete their action, producing Y,
  without any knowledge that B and X even exist; in particular B and X
  need not be anywhere close to the action. So: \emph{did X cause Y}?
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: Contribution or attribution?}
\protect\hypertarget{causal-claims-contribution-or-attribution}{}
The counterfactual model is all about contribution, not attribution,
except in a very conditional sense.

\begin{itemize}
\tightlist
\item
  Focus is on non-rival contributions
\item
  Not: what caused \(Y\) but what is the effect of \(X\)?
\item
  At most it provides a conditional account
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: Contribution or attribution?}
\protect\hypertarget{causal-claims-contribution-or-attribution-1}{}
Consider an outcome \(Y\) that might depend on two causes \(X_1\) and
\(X_2\):

\[Y(0,0) = 0\] \[Y(1,0) = 0\] \[Y(0,1) = 0\] \[Y(1,1) = 1\]

What caused \(Y\)? Which cause was most important?
\end{frame}

\begin{frame}{Causal claims: Contribution or attribution?}
\protect\hypertarget{causal-claims-contribution-or-attribution-2}{}
The counterfactual model is about attribution in a very conditional
sense.

\begin{itemize}
\item
  Focus is on non-rival contributions
\item
  Not: what caused \(Y\) but what is the effect of \(X\)?
\item
  At most it provides a conditional account
\item
  This is problem for research programs that define ``explanation'' in
  terms of figuring out the things that cause \(Y\)
\item
  Real difficulties conceptualizing what it means to say one cause is
  more important than another cause. What does that mean?
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: Contribution or attribution?}
\protect\hypertarget{causal-claims-contribution-or-attribution-3}{}
\emph{Erdogan's increasing authoritarianism was the most important
reason for the attempted coup}

\begin{itemize}
\tightlist
\item
  More important than Turkey's history of coups?
\item
  What does that mean?
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: No causation without manipulation}
\protect\hypertarget{causal-claims-no-causation-without-manipulation}{}
\begin{itemize}
\tightlist
\item
  Some seemingly causal claims not admissible.
\item
  To get the definition off the ground, manipulation must be imaginable
  (whether practical or not)
\item
  This renders thinking about effects of race and gender difficult
\item
  What does it mean to say that Aunt Pat voted for Brexit because she is
  old?
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: No causation without manipulation}
\protect\hypertarget{causal-claims-no-causation-without-manipulation-1}{}
\begin{itemize}
\tightlist
\item
  Some seemingly causal claims not admissible.
\item
  To get the definition off the ground, manipulation must be imaginable
  (whether practical or not)
\item
  This renders thinking about effects of race and gender difficult
\item
  \textbf{Compare}: What does it mean to say that Southern counties
  voted for Brexit because they have many old people?
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: Causal claims are everywhere}
\protect\hypertarget{causal-claims-causal-claims-are-everywhere}{}
\begin{itemize}
\item
  Jack exploited Jill
\item
  It's Jill's fault that bucket fell
\item
  Jack is the most obstructionist member of Congress
\item
  Melania Trump stole from Michelle Obama's speech
\item
  Activists need causal claims
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Causal claims: What is actually seen?}
\protect\hypertarget{causal-claims-what-is-actually-seen}{}
\begin{itemize}
\tightlist
\item
  We have talked about what's potential, now what do we \emph{observe}?
\item
  Say \(Z_i\) indicates whether the unit \(i\) is assigned to treatment
  \((Z_i=1)\) or not \((Z_i=0)\). It describes the treatment process.
  Then what we observe is: \[ Y_i = Z_iY_i(1) + (1-Z_i)Y_i(0) \]
\end{itemize}

This is sometimes called a ``switching equation''

In \texttt{DeclareDesign} \(Y\) is realised from potential outcomes and
assignment in this way using \texttt{reveal\_outcomes}
\end{frame}

\begin{frame}{Causal claims: What is actually seen?}
\protect\hypertarget{causal-claims-what-is-actually-seen-1}{}
\begin{itemize}
\item
  Say \(Z\) is a random variable, then this is a sort of data generating
  process. BUT the key thing to note is

  \begin{itemize}
  \tightlist
  \item
    \(Y_i\) is random but the randomness comes from \(Z_i\) --- the
    potential outcomes, \(Y_i(1)\), \(Y_i(0)\) are fixed
  \item
    Compare this to a regression approach in which \(Y\) is random but
    the \(X\)'s are fixed. eg:
    \[ Y \sim N(\beta X, \sigma^2) \text{ or }  Y=\alpha+\beta X+\epsilon, \epsilon\sim N(0, \sigma^2) \]
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: The estimand and the rub}
\protect\hypertarget{causal-claims-the-estimand-and-the-rub}{}
\begin{itemize}
\tightlist
\item
  The causal effect of Treatment (relative to Control) is:
  \[\tau_i = Y_i(1) - Y_i(0)\]
\item
  This is what we want to estimate.
\item
  BUT: We never can observe both \(Y_i(1)\) and \(Y_i(0)\)!
\item
  This is the \textbf{fundamental problem} (@holland1986statistics)
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: The rub and the solution}
\protect\hypertarget{causal-claims-the-rub-and-the-solution}{}
\begin{itemize}
\item
  Now for some magic. We really want to estimate:
  \[ \tau_i = Y_i(1) - Y_i(0)\]
\item
  BUT: We never can observe both \(Y_i(1)\) and \(Y_i(0)\)
\item
  Say we lower our sights and try to estimate an \emph{average}
  treatment effect: \[ \tau = \mathbb{E} [Y(1)-Y(0)]\]
\item
  Now make use of the fact that
  \[\mathbb E[Y(1)-Y(0)]  = \mathbb E[Y(1)]- \mathbb E [Y(0)] \]
\item
  In words: \emph{The average of differences is equal to the difference
  of averages}; here, the average treatment effect is equal to the
  difference in average outcomes in treatment and control units.
\item
  The magic is that \emph{while we can't hope to measure the
  differences; we are good at measuring averages}.
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: The rub and the solution}
\protect\hypertarget{causal-claims-the-rub-and-the-solution-1}{}
\begin{itemize}
\tightlist
\item
  So we want to estimate \(\mathbb{E} [Y(1)]\) and
  \(\mathbb{E} [Y(0)]\).
\item
  We know that we can estimate averages of a quantity by taking the
  average value from a random sample of units
\item
  To do this here we need to select a random sample of the \(Y(1)\)
  values and a random sample of the \(Y(0)\) values, in other words, we
  \textbf{randomly assign} subjects to treatment and control conditions.
\item
  When we do that we can in fact estimate:
  \[ \mathbb {E}_N[Y_i(1) | Z_i = 1) - \mathbb {E}_N(Y_i(0) | Z_i = 0]\]
  which in expectation equals:
  \[ \mathbb{E} [Y_i(1) | Z_i = 1 \text{ or } Z_i = 0] - \mathbb{E} [Y_i(0) | Z_i = 1 \text{ or } Z_i = 0]\]
\item
  This highlights a deep connection between \textbf{random assignment}
  and \textbf{random sampling}: when we do random assignment \emph{we
  are in fact randomly sampling from different possible worlds}.
\end{itemize}
\end{frame}

\begin{frame}{Causal claims: The rub and the solution}
\protect\hypertarget{causal-claims-the-rub-and-the-solution-2}{}
This provides a \textbf{positive argument} for causal inference from
randomization, rather than simply saying with randomization ``everything
else is controlled for''

\textbf{Let's discuss:}

\begin{itemize}
\tightlist
\item
  \emph{Does the fact that an estimate is unbiased mean that it is
  right?}
\item
  \emph{Can a randomization ``fail''?}
\item
  \emph{Where are the covariates?}
\end{itemize}

\textbf{Idea}: random assignment is random sampling from potential
worlds: to understand anything you find, you need to know the sampling
weights
\end{frame}

\begin{frame}{Reflection}
\protect\hypertarget{reflection}{}
\textbf{Idea}: We now have a \emph{positive} argument for claiming
unbiased estimation of the average treatment effect following random
assignment

But is the average treatment effect a quantity of \emph{social
scientific} interest?
\end{frame}

\begin{frame}{Potential outcomes: why randomization works}
\protect\hypertarget{potential-outcomes-why-randomization-works}{}
The average of the differences \(\approx\) difference of averages

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-222-1.pdf}
\end{frame}

\begin{frame}{Potential outcomes: heterogeneous effects}
\protect\hypertarget{potential-outcomes-heterogeneous-effects}{}
The average of the differences \(\approx\) difference of averages

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-223-1.pdf}
\end{frame}

\begin{frame}{Potential outcomes: heterogeneous effects}
\protect\hypertarget{potential-outcomes-heterogeneous-effects-1}{}
\textbf{Question}: \(\approx\) or \(=\)?
\end{frame}

\begin{frame}{Exercise your potential outcomes 1}
\protect\hypertarget{exercise-your-potential-outcomes-1}{}
Consider the following potential outcomes table:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Unit & Y(0) & Y(1) & \(\tau_i\) \\
\midrule\noalign{}
\endhead
1 & 4 & 3 & \\
2 & 2 & 3 & \\
3 & 1 & 3 & \\
4 & 1 & 3 & \\
5 & 2 & 3 & \\
\bottomrule\noalign{}
\end{longtable}

\textbf{Questions for us:} What are the unit level treatment effects?
What is the average treatment effect?
\end{frame}

\begin{frame}{Exercise your potential outcomes 2}
\protect\hypertarget{exercise-your-potential-outcomes-2}{}
Consider the following potential outcomes table:

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
In treatment? & Y(0) & Y(1) \\
\midrule\noalign{}
\endhead
Yes & & 2 \\
No & 3 & \\
No & 1 & \\
Yes & & 3 \\
Yes & & 3 \\
No & 2 & \\
\bottomrule\noalign{}
\end{longtable}

\textbf{Questions for us: } Fill in the blanks.

\begin{itemize}
\tightlist
\item
  Assuming a constant treatment effect of \(+1\)
\item
  Assuming a constant treatment effect of \(-1\)
\item
  Assuming an \textit{average} treatment effect of \(0\)
\end{itemize}

What is the actual treatment effect?
\end{frame}

\hypertarget{endogeneous-subgroups}{%
\subsection{\texorpdfstring{Endogeneous subgroups
\label{subs}}{Endogeneous subgroups }}\label{endogeneous-subgroups}}

\begin{frame}{Endogeneous Subgroups}
\protect\hypertarget{endogeneous-subgroups-1}{}
Experiments often give rise to endogenous subgroups. The potential
outcomes framework can make it clear why this can cause problems.
\end{frame}

\begin{frame}{Heterogeneous Effects with Endogeneous Categories}
\protect\hypertarget{heterogeneous-effects-with-endogeneous-categories}{}
\begin{itemize}
\item
  Problems arise in analyses of subgroups when the categories themselves
  are affected by treatment
\item
  Example from our work:

  \begin{itemize}
  \tightlist
  \item
    You want to know if an intervention affects reporting on violence
    against women
  \item
    You measure the share of all subjects that experienced violence that
    file reports
  \item
    The problem is that which subjects experienced violence is itself a
    function of treatment
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Heterogeneous Effects with Endogeneous
Categories}
\protect\hypertarget{heterogeneous-effects-with-endogeneous-categories-1}{}
It is possible that in truth no one's reporting behavior has changed,
what has changed is the propensity of people with different propensities
to report to experience violence:

\begin{verbatim}
\begin{table} \scriptsize
    \centering
    \begin{tabular}{rcc|cc|cc}
        
        & \multicolumn{ 2}{c}{Violence(Treatment)} & \multicolumn{ 4}{c}{Reporting(Treatment, Violence)} \\
        
        &       V(0) &       V(1) &     R(0,1) &     R(1,1) &     R(0,0) &     R(1,0) \\ \hline
        
        Type 1 (reporter) &          1 &          1 &          1 &          1 &          0 &          0 \\
        
        Type 2 (non reporter) &          1 &          0 &          0 &          0 &          0 &          0 \\          
    \end{tabular}  
\end{table}
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Heterogeneous Effects with Endogeneous
Categories}
\protect\hypertarget{heterogeneous-effects-with-endogeneous-categories-2}{}
\begin{verbatim}
|                   | **Violence(Treatment)**            | **Reporting(Treatment, Violence)**    |
\end{verbatim}

\textbar-------------------\textbar-------------------------\textbar-----------------------------\textbar-----------------------------\textbar-----------------------------\textbar-----------------------------\textbar-----------------------------\textbar{}
\textbar{} \textbar{} V(0) \textbar{} V(1) \textbar{} R(0,1) \textbar{}
R(1,1) \textbar{} R(0,0) \textbar{} R(1,0) \textbar{}
\textbar-------------------\textbar-------------------------\textbar-----------------------------\textbar-----------------------------\textbar-----------------------------\textbar-----------------------------\textbar-----------------------------\textbar{}
\textbar{} Type 1 (reporter) \textbar{} 1 \textbar{} 1 \textbar{} 1
\textbar{} 1 \textbar{} 0 \textbar{} 0 \textbar{} \textbar{} Type 2 (non
reporter)\textbar{} 1 \textbar{} 0 \textbar{} 0 \textbar{} 0 \textbar{}
0 \textbar{} 0 \textbar{}

Expected reporting given violence in control = Pr(Type 1)

Expected reporting given violence in treatment = 100\%

Question: What is the actual effect of treatment on the propensity to
report violence?
\end{frame}

\begin{frame}{Heterogeneous Effects with Endogeneous Categories}
\protect\hypertarget{heterogeneous-effects-with-endogeneous-categories-3}{}
It is possible that in truth no one's reporting behavior has changed,
what has changed is the propensity of people with different propensities
to report to experience violence:

\begin{table}
\centering
\begin{tabular}{c|cc|cc|c}\scriptsize

           & \multicolumn{ 2}{c}{Reporters} & \multicolumn{ 2}{c}{Non reporters} &            \\ \hline
           & \multicolumn{ 2}{c}{Experience Violence} & \multicolumn{ 2}{c}{Experience Violence} &            \\ \hline \hline
           &         No &        Yes &        No  &        Yes &  \% Report \\

   Control &         25 &         {25} &         25 &        {25} &       { $\frac{25}{25+25}$}= 50\% \\  
   & & & & \\
  Treatment &         25 &         {25} &         50 &          {0} &      {$\frac{25}{25+0}$}=100\% \\ \hline

\end{tabular}  
\end{table}
\end{frame}

\begin{frame}{Heterogeneous Effects with Endogeneous Categories}
\protect\hypertarget{heterogeneous-effects-with-endogeneous-categories-4}{}
This problem can arise as easily in seemingly simple field experiments.
Example:

\begin{itemize}
\tightlist
\item
  In one study we provided constituents with information about
  performance of politicians
\item
  we told politicians in advance so that they could take action
\item
  we wanted to see whether voters punished poorly performing politicians
\item
  what's the problem?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Heterogeneous Effects with Endogeneous
Categories}
\protect\hypertarget{heterogeneous-effects-with-endogeneous-categories-5}{}
Question for us:

Setting:

\begin{verbatim}
    * Quotas for women are randomly placed in a set of constituencies in year 1. All winners in these areas are women; in other areas only some are. 
    * In year 2 these quotas are then lifted. 
\end{verbatim}

\textbf{Questions} Which problems face an endogenous subgroup issue?:

\begin{enumerate}
\tightlist
\item
  You want to estimate the likelihood that a woman will stand for
  reelection in treatment versus control areas in year 2.
\item
  You want to estimate how much incumbents are more likely to be
  reelected in treatment versus control areas in year 2.
\item
  You want to estimate how much treatment areas have more relected
  incumbents in elections in year 2 compared to control.
\end{enumerate}
\end{frame}

\begin{frame}{Heterogeneous Effects with Endogeneous Categories}
\protect\hypertarget{heterogeneous-effects-with-endogeneous-categories-6}{}
In such cases you can:

\begin{itemize}
\tightlist
\item
  Examine the joint distribution of multiple outcomes
\item
  Condition on pretreatment features only
\item
  Engage in mediation analysis
\end{itemize}
\end{frame}

\begin{frame}{Missing data can create an endogeneous subgroup problem}
\protect\hypertarget{missing-data-can-create-an-endogeneous-subgroup-problem}{}
\begin{itemize}
\tightlist
\item
  It is well known that missing data can undo the magic of random
  assignment.
\item
  One seemingly promising approach is to match into pairs
  \textit{ex ante} and drop pairs together \textit{ex post}.
\item
  Say potential outcomes looked like this (four units divided into two
  pairs):
\end{itemize}

\begin{longtable}[]{@{}llllll@{}}
\toprule\noalign{}
Pair & I & I & II & II & \\
\midrule\noalign{}
\endhead
Unit & 1 & 2 & 3 & 4 & Average \\
Y(0) & 0 & 0 & 0 & 0 & \\
Y(1) & -3 & 1 & 1 & 1 & \\
\(\tau\) & -3 & 1 & 1 & 1 & \\
\bottomrule\noalign{}
\end{longtable}
\end{frame}

\begin{frame}{Missing data}
\protect\hypertarget{missing-data}{}
\begin{itemize}
\item
  Say though that cases are likely to drop out of the sample if things
  go badly (eg they get a negative score or die)
\item
  Then you might see no attrition in cases in which people that are
  likely to drop out if treated do not get treated.
\item
  You might assume you have no problem (after all, no attrition).
\item
  No missing data when the normal cases happens to be selected
\end{itemize}

\begin{longtable}[]{@{}llllll@{}}
\toprule\noalign{}
Pair & I & I & II & II & \\
\midrule\noalign{}
\endhead
Unit & 1 & 2 & 3 & 4 & Average \\
Y(0) & 0 & & 0 & & 0 \\
Y(1) & & 1 & & 1 & 1 \\
\(\hat{\tau}\) & & & & & 1 \\
\bottomrule\noalign{}
\end{longtable}
\end{frame}

\begin{frame}{Missing data}
\protect\hypertarget{missing-data-1}{}
\begin{itemize}
\tightlist
\item
  But in cases in which you have attrition, dropping the pair doesn't
  necessarily help.
\item
  The problem is potential missingness still depends on potential
  outcomes
\item
  The kicker is that the method can produce bias even if (\emph{in
  fact}) there is no attrition!
\end{itemize}

Missing data when the vulnerable cases happens to be selected

\begin{longtable}[]{@{}llllll@{}}
\toprule\noalign{}
Pair & I & I & II & II & \\
\midrule\noalign{}
\endhead
Unit & 1 & 2 & 3 & 4 & Average \\
Y(0) & & {[}0{]} & 0 & & 0 \\
Y(1) & {[}-3{]} & & & 1 & 1 \\
\(\hat{\tau}\) & & & & & 1 \\
\bottomrule\noalign{}
\end{longtable}
\end{frame}

\begin{frame}{Missing data}
\protect\hypertarget{missing-data-2}{}
Note: The right way to think about this is that bias is a property of
the strategy over possible realizations of data and not normally a
property of the estimator conditional on the data.
\end{frame}

\begin{frame}{Multistage games}
\protect\hypertarget{multistage-games}{}
Multistage games can also present an endogenous group problem since
collections of late stage players facing a given choice have been
created by early stage players.
\end{frame}

\begin{frame}{Multistage games}
\protect\hypertarget{multistage-games-1}{}
Question: Does \textbf{visibility} alter the extent to which subjects
follow norms to punish antisocial behavior (and reward prosocial
behavior)? Consider a trust game in which we are interested in how
information on receivers affects their actions

\begin{table}[h!] \scriptsize
  \centering
  \caption{Return rates given investments under different conditions}
    \begin{tabular}{lp{3.8cm}|c|cc}
          &                                         & \% invested   & \multicolumn{2}{c}{Average \% returned}  \\ \hline 
          &                                         & (average)     & ...when       & ...when \\ 
          &                                         &               & 10\% invested     & 50\% invested \\ \hline \hline 
Treatment & Masked information on respondents       & 30\% (avg)    & 20\%          & 40\% \\
          & Full information on respondents         & 30\% (avg)    & 0\%           & 60\% \\
    \end{tabular}
\end{table}

What do we think? Does visibility make people react more to investments?
\end{frame}

\begin{frame}{Multistage games}
\protect\hypertarget{multistage-games-2}{}
Imagine you could see all the potential outcomes, and they looked like
this:

\begin{table}[h!] \scriptsize
  \centering
  \caption{Potential outcomes with (and without) identity protection}
    \begin{tabular}{ll|cccccc|c} \footnotesize
          &       & \multicolumn{6}{c}{Responder's return decision (given type)}& Avg.  \\ \hline 
          &       & Nice  & Nice  & Nice  & Mean  & Mean  & Mean \\ 
          & & 1&2&3&4&4&6\\ \hline \hline 
    Offerer  & Invest 10\%: & 60\%      &  60\%     &  60\%     & 0\%   & 0\%   & 0\% & 30\%\\
    behavior      & Invest 50\%: & 60\% & 60\% & 60\% &    0\%   &    0\%   &  0\% & 30\%\\
    \end{tabular}%
\end{table}

\textbf{Conclusion}: Both the offer and the information condition are
\textbf{completely irrelevant} for all subjects.
\end{frame}

\begin{frame}{Multistage games}
\protect\hypertarget{multistage-games-3}{}
Unfortunately you only see a sample of the potential outcomes, and that
looks like this:

\begin{table}[h!] \scriptsize
  \centering
  \caption{Outcomes when respondent \textbf{is visible}}
    \begin{tabular}{ll|cccccc|c} \footnotesize
          &       & \multicolumn{6}{c}{Responder's return decision (given type)}& Avg.   \\ \hline
          &       & Nice  & Nice  & Nice  & Mean  & Mean  & Mean  \\ 
                    & & 1&2&3&4&4&6\\ \hline \hline  
    Offerer  & Invest 10\%: &       &       &       & 0\%   & 0\%   & 0\% & 0\%\\
    behavior      & Invest 50\%: & 60\% & 60\% & 60\% &       &    &   &  60\% \\
    \end{tabular}
\end{table}

\textbf{False Conclusion}: When not protected, responders condition
behavior \textit{strongly} on offers (because offerers can select on
type accurately)
\end{frame}

\begin{frame}{Multistage games}
\protect\hypertarget{multistage-games-4}{}
Unfortunately you only see a sample of the potential outcomes, and that
looks like this:

\begin{table}[h!] \scriptsize
  \centering
  \caption{Outcomes when respondent \textbf{is not visible}}
    \begin{tabular}{ll|cccccc|c} \footnotesize
          &       & \multicolumn{6}{c}{Responder's return decision (given type)} & Avg.  \\ \hline
          &       & Nice  & Nice  & Nice  & Mean  & Mean  & Mean  \\ 
                    & & 1&2&3&4&4&6\\ \hline \hline  
    Offerer         & Invest 10\%: &        &       &    60\%   &    & 0\%   &      0\% & 20\%\\
    behavior        & Invest 50\%: & 60\%   &  60\% &           & 0\%      &       &   &  40\%\\
    \end{tabular}
\end{table}

\textbf{False Conclusion}: When protected, responders condition behavior
less strongly on offers (because offerers can select on type less
accurately)
\end{frame}

\begin{frame}{Multistage games}
\protect\hypertarget{multistage-games-5}{}
What to do?

\textbf{Solutions?}

\begin{enumerate}
\tightlist
\item
  Analysis \emph{could} focus on the effect of treatment on respondent
  behavior, directly.

  \begin{itemize}
  \tightlist
  \item
    This would get the correct answer but to a different question
    {[}Does information affect the share of contributions returned by
    subjects on average? No{]}
  \end{itemize}
\item
  \textbf{Strategy method} can sometimes help address the problem,
  \textbf{but} that is also (a) changing the question and (b) putting
  demands on respondent imagination and honesty
\item
  First mover action could be \textbf{directly manipulated}, but unless
  deception is used that is also changing the question
\item
  First movers could be \textbf{selected} because they act in
  predictable ways (bordering on deception?)
\end{enumerate}

\textbf{Idea}: Proceed with extreme caution when estimating effects
beyond the first stage.
\end{frame}

\hypertarget{dags}{%
\subsection{DAGs}\label{dags}}

\hypertarget{key-insight}{%
\subsection{Key insight}\label{key-insight}}

\begin{frame}{Key insight}
The most powerful results from the study of DAGs are procedures for
figuring out when conditioning aids or hinders causal identification.

\begin{itemize}
\tightlist
\item
  You can read off a \textbf{confounding} variable from a DAG.

  \begin{itemize}
  \tightlist
  \item
    You have to condition on such a variable for causal identification.
  \end{itemize}
\item
  You can read off \textbf{``colliders''} from a DAG

  \begin{itemize}
  \tightlist
  \item
    Sometimes you have \emph{avoid} conditioning on these
  \end{itemize}
\item
  Sometimes a variable might be both, so

  \begin{itemize}
  \tightlist
  \item
    you have to condition on it
  \item
    you have to avoid conditioning on it
  \item
    Ouch.
  \end{itemize}
\end{itemize}
\end{frame}

\hypertarget{key-resource}{%
\subsection{Key resource}\label{key-resource}}

\begin{frame}{Key resource}
\begin{itemize}
\item
  Pearl's book \emph{Causality} is the key reference.
  @pearl2009causality (Though see also older work such as
  @pearl1985graphoids)
\item
  There is a lot of excellent material on Pearl's page
  http://bayes.cs.ucla.edu/WHY/
\item
  See also excellent material on Felix Elwert's page
  http://www.ssc.wisc.edu/\textasciitilde felwert/causality/?page\_id=66
\end{itemize}
\end{frame}

\hypertarget{challenge-for-us}{%
\subsection{Challenge for us}\label{challenge-for-us}}

\begin{frame}{Challenge for us}
\begin{itemize}
\item
  Say you don't like graphs. Fine.\\
\item
  Consider this causal structure:

  \begin{itemize}
  \tightlist
  \item
    \(Z = f_1(U_1, U_2)\)
  \item
    \(X = f_2(U_2)\)
  \item
    \(Y = f_3(X, U_1)\)
  \end{itemize}
\end{itemize}

Say \(Z\) is temporally prior to \(X\); it is correlated with \(Y\)
(because of \(U_1\)) and with \(X\) (because of \(U_2\)).

\textbf{Question:} Would it be useful to ``control'' for \(Z\) when
trying to estimate the effect of \(X\) on \(Y\)?
\end{frame}

\hypertarget{challenge-for-us-1}{%
\subsection{Challenge for us}\label{challenge-for-us-1}}

\begin{frame}{Challenge for us}
\begin{itemize}
\item
  Say you don't like graphs. Fine.\\
\item
  Consider this causal structure:

  \begin{itemize}
  \tightlist
  \item
    \(Z = f_1(U_1, U_2)\)
  \item
    \(X = f_2(U_2)\)
  \item
    \(Y = f_3(X, U_1)\)
  \end{itemize}
\end{itemize}

\textbf{Question:} Would it be useful to ``control'' for \(Z\) when
trying to estimate the effect of \(X\) on \(Y\)?

\textbf{Answer:} Hopefully by the end of today you should see that that
the answer is obviously (or at least, plausibly) ``no.''
\end{frame}

\hypertarget{conditional-independence}{%
\subsection{Conditional independence}\label{conditional-independence}}

\begin{frame}{Conditional independence}
Variable sets \(A\) and \(B\) are conditionally independent, given \(C\)
if for all \(a\), \(b\), \(c\):

\[\Pr(A = a | C = c) = \Pr(A = a | B = b, C = c)\]

Informally; given \(C\), knowing \(B\) tells you nothing more about
\(A\).
\end{frame}

\hypertarget{causal-graphs-basics-1}{%
\subsection{Causal graphs basics 1}\label{causal-graphs-basics-1}}

\begin{frame}{Causal graphs basics 1}
\begin{itemize}
\tightlist
\item
  Consider a situation with variables \(X_1, X_2, \dots X_n\)
\item
  The probability of outcome \(x\) can always be written in the form
  \(P(X_1 = x_1)P(X_2 = x_2|X_1=x_1)(X_3 = x_3|X_1=x_1, X_2 = x_2)\dots\).
\item
  This can be done with any ordering of variables.
\item
  However the representation can be greatly simplified if you can make
  use of a set of ``parentage'' relationships
\item
  Given an ordering of variables, the \textbf{Markovian parents} of
  variable \(X_j\) are the minimal set of variables such that when you
  condition on these, \(X_j\) is independent of all other prior
  variables in the ordering
\item
  In this case we can write: \(P(x) = \prod_j(x_j | pa_j)\)
\item
  No graphs yet
\end{itemize}
\end{frame}

\hypertarget{causal-graphs-basics-2}{%
\subsection{Causal graphs basics 2}\label{causal-graphs-basics-2}}

\begin{frame}{Causal graphs basics 2}
\begin{itemize}
\tightlist
\item
  We want to use causal graphs to represent these relations of
  conditional independence.
\item
  Informally, an arrow, \(A \rightarrow B\) means that \(A\) is a cause
  of \(B\): that is, under some conditions, a change in \(A\) produces a
  change in \(B\).

  \begin{itemize}
  \tightlist
  \item
    Arrows carry no information about the type of effect; e.g.~sign,
    size, or whether different causes are complements or substitutes
  \end{itemize}
\item
  We say that arrows point from \emph{parents} to \emph{children}, and
  by extension from \emph{ancestors} to \emph{descendants}.
\item
  These are parents \emph{on the graph}; but we will connect them to
  Markovian parents in a probability distribution \(P\).
\end{itemize}
\end{frame}

\hypertarget{causal-graphs-basics-2-1}{%
\subsection{Causal graphs basics 2}\label{causal-graphs-basics-2-1}}

\begin{frame}{Causal graphs basics 2}
\begin{itemize}
\tightlist
\item
  A DAG is just a graph in which some or all nodes are connected by
  \emph{directed} edges (arrows) and there are no cyclical paths along
  these directed edges.
\item
  Consider a DAG, \(G\), and consider the ancestry relations implied by
  \(G\): the distribution \(P\) is \emph{Markov relative to the graph
  \(G\)} if every variable is independent of its nondescendants (in
  \(G\)) conditional on its parents (in \(G\)).

  \begin{itemize}
  \tightlist
  \item
    This is the \textbf{Markov condition}: conditional on its parents, a
    variable is independent of its non-descendants.
  \end{itemize}
\item
  OK now we have a link from probability distributions to graphs. But we
  have not talked about causality.
\end{itemize}
\end{frame}

\hypertarget{causal-graphs-basics-3}{%
\subsection{Causal graphs basics 3}\label{causal-graphs-basics-3}}

\begin{frame}[fragile]{Causal graphs basics 3}
We want the graphs to be able to represent the effects of interventions.

Pearl uses \texttt{do} notation to capture this idea.

\[\Pr(X_1, X_2,\dots | do(X_j = x_j))\] or

\[\Pr(X_1, X_2,\dots | \hat{x}_j)\]

denotes the distribution of \(X\) when a particular node (or set of
nodes) is intervened upon and forced to a particular level, \(x_j\).
\end{frame}

\hypertarget{causal-graphs-basics-3-1}{%
\subsection{Causal graphs basics 3}\label{causal-graphs-basics-3-1}}

\begin{frame}{Causal graphs basics 3}
Note, in general:
\[\Pr(X_1, X_2,\dots | do(X_j = x_j')) \neq \Pr(X_1, X_2,\dots | X_j = x_j')\]
as an example we might imagine a situation where for men binary \(X\)
always causes \(Y=1\) and for women \(Y=1\) regardless of \(X\). We
imagine that \(X=1\) for men only.

In that case \(\Pr(Y=1 | X = 1) = 1\) but \(\Pr(Y=1 | do(X = 1)) = .5\)
\end{frame}

\hypertarget{causal-graphs-basics-3-2}{%
\subsection{Causal graphs basics 3}\label{causal-graphs-basics-3-2}}

\begin{frame}[fragile]{Causal graphs basics 3}
\begin{itemize}
\item
  Let \(P_{z}\) denote the resulting distribution on all variables that
  arises when vector \(Z\) is ``set'' (forced, controlled\dots) to the
  value \(z\). That is when we have \texttt{do(Z=z)}.
\item
  Let \(P_*\) denote the set of all such distributions that can result
  from any set of interventions on variables.
\item
  A DAG, \(G\), is a \textbf{causal Bayesian network compatible with
  \(P_*\)} iff, for all interventions \(z\):

  \begin{enumerate}
  \tightlist
  \item
    \(P_{z}\) is Markov relative to \(G\)
  \item
    \(P_z(x_i)=1\) for all \(x_i\) consistent with \(z\)
  \item
    \(P_z(x_j|pa_j)=P(x_j|pa_j)\) for all \(x_j \not\in Z\) when
    \(pa_j\) is consistent with \(z\)
  \end{enumerate}
\end{itemize}
\end{frame}

\hypertarget{causal-graphs-basics-3-3}{%
\subsection{Causal graphs basics 3}\label{causal-graphs-basics-3-3}}

\begin{frame}[fragile]{Causal graphs basics 3}
\begin{itemize}
\tightlist
\item
  That all means that the probability distribution resulting from
  setting some set \(X_i\) to \(\hat{x'}_i\)
  (i.e.~\texttt{do(X=x\textquotesingle{})}) is:
\end{itemize}

\[P_{\hat{x}_i}=P(x_1,x_2,\dots x_n|\hat{x}_i) = \prod_{-i}P(x_j|pa_j)\mathbb{1}(x_i = x_i')\]

This means that there is only probability mass on vectors in which
\(x_i = x_i'\) (reflecting the success of control) and all other
variables are determined by their parents, given the values that have
been set for \(x_i\).
\end{frame}

\hypertarget{conditional-independence-and-d-separation}{%
\subsection{\texorpdfstring{Conditional Independence and
\(d\)-separation}{Conditional Independence and d-separation}}\label{conditional-independence-and-d-separation}}

\begin{frame}{Conditional Independence and \(d\)-separation}
\begin{itemize}
\item
  We now have a well defined sense in which the arrows on a graph
  represent a causal structure and capture the conditional independence
  relations implied by the causal structure.
\item
  Of course any graph might represent many different probability
  distributions \(P\)
\item
  We can now start reading off from a graph when there is or is not
  conditional independence between sets of variables
\end{itemize}
\end{frame}

\hypertarget{conditional-independence-on-paths}{%
\subsection{Conditional independence on
paths}\label{conditional-independence-on-paths}}

\begin{frame}{Conditional independence on paths}
\begin{figure}

{\centering \includegraphics[width=0.7\textwidth,height=\textheight]{0_lectures_files/figure-beamer/HJ-F-2-4-1.pdf}

}

\caption{Three elemental relations of conditional independence.}

\end{figure}
\end{frame}

\hypertarget{conditional-independence-1}{%
\subsection{Conditional independence}\label{conditional-independence-1}}

\begin{frame}{Conditional independence}
\(A\) and \(B\) are \emph{conditionally independent}, given \(C\) if on
\emph{every} path between \(A\) and \(B\):

\begin{itemize}
\tightlist
\item
  there is some chain (\(\bullet\rightarrow \bullet\rightarrow\bullet\)
  or \(\bullet\leftarrow \bullet\leftarrow\bullet\)) or fork
  (\(\bullet\leftarrow \bullet\rightarrow\bullet\)) with the central
  element in \(C\),
\end{itemize}

or

\begin{itemize}
\tightlist
\item
  there is an inverted fork
  (\(\bullet\rightarrow \bullet\leftarrow\bullet\)) with the central
  element (and its descendants) \emph{not} in \(C\)
\end{itemize}

Notes:

\begin{itemize}
\tightlist
\item
  In this case we say that \(A\) and \(B\) are d-separated by \(C\).
\item
  \(A\), \(B\), and \(C\) can all be sets
\item
  Note that a path can involve arrows pointing any direction
  \(\bullet\rightarrow \bullet\rightarrow \bullet\leftarrow \bullet\rightarrow\bullet\)
\end{itemize}
\end{frame}

\hypertarget{test-yourself}{%
\subsection{Test yourself}\label{test-yourself}}

\begin{frame}{Test yourself}
\begin{figure}

{\centering \includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-224-1.pdf}

}

\end{figure}

Are A and D unconditionally independent:

\begin{itemize}
\tightlist
\item
  if you do not condition on anything?
\item
  if you condition on B?
\item
  if you condition on C?
\item
  if you condition on B and C?
\end{itemize}
\end{frame}

\hypertarget{back-to-this-example}{%
\subsection{Back to this example}\label{back-to-this-example}}

\begin{frame}[fragile]{Back to this example}
\begin{verbatim}
* $Z = f_1(U_1, U_2)$
* $X = f_2(U_2)$
* $Y = f_3(X, U_1)$
\end{verbatim}

\begin{enumerate}
\tightlist
\item
  Let's graph this
\item
  Now: say we removed the arrow from \(X\) to \(Y\)

  \begin{itemize}
  \tightlist
  \item
    Would you expect to see a correlation between \(X\) and \(Y\) if you
    did not control for \(Z\)
  \item
    Would you expect to see a correlation between \(X\) and \(Y\) if you
    did control for \(Z\)
  \end{itemize}
\end{enumerate}
\end{frame}

\hypertarget{from-graphs-to-causal-models}{%
\subsection{From graphs to Causal
Models}\label{from-graphs-to-causal-models}}

\begin{frame}{From graphs to Causal Models}
A ``\textbf{causal model}'' is:

1.1: An ordered list of \(n\) endogenous nodes,
\(\mathcal{V}= (V^1, V^2,\dots, V^n)\), with a specification of a range
for each of them

1.2: A list of \(n\) exogenous nodes,
\(\Theta = (\theta^1, \theta^2,\dots , \theta^n)\)

2: A list of \(n\) functions \(\mathcal{F}= (f^1, f^2,\dots, f^n)\), one
for each element of \(\mathcal{V}\) such that each \(f^i\) takes as
arguments \(\theta^i\) as well as elements of \(\mathcal{V}\) that are
\emph{prior} to \(V^i\) in the ordering

and

3: A probability distribution over \(\Theta\)
\end{frame}

\hypertarget{from-graphs-to-causal-models-1}{%
\subsection{From graphs to Causal
Models}\label{from-graphs-to-causal-models-1}}

\begin{frame}{From graphs to Causal Models}
\begin{figure}

{\centering \includegraphics[width=0.8\textwidth,height=\textheight]{0_lectures_files/figure-beamer/HJ-F-2-1-1.pdf}

}

\caption{A simple causal model in which high inequality (\(I\)) affects
democratization (\(D\)) via redistributive demands (\(R\)) and mass
mobilization (\(M\)), which is also a function of ethnic homogeneity
(\(E\)). Arrows show relations of causal dependence between variables.}

\end{figure}
\end{frame}

\begin{frame}{Effects on a DAG}
\protect\hypertarget{effects-on-a-dag}{}
Learning about effects \emph{given} a model means learning about \(F\)
and \emph{also} the distribution of shocks (\(\Theta\)).

For discrete data this can be reduced to a question about learning about
the distribution of \(\Theta\) only.
\end{frame}

\hypertarget{recap-key-features-of-graphs}{%
\subsection{Recap: Key features of
graphs}\label{recap-key-features-of-graphs}}

\begin{frame}{Recap: Key features of graphs}
\begin{itemize}
\tightlist
\item
  Directed
\item
  Acyclic
\item
  The missing arcs are the really important ones
\item
  Implicitly there are shocks going into every node
\item
  These graphs represent Nonparametric structural equation models NPSEMs
\item
  But you cannot read off the size or direction of effects from a DAG
\end{itemize}
\end{frame}

\begin{frame}{Recap: Ten things you need to know about causal inference}
\protect\hypertarget{recap-ten-things-you-need-to-know-about-causal-inference}{}
\begin{enumerate}
\tightlist
\item
  A causal claim is a statement about what didn't happen.
\item
  There is a fundamental problem of causal inference.
\item
  You can estimate average causal effects even if you cannot observe any
  individual causal effects.
\item
  If you know that \(A\) causes \(B\) and that \(B\) causes \(C\), this
  does not mean that you know that \(A\) causes \(C\).
\item
  The counterfactual model is primarily about contribution, and about
  attribution in a limited sense.
\item
  \(X\) can cause \(Y\) even if there is no ``causal path'' connecting
  \(X\) and \(Y\).
\item
  Correlation is not causation.
\item
  \(X\) can cause \(Y\) even if \(X\) is not a necessary condition or a
  sufficient condition for \(Y\).
\item
  Estimating average causal effects does not require that treatment and
  control groups are identical.
\item
  There is no causation without manipulation.
\end{enumerate}

\url{http://egap.org/resources/guides/causality/}
\end{frame}

\hypertarget{inquiries-2}{%
\section{\texorpdfstring{Inquiries
\label{estimands}}{Inquiries }}\label{inquiries-2}}

\hypertarget{estimands-and-inquiries}{%
\subsection{Estimands and inquiries}\label{estimands-and-inquiries}}

\begin{frame}{Estimands and inquiries}
\begin{itemize}
\tightlist
\item
  Your inquiry is your question and the estimand is the true (generally
  unknown) answer to the inquiry
\item
  The estimand is the thing you want to estimate
\item
  If you are estimating something you should be able to say what your
  estimand is
\item
  You are responsible for your estimand. Your estimator will not tell
  you what your estimand is
\item
  Just because you can calculate something does not mean that you have
  an estimand
\item
  You can test a hypothesis without having an estimand
\end{itemize}

Read:
\href{https://macartan.github.io/integrated_inferences/HJC4.html}{II ch
4},
\href{https://book.declaredesign.org/declaration-diagnosis-redesign/defining-inquiry.html}{DD,
ch 7}
\end{frame}

\begin{frame}{Estimands: ATE, ATT, ATC, S-, P-, C-, ITT, LATE}
\protect\hypertarget{estimands-ate-att-atc-s--p--c--itt-late}{}
Say that units are randomly assigned to treatment in different strata
(maybe just one); with fixed, though possibly different, shares assigned
in each stratum. Then the key estimands and estimators are:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.4356}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5644}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Estimand
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Estimator
\end{minipage} \\
\midrule\noalign{}
\endhead
\(\tau_{ATE} \equiv \mathbb{E}[\tau_i]\) &
\(\widehat{\tau}_{ATE} = \sum\nolimits_{x} \frac{w_x}{\sum\nolimits_{j}w_{j}}\widehat{\tau}_x\) \\
\(\tau_{ATT} \equiv \mathbb{E}[\tau_i | Z_i = 1]\) &
\(\widehat{\tau}_{ATT} = \sum\nolimits_{x} \frac{p_xw_x}{\sum\nolimits_{j}p_jw_j}\widehat{\tau}_x\) \\
\(\tau_{ATC} \equiv \mathbb{E}[\tau_i | Z_i = 0]\) &
\(\widehat{\tau}_{ATC} = \sum\nolimits_{x} \frac{(1-p_x)w_x}{\sum\nolimits_{j}(1-p_j)w_j}\widehat{\tau}_x\) \\
\bottomrule\noalign{}
\end{longtable}

where \(x\) indexes strata, \(p_x\) is the share of units in each
stratum that is treated, and \(w_x\) is the size of a stratum.

Here:

\begin{itemize}
\tightlist
\item
  ATE is Average Treatment Effect (all units)
\item
  ATT is Average Treatment Effect on the Treated
\item
  ATC is Average Treatment Effect on the Controls
\end{itemize}
\end{frame}

\begin{frame}{Estimands: ATE, ATT, ATC, S-, P-, C-}
\protect\hypertarget{estimands-ate-att-atc-s--p--c-}{}
In addition, each of these can be targets of interest:

\begin{itemize}
\tightlist
\item
  for the \textbf{population}, in which case we refer to PATE, PATT,
  PATC and \(\widehat{PATE}, \widehat{PATT}, \widehat{PATC}\)
\item
  for a \textbf{sample}, in which case we refer to SATE, SATT, SATC, and
  \(\widehat{SATE}, \widehat{SATT}, \widehat{SATC}\)
\end{itemize}

And for different subgroups,

\begin{itemize}
\tightlist
\item
  given some value on a covariate, in which case we refer to CATE
  (conditional average treatment effect)
\end{itemize}
\end{frame}

\begin{frame}{Broader classes of estimands: LATE/CATE}
\protect\hypertarget{broader-classes-of-estimands-latecate}{}
The CATEs are \textbf{conditional} average treatment effects, for
example the effect for men or for women. These are straightfoward.

However we might also imagine conditioning on unobservable or
counterfactual features.

\begin{itemize}
\tightlist
\item
  The LATE (or CACE: complier average causal effect) asks about the
  effect of a treatment (\(X\)) on an outcome (\(Y\)) \emph{for people
  that are responsive to an encouragement} (\(Z\))
\end{itemize}

\[LATE =  \frac{1}{|C|}\sum_{j\in C}(Y_j(X=1) - Y_j(X=0))\]
\[C:=\{j:X_j(Z=1) > X_j(Z=0) \}\]

We will return to these in the study of instrumental variables.
\end{frame}

\begin{frame}{Quantile estimands}
\protect\hypertarget{quantile-estimands}{}
Other ways to condition on potential outcomes:

\begin{itemize}
\tightlist
\item
  A \emph{quantile} treatment effect: You might be interested in the
  difference between the median \(Y(1)\) and the median \(Y(0)\)
  (@imbens2015causal 20.3.1)
\item
  or even be interested in the median \(Y(1) - Y(0)\). Similarly for
  other quantiles.
\end{itemize}
\end{frame}

\begin{frame}{Model estimands}
\protect\hypertarget{model-estimands}{}
Many inquiries are averages of individual effects, even if the groups
are not known, but they do not have to be:

\begin{itemize}
\tightlist
\item
  The RDD estimand is a statement about what effects \emph{would be} at
  a threshold; it can be defined under a model even if no actual
  individuals are at the threshold. We imagine average potential
  outcomes as a function of treatment \(Z\) and running variable \(X\),
  \(f(z, x)\) and define: \[\tau_{RDD} := f(1, x^*) - f(0, x^*)\]
\end{itemize}
\end{frame}

\begin{frame}{Distribution estimands}
\protect\hypertarget{distribution-estimands}{}
Many inquiries are averages of individual effects, even if the groups
are not known,

But they do not have to be:

\begin{itemize}
\item
  Inquiries might relate to distributional quantities such as:

  \begin{itemize}
  \tightlist
  \item
    The effect of treatment on the variance in outcomes:
    \(var(Y(1)) - var(Y(0))\)
  \item
    The variance of treatment effects: \(var(Y(1) - Y(0))\)
  \item
    Other inequality measures (e.g.~Ginis; (@imbens2015causal 20.3.2))
  \end{itemize}
\end{itemize}

You might even be interested in \(\min(Y_i(1) - Y_i(0))\).
\end{frame}

\begin{frame}{Spillover estimands}
\protect\hypertarget{spillover-estimands}{}
There are lots of interesting ``spillover'' estimands.

Imagine there are three individuals and each person's outcomes depends
on the assignments of all others. For instance \(Y_1(Z_1, Z_2, Z_3\), or
more generally,
\(Y_i(Z_i, Z_{i+1 (\text{mod }3)}, Z_{i+2 (\text{mod }3)})\).

Then three estimands might be:

\begin{itemize}
\tightlist
\item
  \(\frac13\left(\sum_{i}{Y_i(1,0,0) - Y_i(0,0,0)}\right)\)
\item
  \(\frac13\left(\sum_{i}{Y_i(1,1,1) - Y_i(0,0,0)}\right)\)
\item
  \(\frac13\left(\sum_{i}{Y_i(0,1,1) - Y_i(0,0,0)}\right)\)
\end{itemize}

Interpret these. What others might be of interest?
\end{frame}

\begin{frame}{Differnces in CATEs and interaction estimands}
\protect\hypertarget{differnces-in-cates-and-interaction-estimands}{}
A difference in CATEs is a well defined estimand that might involve
interventions on one node only:

\begin{itemize}
\tightlist
\item
  \(\mathbb{E}_{\{W=1}\}[Y(X=1) - Y(X=0)] - \mathbb{E}_{\{W=0\}}[Y(X=1) - Y(X=0)]\)
\end{itemize}

It captures differences in effects.

An \emph{interaction} is an effect on an effect:

\begin{itemize}
\tightlist
\item
  \(\mathbb{E}[Y(X=1, W=1) - Y(X=0, W=1)] - \mathbb{E}[Y(X=1, W=0) - Y(X=0, W=0)]\)
\end{itemize}

Note in the latter the expectation is taken over the whole population.
\end{frame}

\begin{frame}{Mediation estimands and complex counterfactuals}
\protect\hypertarget{mediation-estimands-and-complex-counterfactuals}{}
Say \(X\) can affect \(Y\) directly, or indirectly through \(M\). then
we can write potential outcomes as:

\begin{itemize}
\tightlist
\item
  \(Y(X=x, M=m)\)
\item
  \(M(X=x)\)
\end{itemize}

We can then imagine inquiries of the form:

\begin{itemize}
\tightlist
\item
  \(Y(X=1, M=M(X=1)) - Y(X=0, M=M(X=0))\)
\item
  \(Y(X=1, M=1) - Y(X=0, M=1)\)
\item
  \(Y(X=1, M=M(X=1)) - Y(X=1, M=M(X=0))\)
\end{itemize}

Interpret these. What others might be of interest?
\end{frame}

\begin{frame}{Mediation estimands and complex counterfactuals}
\protect\hypertarget{mediation-estimands-and-complex-counterfactuals-1}{}
Again we might imagine that these are defined with respect to some
group:

\begin{itemize}
\tightlist
\item
  \(A = \{i|Y_i(1, M(X=1)) > Y_i(0, M(X=0))\}\)
\item
  \(\frac{1}{|A|} \sum_{i\in A}(Y(1, 1) > Y(0, 1))\)
\end{itemize}

here, among those for whom \(X\) has a positive effect on \(Y\), for
what share would there be a positive effect if \(M\) were fixed at 1.
\end{frame}

\begin{frame}{Causes of effects and effects of causes}
\protect\hypertarget{causes-of-effects-and-effects-of-causes}{}
In qualitative research a particularly common inquiry is ``did \(X=1\)
cause \(Y=1\)?

This is often given as a probability, the ``probability of causation''
(though at the case level we might better think of this probabiliy as an
estimate rather than an estimand):

\[\Pr(Y_i(0) = 0 | Y_i(1) = 1, X = 1)\]
\end{frame}

\begin{frame}{Causes of effects and effects of causes}
\protect\hypertarget{causes-of-effects-and-effects-of-causes-1}{}
Intuition: What's the probability \(X=1\) caused \(Y=1\) in an
\(X=1, Y=1\) case drawn from a large population with the following
experimental distribution:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
& Y=0 & Y=1 & All \\
\midrule\noalign{}
\endhead
X=0 & 1 & 0 & 1 \\
X=1 & 0.25 & 0.75 & 1 \\
\bottomrule\noalign{}
\end{longtable}
\end{frame}

\begin{frame}{Causes of effects and effects of causes}
\protect\hypertarget{causes-of-effects-and-effects-of-causes-2}{}
Intuition: What's the probability \(X=1\) caused \(Y=1\) in an
\(X=1, Y=1\) case drawn from a large population with the following
experimental distribution:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
& Y=0 & Y=1 & All \\
\midrule\noalign{}
\endhead
X=0 & 0.75 & 0.25 & 1 \\
X=1 & 0.25 & 0.75 & 1 \\
\bottomrule\noalign{}
\end{longtable}
\end{frame}

\begin{frame}{Actual causation}
\protect\hypertarget{actual-causation}{}
Other inquiries focus on distinguishing between causes.

For the Billy Suzy problem {[}@hall2004two{]}, @halpern2016actual
focuses on ``actual causation'' as a way to distinguish between Suzy and
Billy:

\begin{quote}
Imagine Suzy and Billy, simultaneously throwing stones at a bottle. Both
are excellent shots and hit whatever they aim at. Suzy's stone hits
first, knocks over the bottle, and the bottle breaks. However, Billy's
stone \emph{would} have hit had Suzy's not hit, and again the bottle
would have broken. Did Suzy's throw cause the bottle to break? Did
Billy's?
\end{quote}
\end{frame}

\begin{frame}{Actual causation}
\protect\hypertarget{actual-causation-1}{}
Actual Causation:

\begin{enumerate}
\tightlist
\item
  \(X=x\) and \(Y=y\) both happened;
\item
  there is some set of variables, \(\mathcal W\), such that if they were
  fixed at the levels that they \emph{actually took} on in the case, and
  if \(X\) were to be changed, then \(Y\) would change (where
  \(\mathcal W\) can also be an empty set);
\item
  no strict subset of \(X\) satisfies 1 and 2 (there is no redundant
  part of the condition, \(X=x\)).
\end{enumerate}
\end{frame}

\begin{frame}{Actual causation}
\protect\hypertarget{actual-causation-2}{}
\begin{itemize}
\tightlist
\item
  Suzy: Condition 2 is met if Suzy's throw made a difference,
  counterfactually speaking---with the important caveat that, in
  determining this, we are permitted to condition on Billy' stone not
  hitting the bottle.
\item
  Billy: Condition 2 is not met.
\end{itemize}

An inquiry: for what share in a population is a possible cause an actual
cause?
\end{frame}

\hypertarget{pearls-ladder}{%
\subsection{Pearl's ladder}\label{pearls-ladder}}

\hypertarget{inquiries-as-statements-about-principal-strata}{%
\subsection{Inquiries as statements about principal
strata}\label{inquiries-as-statements-about-principal-strata}}

\hypertarget{identification}{%
\subsection{Identification}\label{identification}}

\begin{frame}{Identification}
\emph{What it is. When you have it. What it's worth.}
\end{frame}

\begin{frame}{Identification}
\protect\hypertarget{identification-1}{}
Informally a quantity is ``identified'' if it can be ``recovered'' once
you have enough data.

Say for example average wage is \(x\) in some very large population. If
I gather lots and lots of data on the wages of individuals and take the
average then then my estimate will ultimately let be figure out \(x\).
If \(x\) is \(1\) then by estimate will end up centered on \$1. If it is
\$2 it will end up centered on \$2.

\textbf{Essentially}: Each underlying value produces a unique data
distribution. When you see that distribution you recover the parameter.
\end{frame}

\begin{frame}{Identification (Example without identification)}
\protect\hypertarget{identification-example-without-identification}{}
Informally a quantity is ``identified'' if it can be ``recovered'' once
you have enough data.

\begin{itemize}
\tightlist
\item
  Say for example average wage is \(x^m\) for men and \(x^w\) for women
  (in some very large population).
\item
  If I gather lots and lots of data on the wages of (male and female)
  couples, e.g.~\(x^c_i = x^m_i + x^w_i\) then, although this will be
  informative, it will never be sufficient to recover \(x^m\) for men
  and \(x^w\).
\item
  I can recover \(x^c\), but there are too many combinations of possible
  values of \(x^m\) and \(x^w\) consistent with the observed data.
\end{itemize}
\end{frame}

\begin{frame}{Identification : Goal}
\protect\hypertarget{identification-goal}{}
Our goal in causal inference is to estimate quantities such as:

\[\Pr(Y|\hat{x})\]

where \(\hat{x}\) is interpreted as \(X\) set to \(x\) by ``external''
control. Equivalently: \(do(X=x)\) or sometimes \(X \leftarrow x\).

If this quantity is \textbf{identifiable} then we can recover it with
infinite data.

If it is not identifiable, then, even in the best case, we are not
guaranteed to get the right answer.

Are there general rules for determining whether this quantitiy can be
identified? Yes.
\end{frame}

\begin{frame}{Identification : Goal}
\protect\hypertarget{identification-goal-1}{}
Note first, identifying

\[\Pr(Y|x)\]

is easy.

But we are not interested in identifying the distribution of \(Y\) given
observed values of \(x\), but rather, the distribution of \(Y\) if \(X\)
is \emph{set} to \(x\).
\end{frame}

\hypertarget{levels-and-effects}{%
\subsection{Levels and effects}\label{levels-and-effects}}

\begin{frame}{Levels and effects}
If we can identify the controlled disteribution we can calculate other
causal quantities of interest.

For example for a binary \(X, Y\) the causal effect of \(X\) on the
probability that \(Y=1\) is:

\[\Pr(Y=1|\hat{x}=1) - \Pr(Y=1|\hat{x}=0)\]

Again, \textbf{this is not the same as}:

\[\Pr(Y=1|x=1) - \Pr(Y=1|x=0)\]

It's the difference between seeing and doing.
\end{frame}

\begin{frame}[fragile]{When to condition? What to condition on?}
\protect\hypertarget{when-to-condition-what-to-condition-on}{}
The key idea is that you want to find a set of variables such that when
you condition on these you get what you would get if you used a
\texttt{do} operation.

Intuition:

\begin{itemize}
\tightlist
\item
  You could imagine creating a ``mutilated'' graph by removing all the
  arrows leading \emph{out} of \emph{X}
\item
  Then select a set of variables, \(Z\), such that \(X\) and \(Y\) are
  d-separated by \(Z\) on the the mutilated graph
\item
  When you condition on these you are making sure that any covariation
  between \(X\) and \(Y\) is covariation that is due to the effects of
  \(X\)
\end{itemize}
\end{frame}

\begin{frame}{Illustration}
\protect\hypertarget{illustration}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-236-1.pdf}
\end{frame}

\begin{frame}{Illustration: Remove paths out}
\protect\hypertarget{illustration-remove-paths-out}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-237-1.pdf}
\end{frame}

\begin{frame}{Illustration: Block backdoor path}
\protect\hypertarget{illustration-block-backdoor-path}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-238-1.pdf}
\end{frame}

\begin{frame}{Illustration: Why not like this?}
\protect\hypertarget{illustration-why-not-like-this}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-239-1.pdf}
\end{frame}

\begin{frame}{Identification}
\protect\hypertarget{identification-2}{}
\begin{itemize}
\tightlist
\item
  Three results (``Graphical Identification Criteria'')

  \begin{itemize}
  \tightlist
  \item
    Backdoor criterion
  \item
    Adjustment criterion
  \item
    Frontdoor criterion
  \end{itemize}
\item
  There are more
\end{itemize}
\end{frame}

\begin{frame}{Backdoor Criterion: (Pearl 1995)}
\protect\hypertarget{backdoor-criterion-pearl-1995}{}
The \textbf{backdoor criterion} is satisfied by \(Z\) (relative to
\(X\), \(Y\)) if:

\begin{enumerate}
\tightlist
\item
  No node in \(Z\) is a descendant of \(X\)
\item
  \(Z\) blocks every \textbf{backdoor} path from \(X\) to \(Y\)
  (i.e.~every path that contains an arrow into \(X\))
\end{enumerate}

In that case you can identify the effect of \(X\) on \(Y\) by
conditioning on \(Z\):

\[P(Y=y | \hat{x}) = \sum_z P(Y=y| X = x, Z=z)P(z)\] (This is eqn 3.19
in Pearl (2000))
\end{frame}

\begin{frame}{Backdoor Criterion: (Pearl 1995)}
\protect\hypertarget{backdoor-criterion-pearl-1995-1}{}
\[P(Y=y | \hat{x}) = \sum_z P(Y=y| X = x, Z=z)P(z)\]

\begin{itemize}
\tightlist
\item
  Note notion of a linear control of anything like that; idea really is
  like blocking: think lots of discrete data and no missing patterns
\item
  Note this is a formula for a (possibly counterfactual) \emph{level}; a
  counterfactual difference would be given in the obvious way by:
\end{itemize}

\[P(Y=y | \hat{x}) - P(Y=y | \hat{x}') = \sum_z P(Y=y| X = x, Z=z)P(z) - \sum_z P(Y=y| X = x', Z=z)P(z)\]
\end{frame}

\begin{frame}{Backdoor Proof}
\protect\hypertarget{backdoor-proof}{}
Following Pearl (2009), Chapter 11. Let \(T\) denote the set of parents
of \(X\): \(T := pa(X)\), with (possibly vector valued) realizations
\(t\).

If the backdoor criterion is satisfied, we have:

\begin{enumerate}
\tightlist
\item
  \(Y\) is independent of \(T\), given \(X\) and observed data, \(Z\)
  (since \(Z\) blocks backdoor paths)
\item
  \(X\) is independent of \(Z\) given \(T\). (Since \(Z\) includes only
  nondescendents)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  From the DAG we have:
  \[p(y|\hat{x}) = \sum_{t\in T} p(t)p(y|\hat{x}, t)\]
\end{itemize}
\end{frame}

\begin{frame}{Backdoor Proof}
\protect\hypertarget{backdoor-proof-1}{}
\begin{itemize}
\item
  But we do not observe \(T\), rather we observe \(Z\). OK, but we can
  write:
  \[p(y|\hat{x}) = \sum_{t\in T} p(t) \sum_z p(y|\hat{x}, t, z)p(z|\hat{x}, pa(X))\]
\item
  Then using the two conditions above:

  \begin{enumerate}
  \tightlist
  \item
    replace \(p(y|\hat{x}, pa(X), z)\) with \(p(y, \hat{x}, z)\)
  \item
    replace \(p(z|\hat{x}, pa(X))\) with \(p(z|\hat{x})\)
  \end{enumerate}
\end{itemize}

This gives:
\[p(y|\hat{x}) = \sum_{pa(X)} p(pa(X)) \sum_z p(y|\hat{x}, z)p(z|pa(X)) \]
\end{frame}

\begin{frame}{Now Clean up:}
\protect\hypertarget{now-clean-up}{}
\[p(y|\hat{x}) = \sum_{pa(X)} p(pa(X)) \sum_z p(y|\hat{x}, z)p(z|pa(X))\]
\[\leftrightarrow\]
\[p(y|\hat{x}) =  \sum_z p(y|\hat{x}, z)\sum_{pa(X)} p(pa(X))p(z|pa(X)) = \sum_z p(y|\hat{x})p(z)\]
\end{frame}

\begin{frame}{Adjustment criterion}
\protect\hypertarget{adjustment-criterion}{}
See @shpitser2012validity

The adjustment criterion is satisfied by \(Z\) (relative to \(X\),
\(Y\)) if:

\begin{enumerate}
\tightlist
\item
  no element of \(Z\) is a descendant (in the mutilated
  graph\footnote<.->{remove arrows pointing into \(X\)}) of any variable
  \(W\not\in X\) which lies on a proper causal path from \(X\) to
  \(Y\)\footnote<.->{A \emph{proper} causal pathway nodes in \(X\) to
    nodes in \(Y\) only intersects \(X\) at the endpoint}
\item
  \(Z\) blocks all \textbf{noncausal paths} from \(X\) to \(Y\)
\end{enumerate}
\end{frame}

\begin{frame}{These are different. Simple illustration.}
\protect\hypertarget{these-are-different.-simple-illustration.}{}
Here \(Z\) satisfies the adjustment criterion but not the backdoor
criterion:

\begin{figure}

{\centering \includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-240-1.pdf}

}

\end{figure}

\(Z\) is descendant of \(X\) but it does not a descendant of a node on a
path from \(X\) to \(Y\). No harm adjusting for \(Z\) here, but not
necessary either.
\end{frame}

\begin{frame}{Frontdoor criterion}
\protect\hypertarget{frontdoor-criterion}{}
\end{frame}

\begin{frame}[fragile]{In code: Dagitty}
\protect\hypertarget{in-code-dagitty}{}
There is a package for this

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(dagitty)}
\end{Highlighting}
\end{Shaded}

Then define a dag using dagitty syntax:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OtherTok{\textless{}{-}} \FunctionTok{dagitty}\NormalTok{(}\StringTok{"dag\{X {-}\textgreater{} M {-}\textgreater{} Y ; Z {-}\textgreater{} X ; Z {-}\textgreater{} R {-}\textgreater{} Y\}"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

There is then a simple command to check whether two sets are d-separated
by a third set:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dseparated}\NormalTok{(g, }\StringTok{"X"}\NormalTok{, }\StringTok{"Y"}\NormalTok{, }\StringTok{"M"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dseparated}\NormalTok{(g, }\StringTok{"X"}\NormalTok{, }\StringTok{"Y"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"Z"}\NormalTok{,}\StringTok{"M"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Dagitty: Find adjustment sets}
\protect\hypertarget{dagitty-find-adjustment-sets}{}
And a simple command to identify the adjustments needed to identify the
effect of one variable on another:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{adjustmentSets}\NormalTok{(g, }\AttributeTok{exposure =} \StringTok{"X"}\NormalTok{, }\AttributeTok{outcome =} \StringTok{"Y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{ R }
{ Z }
\end{verbatim}
\end{frame}

\begin{frame}{Important Examples : Confounding}
\protect\hypertarget{important-examples-confounding}{}
Example where \(Z\) is correlated with \(X\) and \(Y\) and is a
confounder

\begin{figure}

{\centering \includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-245-1.pdf}

}

\end{figure}
\end{frame}

\begin{frame}{Confounding}
\protect\hypertarget{confounding}{}
Example where \(Z\) is correlated with \(X\) and \(Y\) but it is
\emph{not} a confounder

\begin{figure}

{\centering \includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-246-1.pdf}

}

\end{figure}
\end{frame}

\begin{frame}{Important Examples : Collider}
\protect\hypertarget{important-examples-collider}{}
But controlling can also cause problems. In fact conditioning on a
temporally pre-treatment variable could cause problems. Who'd have
thunk? Here is an example from Pearl (2005):

\begin{figure}

{\centering \includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-247-1.pdf}

}

\end{figure}
\end{frame}

\begin{frame}[fragile]{Illustration of identification failure from
conditioning on a collider}
\protect\hypertarget{illustration-of-identification-failure-from-conditioning-on-a-collider}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{U1 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{10000}\NormalTok{);  U2 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{10000}\NormalTok{)}
\NormalTok{Z  }\OtherTok{\textless{}{-}}\NormalTok{ U1}\SpecialCharTok{+}\NormalTok{U2}
\NormalTok{X  }\OtherTok{\textless{}{-}}\NormalTok{ U2 }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\SpecialCharTok{/}\DecValTok{2}
\NormalTok{Y  }\OtherTok{\textless{}{-}}\NormalTok{ U1}\SpecialCharTok{*}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ X}

\FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X) }\SpecialCharTok{|\textgreater{}} \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
(Intercept) & -0.02 & 0.02 & -0.85 & 0.39 & -0.06 & 0.02 & 9998 & Y\\
\hline
X & 0.98 & 0.02 & 54.27 & 0.00 & 0.94 & 1.02 & 9998 & Y\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X }\SpecialCharTok{+}\NormalTok{ Z) }\SpecialCharTok{|\textgreater{}} \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
(Intercept) & -0.01 & 0.01 & -0.65 & 0.51 & -0.02 & 0.01 & 9997 & Y\\
\hline
X & -0.33 & 0.01 & -35.01 & 0.00 & -0.35 & -0.31 & 9997 & Y\\
\hline
Z & 1.67 & 0.01 & 225.73 & 0.00 & 1.65 & 1.68 & 9997 & Y\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Let's look at that in dagitty}
\protect\hypertarget{lets-look-at-that-in-dagitty}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OtherTok{\textless{}{-}} \FunctionTok{dagitty}\NormalTok{(}\StringTok{"dag\{U1 {-}\textgreater{} Z  ; U1 {-}\textgreater{} y ; U2 {-}\textgreater{} Z ; U2 {-}\textgreater{} x  {-}\textgreater{} y\}"}\NormalTok{)}
\FunctionTok{adjustmentSets}\NormalTok{(g, }\AttributeTok{exposure =} \StringTok{"x"}\NormalTok{, }\AttributeTok{outcome =} \StringTok{"y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 {}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{isAdjustmentSet}\NormalTok{(g, }\StringTok{"Z"}\NormalTok{, }\AttributeTok{exposure =} \StringTok{"x"}\NormalTok{, }\AttributeTok{outcome =} \StringTok{"y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{isAdjustmentSet}\NormalTok{(g, }\ConstantTok{NULL}\NormalTok{, }\AttributeTok{exposure =} \StringTok{"x"}\NormalTok{, }\AttributeTok{outcome =} \StringTok{"y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] TRUE
\end{verbatim}

Which means, no need to condition on anything.
\end{frame}

\begin{frame}{Collider \& Confounder}
\protect\hypertarget{collider-confounder}{}
A bind: from Pearl 1995.

\begin{figure}

{\centering \includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-250-1.pdf}

}

\end{figure}

For a solution for a class of related problems see @robins2000marginal
\end{frame}

\begin{frame}[fragile]{Let's look at that in dagitty}
\protect\hypertarget{lets-look-at-that-in-dagitty-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OtherTok{\textless{}{-}} \FunctionTok{dagitty}\NormalTok{(}\StringTok{"dag\{U1 {-}\textgreater{} Z  ; U1 {-}\textgreater{} y ; }
\StringTok{             U2 {-}\textgreater{} Z ; U2 {-}\textgreater{} x  {-}\textgreater{} y; }
\StringTok{             Z {-}\textgreater{} x\}"}\NormalTok{)}
\FunctionTok{adjustmentSets}\NormalTok{(g, }\AttributeTok{exposure =} \StringTok{"x"}\NormalTok{, }\AttributeTok{outcome =} \StringTok{"y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
{ U1 }
{ U2, Z }
\end{verbatim}

which means you have to adjust on an unobservable. Here we double check
that including or not including ``Z'' is enough:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{isAdjustmentSet}\NormalTok{(g, }\StringTok{"Z"}\NormalTok{, }\AttributeTok{exposure =} \StringTok{"x"}\NormalTok{, }\AttributeTok{outcome =} \StringTok{"y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{isAdjustmentSet}\NormalTok{(g, }\ConstantTok{NULL}\NormalTok{, }\AttributeTok{exposure =} \StringTok{"x"}\NormalTok{, }\AttributeTok{outcome =} \StringTok{"y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] FALSE
\end{verbatim}
\end{frame}

\hypertarget{frequentist-analysis}{%
\section{\texorpdfstring{Frequentist Analysis
\label{L_inference}}{Frequentist Analysis }}\label{frequentist-analysis}}

\begin{frame}{Frequentist Analysis \label{L_inference}}
\hyperlink{ideas}{\beamergotobutton{Top}}
\end{frame}

\hypertarget{basic-analysis}{%
\subsection{\texorpdfstring{Basic Analysis
\label{nools}}{Basic Analysis }}\label{basic-analysis}}

\begin{frame}{Basic Analysis \label{nools}}
\begin{itemize}
\tightlist
\item
  Simple estimates from experimental data
\item
  Weighting, blocking
\item
  Doubly robust estimation
\item
  Design based variance estimates
\item
  Design based \(p\) values
\item
  Reporting
\end{itemize}
\end{frame}

\begin{frame}{ATE: DIM}
\protect\hypertarget{ate-dim}{}
Unbiased estimates of the (sample) average treatment effect can be
estimated (\textbf{whether or not there imbalance on covariates}) using:

\[
\widehat{ATE} = \frac{1}{n_T}\sum_TY_i - \frac{1}{n_C}\sum_CY_i,
\]
\end{frame}

\begin{frame}[fragile]{ATE: DIM in practice}
\protect\hypertarget{ate-dim-in-practice}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ fabricatr}\SpecialCharTok{::}\FunctionTok{fabricate}\NormalTok{(}\AttributeTok{N =} \DecValTok{100}\NormalTok{, }\AttributeTok{Z =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, N}\SpecialCharTok{/}\DecValTok{2}\NormalTok{), }\AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N) }\SpecialCharTok{+}\NormalTok{ Z)}

\CommentTok{\# by hand}
\NormalTok{df }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{Y1 =} \FunctionTok{mean}\NormalTok{(Y[Z}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]), }
            \AttributeTok{Y0 =} \FunctionTok{mean}\NormalTok{(Y[Z}\SpecialCharTok{==}\DecValTok{0}\NormalTok{]), }
            \AttributeTok{diff =}\NormalTok{ Y1 }\SpecialCharTok{{-}}\NormalTok{ Y0) }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r}
\hline
Y1 & Y0 & diff\\
\hline
1.07 & -0.28 & 1.35\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# with estimatr}
\NormalTok{estimatr}\SpecialCharTok{::}\FunctionTok{difference\_in\_means}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ df) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
Z & 1.35 & 0.17 & 7.94 & 0 & 1.01 & 1.68 & 97.98 & Y\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{ATE: DIM in practice}
\protect\hypertarget{ate-dim-in-practice-1}{}
We can also do this with regression:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estimatr}\SpecialCharTok{::}\FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ df) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
(Intercept) & -0.28 & 0.12 & -2.33 & 0.02 & -0.51 & -0.04 & 98 & Y\\
\hline
Z & 1.35 & 0.17 & 7.94 & 0.00 & 1.01 & 1.68 & 98 & Y\\
\hline
\end{tabular}

See @freedman2008regression on why regression is fine here
\end{frame}

\begin{frame}{ATE: Blocks}
\protect\hypertarget{ate-blocks}{}
Say now different strata or blocks \(\mathcal{S}\) had different
\emph{assignment probabilities}. Then you could estimate:

\begin{equation} \widehat{ATE} = \sum_{S\in \mathcal{S}}\frac{n_{S}}{n} \left(\frac{1}{n_{S1}}\sum_{S\cap T}y_i - \frac{1}{n_{S0}}\sum_{S\cap C}y_i \right) \end{equation}

Note: you cannot just ignore the blocks because assignment is no longer
independent of potential outcomes: you might be sampling units with
different potential outcomes with different probabilities.

However, the formula above works fine because selecting is random
\emph{conditional} on blocks.
\end{frame}

\hypertarget{ate-blocks-in-practice}{%
\subsection{ATE: Blocks in practice}\label{ate-blocks-in-practice}}

\begin{frame}[fragile]{ATE: Blocks in practice}
Data with heterogeneous assignments:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ fabricatr}\SpecialCharTok{::}\FunctionTok{fabricate}\NormalTok{(}
  \AttributeTok{N =} \DecValTok{500}\NormalTok{, }\AttributeTok{X =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, N}\SpecialCharTok{/}\DecValTok{2}\NormalTok{), }
  \AttributeTok{prob =}\NormalTok{ .}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ .}\DecValTok{3}\SpecialCharTok{*}\NormalTok{X,}
  \AttributeTok{Z =} \FunctionTok{rbinom}\NormalTok{(N, }\DecValTok{1}\NormalTok{, prob),}
  \AttributeTok{ip =} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(Z}\SpecialCharTok{*}\NormalTok{prob }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{Z)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{prob)), }\CommentTok{\# discuss}
  \AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N) }\SpecialCharTok{+}\NormalTok{ Z}\SpecialCharTok{*}\NormalTok{X)}
\end{Highlighting}
\end{Shaded}

True effect is 0.5, but:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estimatr}\SpecialCharTok{::}\FunctionTok{difference\_in\_means}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ df) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
Z & 0.9 & 0.1 & 9.32 & 0 & 0.71 & 1.09 & 377.93 & Y\\
\hline
\end{tabular}
\end{frame}

\hypertarget{ate-blocks-in-practice-1}{%
\subsection{ATE: Blocks in practice}\label{ate-blocks-in-practice-1}}

\begin{frame}[fragile]{ATE: Blocks in practice}
Averaging over effects in blocks ::: \{.cell\}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# by hand}
\NormalTok{estimates }\OtherTok{\textless{}{-}} 
\NormalTok{  df }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(X) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{Y1 =} \FunctionTok{mean}\NormalTok{(Y[Z}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]), }
            \AttributeTok{Y0 =} \FunctionTok{mean}\NormalTok{(Y[Z}\SpecialCharTok{==}\DecValTok{0}\NormalTok{]), }
            \AttributeTok{diff =}\NormalTok{ Y1 }\SpecialCharTok{{-}}\NormalTok{ Y0,}
            \AttributeTok{W =} \FunctionTok{n}\NormalTok{())}

\NormalTok{estimates}\SpecialCharTok{$}\NormalTok{diff }\SpecialCharTok{|\textgreater{}} \FunctionTok{weighted.mean}\NormalTok{(estimates}\SpecialCharTok{$}\NormalTok{W)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.7236939
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# with estimatr}
\NormalTok{estimatr}\SpecialCharTok{::}\FunctionTok{difference\_in\_means}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{blocks =}\NormalTok{ X, }\AttributeTok{data =}\NormalTok{ df) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
Z & 0.72 & 0.11 & 6.66 & 0 & 0.51 & 0.94 & 496 & Y\\
\hline
\end{tabular}

:::
\end{frame}

\begin{frame}{ATE with IPW}
\protect\hypertarget{ate-with-ipw}{}
This also corresponds to the difference in the weighted average of
treatment outcomes (with weights given by the inverse of the probability
that each unit is assigned to treatment) and control outcomes (with
weights given by the inverse of the probability that each unit is
assigned to control).

\begin{itemize}
\tightlist
\item
  The average difference in means estimator is the same as what you
  would get if you weighted inversely by shares of units in different
  conditions inside blocks.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{ATE with IPW in practice}
\protect\hypertarget{ate-with-ipw-in-practice}{}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# by hand}
\NormalTok{df }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{Y1 =} \FunctionTok{weighted.mean}\NormalTok{(Y[Z}\SpecialCharTok{==}\DecValTok{1}\NormalTok{], ip[Z}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]), }
            \AttributeTok{Y0 =} \FunctionTok{weighted.mean}\NormalTok{(Y[Z}\SpecialCharTok{==}\DecValTok{0}\NormalTok{],  ip[Z}\SpecialCharTok{==}\DecValTok{0}\NormalTok{]), }\CommentTok{\# note !}
            \AttributeTok{diff =}\NormalTok{ Y1 }\SpecialCharTok{{-}}\NormalTok{ Y0)}\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r}
\hline
Y1 & Y0 & diff\\
\hline
0.59 & -0.15 & 0.74\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# with estimatr}
\NormalTok{estimatr}\SpecialCharTok{::}\FunctionTok{difference\_in\_means}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{weights =}\NormalTok{ ip, }\AttributeTok{data =}\NormalTok{ df) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
Z & 0.74 & 0.11 & 6.65 & 0 & 0.52 & 0.96 & 498 & Y\\
\hline
\end{tabular}
\end{frame}

\begin{frame}{ATE with IPW}
\protect\hypertarget{ate-with-ipw-1}{}
\begin{itemize}
\item
  But \textbf{inverse propensity weighting} is a more general principle,
  which can be used even if you do not have blocks.
\item
  The intuition for it comes straight from \textbf{sampling weights} ---
  you weight up in order to recover an unbiased estiamte of the
  potential outcomes for all units, whether or not they are assigned to
  treatment.
\item
  With sampling weights however you can include units even if their
  weight was 1. \emph{Why can you not include these units when doing
  inverse propensity weighting?}
\end{itemize}
\end{frame}

\begin{frame}{Illustration: Estimating treatment effects with terrible
treatment assignments: Fixer\label{Fixer}}
\protect\hypertarget{illustration-estimating-treatment-effects-with-terrible-treatment-assignments-fixer}{}
Say you made a mess and used a randomization that was correlated with
some variable, \(X\). For example:

\begin{itemize}
\tightlist
\item
  The randomization is done in a way that introduces a correlation
  between Treatment Assignment and Potential Outcomes
\item
  Then possibly, even though there is no true causal effect, we naively
  estimate a large one --- enormous bias
\item
  However since we know the assignment procedure we can \textbf{fully}
  correct for the bias
\item
  In the next example, we do this using ``\textbf{inverse propensity
  score weighting}.'' This is exactly analogous to standard survey
  weighting --- since we selected different units for treatment with
  different probabilities, we weight them differently to recover the
  average outcome among treated units (same for control).
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Basic randomization: Fixer}
\protect\hypertarget{basic-randomization-fixer}{}
Code to generate bad assignment but proper propensity weights:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# design \textless{}{-} }
\CommentTok{\#   declare\_model(N = 200,}
\CommentTok{\#                 X = runif(N),}
\CommentTok{\#                 Y0 = X,}
\CommentTok{\#                 Y1 = X,}
\CommentTok{\#                 Y = X)}

\NormalTok{n  }\OtherTok{\textless{}{-}} \DecValTok{200}\NormalTok{; reps }\OtherTok{\textless{}{-}} \DecValTok{500}\NormalTok{; X  }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(n)     }\CommentTok{\# Create a covariate (length n)}
\NormalTok{Y  }\OtherTok{\textless{}{-}}\NormalTok{ Y1 }\OtherTok{\textless{}{-}}\NormalTok{ Y0 }\OtherTok{\textless{}{-}}\NormalTok{ X                        }\CommentTok{\# Say X completely determines Y!}
\NormalTok{Z  }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(i) }\FunctionTok{rank}\NormalTok{(X}\SpecialCharTok{+}\DecValTok{2}\SpecialCharTok{*}\FunctionTok{runif}\NormalTok{(n))}\SpecialCharTok{\textgreater{}}\NormalTok{(n}\SpecialCharTok{/}\DecValTok{2}\NormalTok{) }\CommentTok{\# Bad randomization! }
\NormalTok{P  }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{reps, Z)                    }\CommentTok{\# Lots of possible draws}
\NormalTok{p  }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(P, }\DecValTok{1}\NormalTok{, mean)                    }\CommentTok{\# Recreate propensities!}
\NormalTok{pw }\OtherTok{\textless{}{-}}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{P)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)); pw[P]}\OtherTok{=}\NormalTok{(P}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{p))[P]   }\CommentTok{\# Create inv prop weights}

\NormalTok{naive   }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(P),}\ControlFlowTok{function}\NormalTok{(i) \{}
              \FunctionTok{mean}\NormalTok{(Y[P[,i]])}\SpecialCharTok{{-}}\FunctionTok{mean}\NormalTok{(Y[}\SpecialCharTok{!}\NormalTok{P[,i]])\}) }
\NormalTok{weightd }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(P),}\ControlFlowTok{function}\NormalTok{(i) \{  }\CommentTok{\# IPW estimates}
              \FunctionTok{weighted.mean}\NormalTok{(Y[P[,i]],  pw[,i][P[,i]])}\SpecialCharTok{{-}}
              \FunctionTok{weighted.mean}\NormalTok{(Y[}\SpecialCharTok{!}\NormalTok{P[,i]], pw[,i][}\SpecialCharTok{!}\NormalTok{P[,i]])\}) }
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Basic randomization: Fixer}
\protect\hypertarget{basic-randomization-fixer-1}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-281-1.pdf}
\end{frame}

\begin{frame}{IPW with one unit!}
\protect\hypertarget{ipw-with-one-unit}{}
This example is surprising but it helps you see the logic of why inverse
weighting gets unbiased estimates (and why that might not guarantee a
reasonable answer)

Imagine there is one unit with potential outcomes
\(Y(1) = 2, Y(0) = 1\). So the unit level treatment effect is 1.

You toss a coin.

\begin{itemize}
\tightlist
\item
  If you assign to treatment you estimate:
  \(\hat\tau = \frac{2}{0.5} = 4\)
\item
  If you assign to control you estimate:
  \(\hat\tau = -\frac{1}{0.5} = -2\)
\end{itemize}

SO your expected estimate is: \[0.5 \times 4 - 0.5 \times (-2) = 1\]

Great on average but always lousy
\end{frame}

\hypertarget{example}{%
\subsection{Example}\label{example}}

\begin{frame}{Covariate Adjustment\label{CA}}
\protect\hypertarget{covariate-adjustment}{}
Consider for example this data. \bigskip

\begin{itemize}
\tightlist
\item
  You randomly pair offerers and receivers in a dictator game (in which
  offerers decide how much of \$1 to give to receivers).
\item
  Your population comes from two groups (80\% Baganda and 20\%
  Banyankole) \emph{so in randomly assigning partners you are randomly
  determining whether a partner is a coethnic or not}.
\item
  \textbf{You find that in non-coethnic pairings 35\% is offered, in
  coethnic pairings 48\% is offered.}
\end{itemize}

Should you believe it?
\end{frame}

\begin{frame}{Covariate Adjustment}
\protect\hypertarget{covariate-adjustment-1}{}
\begin{itemize}
\tightlist
\item
  Population: randomly matched Baganda (80\% of pop) and Banyankole
  (20\% of pop)
\item
  You find: in non-coethnic pairings 35\% is offered, in coethnic
  pairings 48\% is offered.
\item
  But a closer look at the data reveals \dots
\end{itemize}

\begin{table}[h!]    \footnotesize
    \begin{tabular}{cc|cc}  \footnotesize
&   &       To: Baganda &To: Banyankole \\ \hline
Offers by   &Baganda    &64\%   & 16\% \\
    &Banyankole &16\%   &4\% \\
    \end{tabular}
    \caption{\small Number of Games}
\end{table}

\begin{table}[h!]    \footnotesize
    \begin{tabular}{cc|cc} \footnotesize
&   &       To: Baganda &To: Banyankole \\ \hline
Offers by   &Baganda    &50 & 50 \\
    &Banyankole &20 &20 \\
    \end{tabular}
    \caption{\small  Average Offers}
\end{table}

\footnotesize So that's a problem
\end{frame}

\begin{frame}{Covariate Adjustment}
\protect\hypertarget{covariate-adjustment-2}{}
Control?

\begin{itemize}
\tightlist
\item
  With such data you might be tempted to `control' for the covariate
  (here: ethnic group), using regression.
\item
  But, perhaps surprisingly, it turns out that regression with
  covariates does not estimate average treatment effects.
\item
  It does estimate an average of treatment effects, but specifically a
  minimum variance estimator, not necessarily an estimator of your
  estimand.
\end{itemize}
\end{frame}

\begin{frame}{Covariate Adjustment}
\protect\hypertarget{covariate-adjustment-3}{}
Compare:

\begin{itemize}
\tightlist
\item
  \(\hat{\tau}_{ATE} =\sum_{x} \frac{w_x}{\sum_{j}w_{j}}\hat{\tau}_x\)
\item
  \(\hat{\tau}_{OLS} =\sum_{x} \frac{w_xp_x(1-p_x)}{\sum_{j}w_j{p_j(1-p_j)}}\hat{\tau}_x\)
\end{itemize}

Instead you can use formula above for \(\hat{\tau}_{ATE}\) to estimate
ATE

alternatively\ldots{}
\end{frame}

\begin{frame}{Covariate adjustment via saturated regression}
\protect\hypertarget{covariate-adjustment-via-saturated-regression}{}
Alternatively you can use a regression that includes both the treatment
and the treatment \emph{interacted} with the covariates.

In practice this is best done by \emph{demeaning} the covariates; doing
this lets you read off the average effect from the main term. Key
resource: @lin2012agnostic
\end{frame}

\begin{frame}[fragile]{Covariate adjustment via saturated regression}
\protect\hypertarget{covariate-adjustment-via-saturated-regression-1}{}
Returning to prior example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ fabricatr}\SpecialCharTok{::}\FunctionTok{fabricate}\NormalTok{(}
  \AttributeTok{N =} \DecValTok{500}\NormalTok{, }
  \AttributeTok{X =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, N}\SpecialCharTok{/}\DecValTok{2}\NormalTok{), }
  \AttributeTok{Z =} \FunctionTok{rbinom}\NormalTok{(N, }\DecValTok{1}\NormalTok{, .}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ .}\DecValTok{3}\SpecialCharTok{*}\NormalTok{X),}
  \AttributeTok{Y =} \FunctionTok{rnorm}\NormalTok{(N) }\SpecialCharTok{+}\NormalTok{ Z}\SpecialCharTok{*}\NormalTok{X)}

\FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z}\SpecialCharTok{*}\NormalTok{X\_c, }\AttributeTok{data =}\NormalTok{ df }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{X\_c =}\NormalTok{ X }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(X))) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
(Intercept) & -0.10 & 0.06 & -1.70 & 0.09 & -0.22 & 0.02 & 496 & Y\\
\hline
Z & 0.59 & 0.10 & 5.83 & 0.00 & 0.39 & 0.78 & 496 & Y\\
\hline
X\_c & -0.18 & 0.12 & -1.48 & 0.14 & -0.41 & 0.06 & 496 & Y\\
\hline
Z:X\_c & 0.86 & 0.20 & 4.27 & 0.00 & 0.46 & 1.26 & 496 & Y\\
\hline
\end{tabular}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm\_lin}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X, }\AttributeTok{data =}\NormalTok{ df) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r|r|r|r|r|l}
\hline
term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
(Intercept) & -0.10 & 0.06 & -1.70 & 0.09 & -0.22 & 0.02 & 496 & Y\\
\hline
Z & 0.59 & 0.10 & 5.83 & 0.00 & 0.39 & 0.78 & 496 & Y\\
\hline
X\_c & -0.18 & 0.12 & -1.48 & 0.14 & -0.41 & 0.06 & 496 & Y\\
\hline
Z:X\_c & 0.86 & 0.20 & 4.27 & 0.00 & 0.46 & 1.26 & 496 & Y\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Demeaning and saturating}
\protect\hypertarget{demeaning-and-saturating}{}
Demeaning interactions

\begin{itemize}
\tightlist
\item
  Say you have a factorial design with treatments X1 and X2 (or
  obervational data with two covariates)
\item
  You analyse with a model that has main terms and interaction terms
\item
  Interpreting coefficients can be confusing, but sometimes demeaning
  can help. What does demeaning do?
\end{itemize}

Let's:

\begin{itemize}
\tightlist
\item
  Declare a factorial design in which Y is generated according to
\end{itemize}

\texttt{f\_Y\ \textless{}-\ function(X1,\ X2,\ u)\ .1\ +\ .2*X1\ +\ .3*X2\ +\ u*X1*X2}

where u is distributed \(U[0,1]\).

\begin{itemize}
\tightlist
\item
  Specify estimands carefully
\item
  Run analyses in which we do and do not demean the treatments; compare
  and explain results
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Demeaning interactions}
\protect\hypertarget{demeaning-interactions}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_Y }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X1, X2, u) .}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ .}\DecValTok{2}\SpecialCharTok{*}\NormalTok{X1 }\SpecialCharTok{+}\NormalTok{ .}\DecValTok{3}\SpecialCharTok{*}\NormalTok{X2 }\SpecialCharTok{+}\NormalTok{ u}\SpecialCharTok{*}\NormalTok{X1}\SpecialCharTok{*}\NormalTok{X2}

\NormalTok{design }\OtherTok{\textless{}{-}}
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{1000}\NormalTok{,}
                \AttributeTok{u =} \FunctionTok{runif}\NormalTok{(N),}
                \AttributeTok{X1 =} \FunctionTok{complete\_ra}\NormalTok{(N),}
                \AttributeTok{X2 =} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ X1),}
                \AttributeTok{X1\_demeaned =}\NormalTok{ X1 }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(X1),}
                \AttributeTok{X2\_demeaned =}\NormalTok{ X2 }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(X2),}
                \AttributeTok{Y =} \FunctionTok{f\_Y}\NormalTok{(X1, X2, u)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}
    \AttributeTok{base =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, u)),}
    \AttributeTok{average =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, u) }\SpecialCharTok{+} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, u)  }\SpecialCharTok{+} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, u)  }\SpecialCharTok{+} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, u))}\SpecialCharTok{/}\DecValTok{4}\NormalTok{,}
    \AttributeTok{CATE\_X1\_given\_0 =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{f\_Y}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, u) }\SpecialCharTok{{-}} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, u)),}
    \AttributeTok{CATE\_X2\_given\_0 =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, u) }\SpecialCharTok{{-}} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, u)),}
    \AttributeTok{ATE\_X1 =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{f\_Y}\NormalTok{(}\DecValTok{1}\NormalTok{, X2, u) }\SpecialCharTok{{-}} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, X2, u)),}
    \AttributeTok{ATE\_X2 =} \FunctionTok{mean}\NormalTok{(}\FunctionTok{f\_Y}\NormalTok{(X1, }\DecValTok{1}\NormalTok{, u) }\SpecialCharTok{{-}} \FunctionTok{f\_Y}\NormalTok{(X1, }\DecValTok{0}\NormalTok{, u)),}
    \AttributeTok{I\_X1\_X2 =} \FunctionTok{mean}\NormalTok{((}\FunctionTok{f\_Y}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, u) }\SpecialCharTok{{-}} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, u)) }\SpecialCharTok{{-}}\NormalTok{ (}\FunctionTok{f\_Y}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, u) }\SpecialCharTok{{-}} \FunctionTok{f\_Y}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, u)))}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X1}\SpecialCharTok{*}\NormalTok{X2, }
                    \AttributeTok{inquiry =} \FunctionTok{c}\NormalTok{(}\StringTok{"base"}\NormalTok{, }\StringTok{"CATE\_X1\_given\_0"}\NormalTok{, }\StringTok{"CATE\_X2\_given\_0"}\NormalTok{, }\StringTok{"I\_X1\_X2"}\NormalTok{), }
                    \AttributeTok{term =} \FunctionTok{c}\NormalTok{(}\StringTok{"(Intercept)"}\NormalTok{, }\StringTok{"X1"}\NormalTok{, }\StringTok{"X2"}\NormalTok{, }\StringTok{"X1:X2"}\NormalTok{),}
                    \AttributeTok{label =} \StringTok{"natural"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X1\_demeaned}\SpecialCharTok{*}\NormalTok{X2\_demeaned, }
                    \AttributeTok{inquiry =} \FunctionTok{c}\NormalTok{(}\StringTok{"average"}\NormalTok{, }\StringTok{"ATE\_X1"}\NormalTok{, }\StringTok{"ATE\_X2"}\NormalTok{, }\StringTok{"I\_X1\_X2"}\NormalTok{), }
                    \AttributeTok{term =} \FunctionTok{c}\NormalTok{(}\StringTok{"(Intercept)"}\NormalTok{, }\StringTok{"X1\_demeaned"}\NormalTok{, }\StringTok{"X2\_demeaned"}\NormalTok{, }\StringTok{"X1\_demeaned:X2\_demeaned"}\NormalTok{),}
                    \AttributeTok{label =} \StringTok{"demeaned"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Demeaning interactions: Solution}
\protect\hypertarget{demeaning-interactions-solution}{}
\texttt{f\_Y\ \textless{}-\ function(X1,\ X2,\ u)\ .1\ +\ .2*X1\ +\ .3*X2\ +\ u*X1*X2}

\begin{tabular}{l|l|l|l|l}
\hline
Inquiry & Estimator & Term & Mean Estimand & Mean Estimate\\
\hline
ATE\_X1 & demeaned & X1\_demeaned & 0.45 & 0.45\\
\hline
 &  &  & (0.00) & (0.00)\\
\hline
ATE\_X2 & demeaned & X2\_demeaned & 0.55 & 0.55\\
\hline
 &  &  & (0.00) & (0.00)\\
\hline
average & demeaned & (Intercept) & 0.48 & 0.47\\
\hline
 &  &  & (0.00) & (0.00)\\
\hline
base & natural & (Intercept) & 0.10 & 0.10\\
\hline
 &  &  & (0.00) & (0.00)\\
\hline
CATE\_X1\_given\_0 & natural & X1 & 0.20 & 0.20\\
\hline
 &  &  & (0.00) & (0.00)\\
\hline
CATE\_X2\_given\_0 & natural & X2 & 0.30 & 0.30\\
\hline
 &  &  & (0.00) & (0.00)\\
\hline
I\_X1\_X2 & demeaned & X1\_demeaned:X2\_demeaned & 0.50 & 0.50\\
\hline
 &  &  & (0.00) & (0.00)\\
\hline
I\_X1\_X2 & natural & X1:X2 & 0.50 & 0.50\\
\hline
 &  &  & (0.00) & (0.00)\\
\hline
\end{tabular}

It's all good. But you need to match the estimator to the inquiry:
demean for average marginal effects; do not demean for conditional
marginal effects.
\end{frame}

\begin{frame}{Summary}
\protect\hypertarget{summary}{}
If you have different groups with different assignment propensities you
can do any or all of these:

\begin{enumerate}
\tightlist
\item
  Blocked differences in means
\item
  Inverse propensity weighting
\item
  Saturated regression (Lin)
\end{enumerate}

We will compare the performances of these different approaches later.

You cannot (reliably):

\begin{enumerate}
\tightlist
\item
  Ignore the groups
\item
  Include them in a regression (without interactions)
\end{enumerate}
\end{frame}

\begin{frame}{Covariate Adjustment\label{CA}}
\protect\hypertarget{covariate-adjustment-4}{}
\begin{itemize}
\tightlist
\item
  Even though randomization ensures no bias, you may sometimes
  \textbf{want} to ``\textbf{control}'' for covariates in order to
  improve efficiency (see the discussion of blocking above).
\item
  Or you may \textbf{have} to take account of the fact that the
  assignment to treatment is correlated with a covariate.
\end{itemize}
\end{frame}

\begin{frame}{Conditional Bias and Precision Gains from Controls}
\protect\hypertarget{conditional-bias-and-precision-gains-from-controls}{}
Controls can do reduce noise and improve precision. This is an argument
for using variables that are correlated with the output (not with the
treatment).

\includegraphics[width=2in,height=\textheight]{figs/n.png}
\end{frame}

\begin{frame}{Conditional Bias and Precision Gains from Controls}
\protect\hypertarget{conditional-bias-and-precision-gains-from-controls-1}{}
Introducing controls can create complications

As argued by Freedman (summary from @lin2012agnostic), we can get:
``worsened asymptotic precision, invalid measures of precision, and
small-sample bias''\footnote<.->{though note that the precision concern
  does not hold when treatment and control groups are equally sized}

These adverse effects are essentially removed with an interacted model

See discussions in @imbens2015causal (7.6, 7.7) and especialy Theorem
7.2 for the aymptotic variance of the estimator
\end{frame}

\begin{frame}{Conditional Bias and Precision Gains from Controls}
\protect\hypertarget{conditional-bias-and-precision-gains-from-controls-2}{}
Note also including controls when treatment is correlated with
covariates can induce ``conditional bias.'' Doing this will change your
estimates so be sure not to fish!

\begin{figure}

{\centering \includegraphics[width=2.33in,height=\textheight]{figs/cb.jpg}

}

\caption{Advantages of controlling for vars that are correlated with
outcomes}

\end{figure}

There are more or less sophisticated ways of doing this\ldots.
\end{frame}

\hypertarget{doubly-robust-estimation}{%
\subsection{Doubly robust estimation}\label{doubly-robust-estimation}}

\begin{frame}{Doubly robust estimation}
\protect\hypertarget{doubly-robust-estimation-1}{}
Doubly robust estimation combines:

\begin{enumerate}
\tightlist
\item
  A model for how the covariates predict the potential outcomes
\item
  A model for how the covariates predict assignment propensities
\end{enumerate}

Using both together to estimate potential outcomes using propensity
weighting lets you do well even if either model is wrong.

Each part can be done using nonparameteric methods resulting in an
overall semi-parametric procedure.

\begin{itemize}
\tightlist
\item
  \(\pi(Z) = \Pr(Z=1|X)\): Estimate \(\hat\pi\)
\item
  \(Y_z = \mathbb{E}[Y|Z=z, X]\): Estimate \(\hat{Y}_z\)
\item
  Estimate of causal effect:
  \(\frac{1}{n}\sum_{i=1}^n\left(\left(\frac{Z_i}{\hat{\pi}_i}(Y_i - \hat{Y}_{i1}\right) - \left(\frac{1-Z_i}{1-\hat{\pi}_i}(Y_i - \hat{Y}_{i0}\right) + \left(\hat{Y}_{i1} - \hat{Y}_{i0}\right) \right)\)
\end{itemize}
\end{frame}

\begin{frame}{Doubly robust estimation}
\protect\hypertarget{doubly-robust-estimation-2}{}
\begin{itemize}
\item
  Estimate of causal effect:
  \(\frac{1}{n}\sum_{i=1}^n\left(\left(\frac{Z_i}{\hat{\pi}_i}(Y_i - \hat{Y}_{i1}\right) - \left(\frac{1-Z_i}{1-\hat{\pi}_i}(Y_i - \hat{Y}_{i0}\right) + \left(\hat{Y}_{i1} - \hat{Y}_{i0}\right) \right)\)
\item
  Note that if \(\hat{Y}_{iz}\) are correct then the first parts drop
  out and we we get the right answer.
\item
  So if you can impute the potential outcomes, you are good (though
  hardly surprising)
\end{itemize}
\end{frame}

\begin{frame}{Doubly robust estimation}
\protect\hypertarget{doubly-robust-estimation-3}{}
\begin{itemize}
\tightlist
\item
  More subtly say the \(\hat{pi}\)s are correct, but your imputations
  are wrong; then we again have an unbiased estimator.
\end{itemize}

To see this imagine with probability \(\pi\) we assign unit 1 to
treatment and 2 to control (otherwise 1 to control and 2 to treatment).

Then our \emph{expected} estimate is:

\(\frac12\pi\left(\left(\frac{1}{\pi}(Y_{11} - \hat{Y}_{11}\right) - \left(\frac{1}{\pi}(Y_{20} - \hat{Y}_{20}\right) \right) + (1-\pi)\left(\left(\frac{1}{1-\pi}(Y_{21} - \hat{Y}_{21}\right) - \left(\frac{1}{1-\pi}(Y_{10} - \hat{Y}_{10}\right) \right) + \left(\hat{Y}_{11} - \hat{Y}_{20}\right) + \left(\hat{Y}_{21} - \hat{Y}_{10}\right)\)

\(\frac12\left(Y_{11} - Y_{10} + Y_{21}- Y_{20} +\pi\left(\left(\frac{1}{\pi}( - \hat{Y}_{11}\right) - \left(\frac{1}{\pi}( - \hat{Y}_{20}\right) \right) + (1-\pi)\left(\left(\frac{1}{1-\pi}( - \hat{Y}_{21}\right) - \left(\frac{1}{1-\pi}(- \hat{Y}_{10}\right) \right)\right) + \left(\hat{Y}_{11} - \hat{Y}_{20}\right) + \left(\hat{Y}_{21} - \hat{Y}_{10}\right)\)

\(\frac12\left(Y_{11} - Y_{10} + Y_{21}- Y_{20}\right)\)

@robins1994estimation
\end{frame}

\hypertarget{doubly-robust-estimation-illustration}{%
\subsection{Doubly robust estimation
illustration}\label{doubly-robust-estimation-illustration}}

\begin{frame}[fragile]{Data with confounding}
\protect\hypertarget{data-with-confounding}{}
Consider this data:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# df with rue treatment effect of 1 }
\CommentTok{\# (0.5 if race = 0; 1.5 if race = 1)}

\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ fabricatr}\SpecialCharTok{::}\FunctionTok{fabricate}\NormalTok{(}
  \AttributeTok{N =} \DecValTok{5000}\NormalTok{,}
  \AttributeTok{class =} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{, N, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{),}
  \AttributeTok{race =} \FunctionTok{rbinom}\NormalTok{(N, }\DecValTok{1}\NormalTok{, .}\DecValTok{5}\NormalTok{),}
  \AttributeTok{Z =} \FunctionTok{rbinom}\NormalTok{(N, }\DecValTok{1}\NormalTok{, .}\DecValTok{2} \SpecialCharTok{+}\NormalTok{ .}\DecValTok{3}\SpecialCharTok{*}\NormalTok{race),}
  \AttributeTok{Y =}\NormalTok{ .}\DecValTok{5}\SpecialCharTok{*}\NormalTok{Z }\SpecialCharTok{+}\NormalTok{ race}\SpecialCharTok{*}\NormalTok{Z }\SpecialCharTok{+}\NormalTok{ class }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(N),}
  \AttributeTok{qsmk =} \FunctionTok{factor}\NormalTok{(Z),}
  \AttributeTok{class =} \FunctionTok{factor}\NormalTok{(class),}
  \AttributeTok{race =} \FunctionTok{factor}\NormalTok{(race)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Simple approaches}
\protect\hypertarget{simple-approaches}{}
Naive regression produces biased estimates, even with controls. Lin
regression gets the right result however.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Naive}
\FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{data =}\NormalTok{ df)}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.257443
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# OLS with controls}
\FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ class }\SpecialCharTok{+}\NormalTok{ race, }\AttributeTok{data =}\NormalTok{ df)}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.121328
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Lin}
\FunctionTok{lm\_lin}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z,  }\SpecialCharTok{\textasciitilde{}}\NormalTok{ class }\SpecialCharTok{+}\NormalTok{ race, }\AttributeTok{data =}\NormalTok{ df)}\SpecialCharTok{$}\NormalTok{coefficients[[}\StringTok{"Z"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.002136
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Doubly robust estimation}
\protect\hypertarget{doubly-robust-estimation-4}{}
\texttt{drtmle} is an R package that uses doubly robust estimation to
compute ``marginal means of an outcome under fixed levels of a
treatment.''

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(SuperLearner)}
\FunctionTok{library}\NormalTok{(drtmle)}
\NormalTok{drtmle\_fit }\OtherTok{\textless{}{-}} \FunctionTok{drtmle}\NormalTok{(}
  \AttributeTok{W =}\NormalTok{ df }\SpecialCharTok{|\textgreater{}} \FunctionTok{select}\NormalTok{(race, class), }
  \AttributeTok{A =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Z, }
  \AttributeTok{Y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{Y, }
  \AttributeTok{SL\_Q =} \FunctionTok{c}\NormalTok{(}\StringTok{"SL.glm"}\NormalTok{, }\StringTok{"SL.mean"}\NormalTok{, }\StringTok{"SL.glm.interaction"}\NormalTok{),}
  \AttributeTok{SL\_g =} \FunctionTok{c}\NormalTok{(}\StringTok{"SL.glm"}\NormalTok{, }\StringTok{"SL.mean"}\NormalTok{, }\StringTok{"SL.glm.interaction"}\NormalTok{),}
  \AttributeTok{SL\_Qr =} \StringTok{"SL.glm"}\NormalTok{,}
  \AttributeTok{SL\_gr =} \StringTok{"SL.glm"}\NormalTok{, }
  \AttributeTok{maxIter =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Doubly robust estimation}
\protect\hypertarget{doubly-robust-estimation-5}{}
\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# "Marginal means"}
\NormalTok{drtmle\_fit}\SpecialCharTok{$}\NormalTok{drtmle}\SpecialCharTok{$}\NormalTok{est}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.983348 2.985222
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Effects}
\FunctionTok{ci}\NormalTok{(drtmle\_fit, }\AttributeTok{contrast =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$drtmle
                  est   cil   ciu
E[Y(1)]-E[Y(0)] 1.002 0.937 1.067
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wald\_test}\NormalTok{(drtmle\_fit, }\AttributeTok{contrast =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
$drtmle
                      zstat pval
H0:E[Y(1)]-E[Y(0)]=0 30.301    0
\end{verbatim}

Resource: https://muse.jhu.edu/article/883477
\end{frame}

\hypertarget{assessing-performance}{%
\subsection{Assessing performance}\label{assessing-performance}}

\begin{frame}[fragile]{Assessing performance}
\textbf{Challenge}: Use \texttt{DeclareDesign} to compare performance of
\texttt{drtmle} and \texttt{lm\_lin}
\end{frame}

\hypertarget{randomization-inference}{%
\subsection{\texorpdfstring{Randomization Inference
\label{ri}}{Randomization Inference }}\label{randomization-inference}}

\begin{frame}{Calculate a \(p\) value in your head}
\protect\hypertarget{calculate-a-p-value-in-your-head}{}
\begin{itemize}
\item
  Illustrating \(p\) values via ``randomization inference''
\item
  Say you randomized assignment to treatment and your data looked like
  this.
\end{itemize}

\begin{longtable}[]{@{}lllllllllll@{}}
\toprule\noalign{}
Unit & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\midrule\noalign{}
\endhead
Treatment & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
Health score & 4 & 2 & 3 & 1 & 2 & 3 & 4 & 8 & 7 & 6 \\
\bottomrule\noalign{}
\end{longtable}

Then:

\begin{itemize}
\tightlist
\item
  Does the treatment improve your health?
\item
  What's the \(p\) value for the null that treatment had no effect on
  anybody?
\end{itemize}
\end{frame}

\begin{frame}{Calculate a \(p\) value in your head}
\protect\hypertarget{calculate-a-p-value-in-your-head-1}{}
\begin{itemize}
\tightlist
\item
  Illustrating \(p\) values via ``randomization inference''
\item
  Say you randomized assignment to treatment and your data looked like
  this.
\end{itemize}

\begin{longtable}[]{@{}lllllllllll@{}}
\toprule\noalign{}
Unit & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\midrule\noalign{}
\endhead
Treatment & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
Health score & 4 & 2 & 3 & 1 & 2 & 3 & 4 & 8 & 7 & 6 \\
\bottomrule\noalign{}
\end{longtable}

Then:

\begin{itemize}
\tightlist
\item
  Does the treatment improve your health?
\item
  What's the \(p\) value for the null that treatment had no effect on
  anybody?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Randomization Inference: Some code}
\protect\hypertarget{randomization-inference-some-code}{}
\begin{itemize}
\tightlist
\item
  In principle it is very easy.
\item
  These few lines generate data, produce the regression estimate and
  then an RI estimate of \(p\):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# data}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{fabricate}\NormalTok{(}\AttributeTok{N =} \DecValTok{200}\NormalTok{, }\AttributeTok{X =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{,}\ConstantTok{TRUE}\NormalTok{), N}\SpecialCharTok{/}\DecValTok{2}\NormalTok{), }\AttributeTok{Y=}\NormalTok{  .}\DecValTok{1}\SpecialCharTok{*}\NormalTok{X }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(N))}

\CommentTok{\# test stat}
\NormalTok{t }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df) }\FunctionTok{with}\NormalTok{(df, }\FunctionTok{mean}\NormalTok{(Y[X])}\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Y[}\SpecialCharTok{!}\NormalTok{X]))}

\CommentTok{\# test stat distribution}
\NormalTok{ts }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}\DecValTok{1000}\NormalTok{, df }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{X =} \FunctionTok{sample}\NormalTok{(X)) }\SpecialCharTok{|\textgreater{}} \FunctionTok{t}\NormalTok{())}

\CommentTok{\# test}
\FunctionTok{mean}\NormalTok{(ts }\SpecialCharTok{\textgreater{}=} \FunctionTok{t}\NormalTok{(df))   }\CommentTok{\# One sided p value}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.349
\end{verbatim}
\end{frame}

\begin{frame}{Randomization Inference}
\protect\hypertarget{randomization-inference-1}{}
In practice it is a good idea to create a \(P\) matrix when you do your
randomization (although note: if the null is about one treatment, then
you are interested only in the randomization of that treatment, not the
joint randomization of all)
\end{frame}

\begin{frame}{Randomization Inference}
\protect\hypertarget{randomization-inference-2}{}
\begin{itemize}
\tightlist
\item
  Say you had a silly randomization procedure and forgot to take account
  of it in your estimates.

  \begin{figure}[htbp]
            \centering
                \includegraphics[width=.9\textwidth]{figs/pw2.png}
            \label{fig:pweight}
        \end{figure}
\item
  You estimate .15. \textsl{Does the treatment improve your health?}
\item
  \(p=\)?
\end{itemize}
\end{frame}

\begin{frame}{Randomization Inference}
\protect\hypertarget{randomization-inference-3}{}
\begin{itemize}
\tightlist
\item
  Randomization procedures are sometimes funky in lab experiments
\item
  Using randomization inference would force a focus on the true
  assignment of individuals to treatments
\item
  Fake (but believable) example follows
\end{itemize}
\end{frame}

\begin{frame}{Randomization Inference}
\protect\hypertarget{randomization-inference-4}{}
\begin{table}
  \centering
  \caption{Optimal assignment to treatment given constraints due to facilities}
    \begin{tabular}{rrcccc}
          &       & Capacity & T1    & T2    & T3 \\ \hline
    Session & Thursday & 40    & 10    & 30    & 0 \\
          & Friday & 40    & 10    & 0     & 30 \\
          & Saturday & 10    & 10    & 0     & 0 \\ \hline
          &       & 90    & 30    & 30    & 30 \\ \hline
    \end{tabular}
\end{table}

\begin{table}[htbp] \small
  \centering
  \caption{Constraints due to subjects}
    \begin{tabular}{ccc}
    Subject Type & N     & Available \\ \hline
    A     & 30    & Thurs, Fri \\
    B     & 30    & Thurs, Sat \\
    C     & 30    & Fri, Sat \\ \hline
    \end{tabular}
\end{table}
\end{frame}

\begin{frame}{Randomization Inference}
\protect\hypertarget{randomization-inference-5}{}
\small If you think hard about assignment you might come up with an
allocation like this.

\begin{table}
  \centering
  \caption{Assignment of people to days}
    \begin{tabular}{ccc|ccc}
          &       &       &       & Allocation &  \\
    Subject Type & N     & Available & Thurs & Fri   & Sat \\ \hline
    A     & 30    & Thurs, Fri & 15    & 15    &  \\
    B     & 30    & Thurs, Sat & 25    &       & 5 \\
    C     & 30    & Fri, Sat &       & 25    & 5 \\
    \end{tabular}
\end{table}

\footnotesize  That allocation balances as much as possible. Given the
allocation you might randomly assign individuals to different days as
well as randomly assigning them to treatments within days. If you then
figure out assignment propensities, this is what you would get:

\begin{table}
  \centering
    \begin{tabular}{cccccc}
          &       &       & \multicolumn{3}{c}{Assignment Probabilities}  \\ \hline
    Subject Type & N     & Available & T1    & T2    & T3 \\ \hline
    A     & 30    & Thurs, Fri & 0.25  & 0.375 & 0.375 \\
    B     & 30    & Thurs, Sat & 0.375 & 0.625 & 0 \\
    C     & 30    & Fri, Sat & 0.375 &       & 0.625 \\ \hline
    \end{tabular}
  
\end{table}
\end{frame}

\begin{frame}{Randomization Inference}
\protect\hypertarget{randomization-inference-6}{}
\footnotesize Even under the assumption that the day of measurement does
not matter, these assignment probabilities have big implications for
analysis.

\begin{table}\footnotesize
    \begin{tabular}{ccc|ccc}
          &       &       & \multicolumn{3}{|c}{Assignment Probabilities} \\
    Subject Type & N     & Available & T1    & T2    & T3 \\ \hline
    A     & 30    & Thurs, Fri & 0.25  & 0.375 & 0.375 \\
    B     & 30    & Thurs, Sat & 0.375 & 0.625 & 0 \\
    C     & 30    & Fri, Sat & 0.375 &       & 0.625 \\
    \end{tabular}
  %
\end{table}

\begin{itemize}
\item
  Only the type \(A\) subjects could have received any of the three
  treatments.
\item
  There are no two treatments for which it is possible to compare
  outcomes for subpopulations \(B\) and \(C\)
\item
  A comparison of \(T1\) versus \(T2\) can only be made for population
  \(A \cup B\)
\item
  However subpopulation \(A\) is assigned to \(A\) (versus \(B\)) with
  probability 4/5; while population \(B\) is assigned with probability
  3/8
\item
  \textbf{Implications for design}: need to uncluster treatment delivery
\item
  \textbf{Implications for analysis}: need to take account of
  propensities
\end{itemize}

\textbf{Idea}: Wacky assignments happen but if you know the propensities
you can do the analysis.
\end{frame}

\begin{frame}{Randomization Inference}
\protect\hypertarget{randomization-inference-7}{}
\begin{itemize}
\tightlist
\item
  Randomization inference can get quite a bit more complicated when you
  want to test a null other than the sharp null of no effect.
\item
  Say you wanted to test the null that the effect is 2 for all units.
  How do you do it?
\item
  Say you wanted to test the null that an \emph{interaction effect} is
  zero. How do you do it?
\item
  In both cases by filling in a potential outcomes schedule given the
  hypothesis in question and then generating a test statistic
\end{itemize}

\begin{table}
\centering
\begin{tabular}{cccccccc}

\multicolumn{ 2}{c}{Observed} &            & \multicolumn{ 2}{c}{Under null that } &            & \multicolumn{ 2}{c}{Under null that } \\

           &            &            & \multicolumn{ 2}{c}{effect is 0} &            & \multicolumn{ 2}{c}{effect is 2} \\  \hline

      Y(0) &       Y(1) &            &       Y(0) &       Y(1) &            &       Y(0) &       Y(1) \\

         1 &          ? &            &          1 &          1 &            &          1 &          3 \\

         2 &          ? &            &          2 &          2 &            &          2 &          4 \\

         ? &          4 &            &          4 &          4 &            &          2 &          4 \\

         ? &          3 &            &          3 &          3 &            &          1 &          3 \\

\end{tabular}  
\end{table}
\end{frame}

\hypertarget{design-based-estimation-of-variance}{%
\subsection{Design Based Estimation of
Variance}\label{design-based-estimation-of-variance}}

\begin{frame}{Var(ATE)}
\protect\hypertarget{varate}{}
\begin{itemize}
\tightlist
\item
  Recall that the treatment effect is gotten by taking a sample of
  outcomes under treatment and comparing them to a sample of outcomes
  under control
\item
  Say that there is no ``error''
\item
  Why would this procedure produce uncertainty?
\end{itemize}
\end{frame}

\begin{frame}{Var(ATE)}
\protect\hypertarget{varate-1}{}
\begin{itemize}
\tightlist
\item
  Why would this procedure produce uncertainty?
\item
  The uncertainty comes from being uncertain about the average outcome
  under control from observations of the control units, and from being
  uncertain about the average outcome under treatment from obervation of
  the treated units
\item
  In other words, it comes from the variance in the treatment outcomes
  and variance in the control outcomes (and not, for example, from
  variance in the treatment effect)
\end{itemize}
\end{frame}

\begin{frame}{Var(ATE)}
\protect\hypertarget{varate-2}{}
\scriptsize You can also estimate variance straight from the data. From
\href{http://www.stat.berkeley.edu/~census/neyregcm.pdf}{Freedman Prop 1}
(using combinatorics!) we have:

\begin{eqnarray*} 
V(\widehat{ATE})  &=  &\frac{1}{n-1}\left[\frac{n_C}{n_T}V(Y(1)) +  \frac{n_T}{n_C}V(Y(0))\right] + 2C\left(Y(1),Y(0)\right)  \nonumber \\
\end{eqnarray*} Usefully rewritten as: \begin{eqnarray*} 
V(\widehat{ATE})  &=  &\frac{n}{n-1}\left[\frac{V(Y(1))}{n_T} +  \frac{V(Y(0))}{n_C}\right] - \frac{1}{n-1}\left[V(Y(1)) + V(Y(0)) - 2C\left(Y(1),Y(0)\right)\right]  \nonumber 
\end{eqnarray*}

\dots where \(V\) denotes variance and \(C\) covariance
\end{frame}

\begin{frame}[fragile]{Var(ATE)}
\protect\hypertarget{varate-3}{}
Note:

\begin{itemize}
\tightlist
\item
  We can use the sample estimates \(s^2(\{Y_i\}_{i \in C})\) and
  \(s^2(\{Y_i\}_{i \in T})\) for the first part.
\item
  But \(C(Y(1),Y(0))\) cannot be estimated from data.
\item
  The \textbf{Neyman estimator} ignores the second part (and so is
  conservative).
\item
  Tip: for STATA users, use \texttt{,\ robust} (see
  @samii2012equivalencies)
\end{itemize}
\end{frame}

\begin{frame}{ATE and Var(ATE)\}}
\protect\hypertarget{ate-and-varate}{}
For the case with blocking, the conservative estimator is:

\begin{equation*} V(\widehat{ATE})   = {\sum_{S\in \mathcal{S}}{\left(\frac{n_{S}}{n}\right)^2} \left({\frac{s^2_{S1}}{n_{S1}}} + {\frac{s^2_{S0}}{n_{S0}}} \right)}  \end{equation*}
\end{frame}

\begin{frame}{Illustration of Neyman Conservative Estimator}
\protect\hypertarget{illustration-of-neyman-conservative-estimator}{}
An illustration of \textit{how} conservative the conservative estimator
of variance really is (numbers in plot are correlations between \(Y(1)\)
and \(Y(0)\).

We confirm that:

\begin{enumerate}
\tightlist
\item
  the estimator is conservative
\item
  the estimator is more conservative for negative correlations between
  \(Y(0)\) and \(Y(1)\) --- eg if those cases that do particularly badly
  in control are the ones that do particularly well in treatment \%, and
\item
  with \(\tau\) and \(V(Y(0))\) fixed. high positive correlations are
  associated with highest variance.
\end{enumerate}
\end{frame}

\begin{frame}{Illustration of Neyman Conservative Estimator}
\protect\hypertarget{illustration-of-neyman-conservative-estimator-1}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-293-1.pdf}
\end{frame}

\begin{frame}{Illustration of Neyman Conservative Estimator}
\protect\hypertarget{illustration-of-neyman-conservative-estimator-2}{}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.0567}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.0567}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1489}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.0709}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1348}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.2057}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.3262}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\(\tau\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\rho\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\sigma^2_{Y(1)}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\Delta\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\sigma^2_{\tau}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\widehat{\sigma}^2_{\tau}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\widehat{\sigma}^2_{\tau(\text{Neyman})}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
1.00 & -1.00 & 1.00 & -0.04 & 0.00 & -0.00 & 0.04 \\
1.00 & -0.67 & 1.00 & -0.03 & 0.01 & 0.01 & 0.04 \\
1.00 & -0.33 & 1.00 & -0.03 & 0.01 & 0.01 & 0.04 \\
1.00 & 0.00 & 1.00 & -0.02 & 0.02 & 0.02 & 0.04 \\
1.00 & 0.33 & 1.00 & -0.01 & 0.03 & 0.03 & 0.04 \\
1.00 & 0.67 & 1.00 & -0.01 & 0.03 & 0.03 & 0.04 \\
1.00 & 1.00 & 1.00 & 0.00 & 0.04 & 0.04 & 0.04 \\
\bottomrule\noalign{}
\end{longtable}

Here \(\rho\) is the unobserved correlation between \(Y(1)\) and
\(Y(0)\); and \(\Delta\) is the final term in the sample variance
equation that we cannot estimate.
\end{frame}

\begin{frame}{Tighter Bounds On Variance Estimate}
\protect\hypertarget{tighter-bounds-on-variance-estimate}{}
The conservative variance comes from the fact that you do not know the
covariance between \(Y(1)\) and \(Y(0)\).

\begin{itemize}
\tightlist
\item
  But as
  \href{http://arxiv.org/pdf/1405.6555.pdf}{Aronow, Green, and Lee (2014)}
  point out, you \textit{do} know something.
\item
  Intuitively, if you know that the variance of \(Y(1)\) is 0, then the
  covariance also has to be zero.
\item
  This basic insight opens a way of calculating bounds on the variance
  of the sample average treatment effect.
\end{itemize}
\end{frame}

\begin{frame}{Tighter Bounds On Variance Estimate}
\protect\hypertarget{tighter-bounds-on-variance-estimate-1}{}
Example:

\begin{itemize}
\tightlist
\item
  Take a million-observation dataset, with treatment randomly assigned
\item
  Assume \(Y(0)=0\) for everyone and \(Y(1)\) distributed normally with
  mean 0 and standard deviation of 1000.
\item
  Note here the covariance of \(Y(1)\) and \(Y(0)\) is 0.
\item
  Note the true variance of the estimated sample average treatment
  effect should be (approx)
  \(\frac{Var(Y(1))}{\sqrt{1000000}} + \frac{Var(Y(0))}{\sqrt{1000000}} = 1\).
\item
  But using the Neyman estimator (or OLS!) we estimate (approx)
  \(\frac{Var(Y(1))}{\sqrt{1000000/2}} + \frac{Var(Y(0))}{\sqrt{1000000/2}} = \sqrt{2}\).
\item
  But we can recover the truth knowing the covariance between \(Y(1)\)
  and \(Y(0)\) is 0.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Tighter Bounds On Variance Estimate: Code}
\protect\hypertarget{tighter-bounds-on-variance-estimate-code}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sharp\_var }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(yt,yc,}\AttributeTok{N=}\FunctionTok{length}\NormalTok{(}\FunctionTok{c}\NormalTok{(yt,yc)),}\AttributeTok{upper=}\ConstantTok{TRUE}\NormalTok{)\{}
\NormalTok{ m }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(yt);  n }\OtherTok{\textless{}{-}}\NormalTok{ m }\SpecialCharTok{+} \FunctionTok{length}\NormalTok{(yc)}
\NormalTok{ V }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x,N) \{}
\NormalTok{       (N}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(N}\SpecialCharTok{*}\NormalTok{(}\FunctionTok{length}\NormalTok{(x)}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)) }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)\}}
\NormalTok{ yt }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(yt)}
 \ControlFlowTok{if}\NormalTok{(upper) \{yc }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(yc)}
\NormalTok{       \} }\ControlFlowTok{else}\NormalTok{ \{yc }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(yc,}\AttributeTok{decreasing=}\ConstantTok{TRUE}\NormalTok{)\}}
\NormalTok{ p\_i }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(}\FunctionTok{sort}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,n}\SpecialCharTok{{-}}\NormalTok{m,}\DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(n}\SpecialCharTok{{-}}\NormalTok{m),}\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,m,}\DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{m)))}\SpecialCharTok{{-}} 
\NormalTok{        .Machine}\SpecialCharTok{$}\NormalTok{double.eps}\SpecialCharTok{\^{}}\NormalTok{.}\DecValTok{5}
\NormalTok{ p\_i[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ .Machine}\SpecialCharTok{$}\NormalTok{double.eps}\SpecialCharTok{\^{}}\NormalTok{.}\DecValTok{5}
\NormalTok{ yti }\OtherTok{\textless{}{-}}\NormalTok{ yt[}\FunctionTok{ceiling}\NormalTok{(p\_i}\SpecialCharTok{*}\NormalTok{m)]; yci }\OtherTok{\textless{}{-}}\NormalTok{ yc[}\FunctionTok{ceiling}\NormalTok{(p\_i}\SpecialCharTok{*}\NormalTok{(n}\SpecialCharTok{{-}}\NormalTok{m))]}
\NormalTok{ p\_i\_minus }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\ConstantTok{NA}\NormalTok{,p\_i[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{ (}\FunctionTok{length}\NormalTok{(p\_i)}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)])}
 \FunctionTok{return}\NormalTok{(((N}\SpecialCharTok{{-}}\NormalTok{m)}\SpecialCharTok{/}\NormalTok{m }\SpecialCharTok{*} \FunctionTok{V}\NormalTok{(yt,N) }\SpecialCharTok{+}\NormalTok{ (N}\SpecialCharTok{{-}}\NormalTok{(n}\SpecialCharTok{{-}}\NormalTok{m))}\SpecialCharTok{/}\NormalTok{(n}\SpecialCharTok{{-}}\NormalTok{m)}\SpecialCharTok{*}\FunctionTok{V}\NormalTok{(yc,N) }\SpecialCharTok{+}
       \DecValTok{2}\SpecialCharTok{*}\FunctionTok{sum}\NormalTok{(((p\_i}\SpecialCharTok{{-}}\NormalTok{p\_i\_minus)}\SpecialCharTok{*}\NormalTok{yti}\SpecialCharTok{*}\NormalTok{yci)[}\DecValTok{2}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(p\_i)]) }\SpecialCharTok{{-}}
       \DecValTok{2}\SpecialCharTok{*}\FunctionTok{mean}\NormalTok{(yt)}\SpecialCharTok{*}\FunctionTok{mean}\NormalTok{(yc))}\SpecialCharTok{/}\NormalTok{(N}\DecValTok{{-}1}\NormalTok{))\}}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Illustration}
\protect\hypertarget{illustration-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n   }\OtherTok{\textless{}{-}} \DecValTok{1000000}
\NormalTok{Y   }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,n}\SpecialCharTok{/}\DecValTok{2}\NormalTok{), }\DecValTok{1000}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{(n}\SpecialCharTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{X   }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,n}\SpecialCharTok{/}\DecValTok{2}\NormalTok{), }\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, n}\SpecialCharTok{/}\DecValTok{2}\NormalTok{))}
\NormalTok{ols }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{coef}\NormalTok{(}\FunctionTok{summary}\NormalTok{(}\FunctionTok{lm}\NormalTok{(Y}\SpecialCharTok{\textasciitilde{}}\NormalTok{X)))[}\DecValTok{2}\NormalTok{,],}\DecValTok{3}\NormalTok{)}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(ols)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in eval(substitute(expr), data, enclos = parent.frame()): numeric 'envir' arg not of length one
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sharp }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FunctionTok{sharp\_var}\NormalTok{(Y[X}\SpecialCharTok{==}\DecValTok{1}\NormalTok{], Y[X}\SpecialCharTok{==}\DecValTok{0}\NormalTok{], }\AttributeTok{upper =} \ConstantTok{FALSE}\NormalTok{), }
                 \FunctionTok{sharp\_var}\NormalTok{(Y[X}\SpecialCharTok{==}\DecValTok{1}\NormalTok{], Y[X}\SpecialCharTok{==}\DecValTok{0}\NormalTok{], }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{)),}\DecValTok{3}\NormalTok{)}
\NormalTok{sharp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1 1
\end{verbatim}
\end{frame}

\hypertarget{principle-keep-the-reporting-close-to-the-design}{%
\subsection{Principle: Keep the reporting close to the
design}\label{principle-keep-the-reporting-close-to-the-design}}

\begin{frame}{Design based analysis}
\protect\hypertarget{design-based-analysis}{}
\begin{itemize}
\tightlist
\item
  Report the analysis that is implied by the design.
\end{itemize}

\begin{table}
\small \centering
\begin{tabular}{cc|ccc|c}\small

           &            &         T2 &            &            &            \\

           &            &          N &          Y &        All &       Diff \\ \hline

        T1 &          N &      $\overline{y}_{00}$ &      $\overline{y}_{01}$ &     $\overline{y}_{0x}$ &    $d_2|T1=0$ \\

           &            &       (sd) &       (sd) &       (sd) &       (sd) \\

           &          Y &      $\overline{y}_{10}$ &      $\overline{y}_{10}$ &         $\overline{y}_{1x}$ &    $d_2|T1=1$ \\

           &            &       (sd) &       (sd) &       (sd) &       (sd) \\

           &        All &     $\overline{y}_{x0}$ &     $\overline{y}_{x1}$ &          $y$ &    $d_2$ \\

           &            &       (sd) &       (sd) &       (sd) &       (sd) \\ \hline

           &       Diff &    $d_1|T2=0$ &    $d_1|T2=1$ &    $d_1$ &    \color{green} $d_1d_2$ \\

           &            &       (sd) &       (sd) &       (sd) &       (sd) \\

\end{tabular}  
\end{table}

This is instantly recognizable from the design and returns all the
benefits of the factorial design including all main effects, conditional
causal effects, interactions and summary outcomes. It is much clearer
and more informative than a regression table.
\end{frame}

\hypertarget{bayesian-approaches}{%
\section{Bayesian approaches}\label{bayesian-approaches}}

\hypertarget{bayes-basics}{%
\subsection{Bayes Basics}\label{bayes-basics}}

\begin{frame}{Bayes Rule}
\protect\hypertarget{bayes-rule}{}
\begin{itemize}
\item
  Bayesian methods are just sets of procedures to figure out how to
  update beliefs in light of new information.
\item
  We begin with a prior belief about the probability that a hypothesis
  is true.
\item
  New data then allow us to form a posterior belief about the
  probability of the hypothesis.
\end{itemize}

Bayesian inference takes into account:

\begin{itemize}
\tightlist
\item
  the consistency of the evidence with a hypothesis
\item
  the uniqueness of the evidence to that hypothesis
\item
  background knowledge about the problem.
\end{itemize}
\end{frame}

\begin{frame}{Illustration 1}
\protect\hypertarget{illustration-1-1}{}
I draw a card from a deck and ask \emph{What are the chances it is a
Jack of Spades?}

\begin{itemize}
\tightlist
\item
  Just 1 in 52.
\end{itemize}

Now I tell you that the card is indeed a spade. What would you guess?

\begin{itemize}
\tightlist
\item
  1 in 13
\end{itemize}

What if told you it was a heart?

\begin{itemize}
\tightlist
\item
  No chance it is the Jack of Spades
\end{itemize}

What if I said it was a face card and a spade.

\begin{itemize}
\tightlist
\item
  1 in 3.
\end{itemize}
\end{frame}

\begin{frame}{Illustration 1}
\protect\hypertarget{illustration-1-2}{}
These answers are applications of Bayes' rule.

In each case the answer is derived by assessing what is possible, given
the new information, and then assessing how likely the outcome of
interest among the states that are possible. In all the cases you
calculate:

\[\text{Prob Jack of Spades | Info} = \frac{\text{Is Jack of Spades Consistent w/ Info?}}{\text{How many cards are consistent w/ Info?}} \]
\end{frame}

\begin{frame}{Illustration 2 \textbf{Interpreting Your Test Results}}
\protect\hypertarget{illustration-2-interpreting-your-test-results}{}
You take a test to see whether you suffer from a disease that affects 1
in 100 people. The test is good in the following sense:

\begin{itemize}
\tightlist
\item
  if you have the disease, then with a 99\% probability it will say you
  have the disease
\item
  if you do not have it, then with a 99\% probability, it will say that
  you do not have it
\end{itemize}

The test result says that you have the disease. What are the chances you
have it?
\end{frame}

\begin{frame}{Illustration 2 \textbf{Interpreting Your Test Results}}
\protect\hypertarget{illustration-2-interpreting-your-test-results-1}{}
\begin{itemize}
\item
  It is \emph{not} 99\%. 99\% is the probability of the result given the
  disease, but we want the probability of the disease given the result.
\item
  The right answer is 50\%, which you can think of as the share of
  people that have the disease among all those that test positive. For
  example
\item
  e.g.~if there were 10,000 people, then 100 would have the disease and
  99 of these would test positive. But 9,900 would not have the disease
  and 99 of these would test positive. So the people with the disease
  that test positive are half of the total number testing positive.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Illustration 2. An illustration}
\protect\hypertarget{illustration-2.-an-illustration}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  p}\OtherTok{=}\NormalTok{.}\DecValTok{9}\NormalTok{; }\DocumentationTok{\#\# power of test and prior prob healthy}
\NormalTok{  s}\OtherTok{=}\DecValTok{2000}  \DocumentationTok{\#\# population size}
\NormalTok{  col5 }\OtherTok{=} \StringTok{"red"}
\NormalTok{  col0 }\OtherTok{=} \StringTok{"black"}

  \FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
    \FunctionTok{plot}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{axes=}\NormalTok{F, }\AttributeTok{type=}\StringTok{"n"}\NormalTok{, }\AttributeTok{ann=}\NormalTok{F)}
    \FunctionTok{title}\NormalTok{(}\AttributeTok{main =}\StringTok{"Healthy Circles"}\NormalTok{)}
    \FunctionTok{points}\NormalTok{(.}\DecValTok{175}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{p}\SpecialCharTok{*}\NormalTok{s)}\SpecialCharTok{+}\NormalTok{.}\DecValTok{5}\NormalTok{, .}\DecValTok{175}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{p}\SpecialCharTok{*}\NormalTok{s) }\SpecialCharTok{+}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{col =}\NormalTok{ col5, }\AttributeTok{pch=}\DecValTok{21}\NormalTok{, }\AttributeTok{bg =}\NormalTok{ col5) }\DocumentationTok{\#\#Test negative}
    \FunctionTok{points}\NormalTok{(.}\DecValTok{1}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{((}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{p}\SpecialCharTok{*}\NormalTok{s)}\SpecialCharTok{+}\NormalTok{.}\DecValTok{5}\NormalTok{, .}\DecValTok{1}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{((}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{p}\SpecialCharTok{*}\NormalTok{s) }\SpecialCharTok{+}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{col =}\NormalTok{ col0, }\AttributeTok{pch=}\DecValTok{21}\NormalTok{, }\AttributeTok{bg =}\NormalTok{ col0, }\AttributeTok{cex=}\FloatTok{1.1}\NormalTok{) }\DocumentationTok{\#\# Test positive}
    \FunctionTok{box}\NormalTok{()}
  
    \FunctionTok{plot}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{axes=}\NormalTok{F, }\AttributeTok{type=}\StringTok{"n"}\NormalTok{, }\AttributeTok{ann=}\NormalTok{F)}
    \FunctionTok{title}\NormalTok{(}\AttributeTok{main =}\StringTok{"Sick squares"}\NormalTok{)}
    \FunctionTok{points}\NormalTok{(.}\DecValTok{1}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{s)}\SpecialCharTok{+}\NormalTok{ .}\DecValTok{5}\NormalTok{, .}\DecValTok{1}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{(p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{s) }\SpecialCharTok{+}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{col =}\NormalTok{ col0, }\AttributeTok{pch=}\DecValTok{22}\NormalTok{, }\AttributeTok{bg =}\NormalTok{ col0)}
    \FunctionTok{points}\NormalTok{(.}\DecValTok{175}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{((}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{s)}\SpecialCharTok{+}\NormalTok{.}\DecValTok{5}\NormalTok{, .}\DecValTok{175}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{((}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p)}\SpecialCharTok{*}\NormalTok{s) }\SpecialCharTok{+}\NormalTok{ .}\DecValTok{5}\NormalTok{, }\AttributeTok{col =}\NormalTok{ col5, }\AttributeTok{pch=}\DecValTok{22}\NormalTok{, }\AttributeTok{bg =}\NormalTok{ col5) }
    \FunctionTok{box}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\textwidth,height=\textheight]{0_lectures_files/figure-beamer/unnamed-chunk-322-1.pdf}

}

\end{figure}

What's the probability of being a circle given you are black?
\end{frame}

\begin{frame}{Illustration 2. More formally.}
\protect\hypertarget{illustration-2.-more-formally.}{}
As an equation this might be written:

\[\text{Prob You have the Disease | Pos} = \frac{\text{How many have the disease and test pos?}}{\text{How many people test pos?}}\]
\end{frame}

\begin{frame}{Two Child Problem}
\protect\hypertarget{two-child-problem}{}
Consider last an old puzzle found described @gardner1961second.

\begin{itemize}
\tightlist
\item
  Mr Smith has two children, \(A\) and \(B\).
\item
  At least one of them is a boy.
\item
  What are the chances they are both boys?
\end{itemize}

To be explicit about the puzzle, we will assume that the information
that one child is a boy is given as a truthful answer to the question
``\emph{is at least one of the children a boy?}''

Assuming also that there is a 50\% probability that a given child is a
boy.
\end{frame}

\begin{frame}{Two Child Problem}
\protect\hypertarget{two-child-problem-1}{}
As an equation:

\[\text{Prob both boys | Not both girls} = \frac{\text{Prob both boys}}{\text{Prob not both girls}} = \frac{\text{1 in 4}}{\text{3 in 4}}\]
\end{frame}

\begin{frame}{Bayes Rule}
\protect\hypertarget{bayes-rule-1}{}
Formally, all of these equations are applications of Bayes' rule which
is a simple and powerful formula for deriving updated beliefs from new
data.

The formula is given as: \begin{eqnarray}
\Pr(H|\mathcal{D})&=&\frac{\Pr(\mathcal{D}|H)\Pr(H)}{\Pr(\mathcal{D})}\\
                  &=&\frac{\Pr(\mathcal{D}|H)\Pr(H)}{\sum_{H'}\Pr(\mathcal{D}|H')\Pr(H'))}
\end{eqnarray}
\end{frame}

\begin{frame}{Bayes Rule}
\protect\hypertarget{bayes-rule-2}{}
Formally, all of these equations are applications of Bayes' rule which
is a simple and powerful formula for deriving updated beliefs from new
data.

For continuous distributions and parameter vector \(\theta\):

\[p(\theta|\mathcal{D})=\frac{p(\mathcal{D}|\theta)p(\theta)}{\int_{\theta'}p(\mathcal{D|\theta'})p(\theta')d\theta}\]
\end{frame}

\begin{frame}{Useful Distributions: Beta and Dirichlet Distributions}
\protect\hypertarget{useful-distributions-beta-and-dirichlet-distributions}{}
\begin{itemize}
\tightlist
\item
  Bayes rule requires the ability to express a prior distribution but it
  does not require that the prior have any particular properties other
  than being probability distributions.
\item
  Sometimes however it can be useful to make use of ``off the shelf''
  distributions.
\end{itemize}

Consider \textbf{the share of people in a population that voted}. This
is a quantity between 0 and 1.

\begin{itemize}
\tightlist
\item
  Two people might may both believe that the turnout was around 50\% but
  differ in how certain they are about this claim.
\item
  One might claim to have no information and to believe any turnout rate
  between 0 and 100\% is equally likely; another might be completely
  confident that the number if 50\%.
\end{itemize}

Here the parameter of interest is a \emph{share}. The \textbf{Beta} and
\textbf{Dirichlet} distributions are particularly useful for
representing beliefs on shares.
\end{frame}

\begin{frame}{Beta}
\protect\hypertarget{beta}{}
\begin{itemize}
\tightlist
\item
  The Beta distribution is a distribution over the \([0,1]\) that is
  governed by two parameters, \(\alpha\) and \(\beta\).
\item
  In the case in which both \(\alpha\) and \(\beta\) are 1, the
  distribution is uniform -- all values are seen as equally likely.
\item
  As \(\alpha\) rises large outcomes are seen as more likely
\item
  As \(\beta\) rises, lower outcomes are seen as more likely.
\item
  If both rise proportionately the expected outcome does not change but
  the distribution becomes tighter.
\end{itemize}

An attractive feature is that if one has a prior Beta(\(\alpha\),
\(\beta\)) over the probability of some event, and then one observes a
positive case, the Bayesian posterior distribution is also a Beta with
with parameters \(\alpha+1, \beta\). Thus if people start with uniform
priors and build up knowledge on seeing outcomes, their posterior
beliefs should be Beta.
\end{frame}

\begin{frame}{Beta}
\protect\hypertarget{beta-1}{}
Here is a set of such distributions.

\begin{figure}

{\centering \includegraphics{0_lectures_files/figure-beamer/Betas-1.pdf}

}

\caption{\label{betas} Beta distributions}

\end{figure}
\end{frame}

\begin{frame}{Dirichlet distributions.}
\protect\hypertarget{dirichlet-distributions.}{}
The Dirichlet distributions are generalizations of the Beta to the
situation in which there are beliefs not just over a proportion, or a
probability, but over collections of probabilities.

\begin{itemize}
\item
  If four outcomes are possible and each is likely to occur with
  probability \(p_k\), \(k=1,2,3,4\) then beliefs are distributions over
  a three dimensional unit simplex.
\item
  The distribution has as many parameters as there are outcomes and
  these are traditionally recorded in a vector, \(\alpha\).
\item
  As with the Beta distribution, an uninformative prior (Jeffrey's
  prior) has \(\alpha\) parameters of \((.5,.5,.5, \dots)\) and a
  uniform (``flat'') distribution has \(\alpha = (1,1,1,,\dots)\).
\item
  The Dirichlet updates in a simple way. If you have a Dirichlet prior
  with parameter \(\alpha = (\alpha_1, \alpha_2, \dots)\) and you
  observe outcome \(1\), for example, then then posterior distribution
  is also Dirichlet with parameter vector
  \(\alpha' = (\alpha_1+1, \alpha_2,\dots)\).
\end{itemize}
\end{frame}

\hypertarget{stan}{%
\subsection{Stan}\label{stan}}

\begin{frame}{Plan}
\protect\hypertarget{plan-1}{}
In this short lecture we:

\begin{itemize}
\tightlist
\item
  fire up stan
\item
  implement a simple linear model and talk through the main model blocks
\item
  implement a simple hierarchical model
\item
  describe a behavioral game and set up a model to recover some
  parameters of interest, given the game
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Getting set up}
\protect\hypertarget{getting-set-up}{}
The good news: There is lots of help online. Start with:
https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started

We will jump straight into things and work through a session.

\begin{enumerate}
\tightlist
\item
  Install the stan package and fire up. Useful to set options so that
  multiple cores are being used:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rstan)}
\FunctionTok{rstan\_options}\NormalTok{(}\AttributeTok{auto\_write =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{options}\NormalTok{(}\AttributeTok{mc.cores =}\NormalTok{ parallel}\SpecialCharTok{::}\FunctionTok{detectCores}\NormalTok{())}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{One variable model: Simple example}
\protect\hypertarget{one-variable-model-simple-example}{}
\begin{enumerate}
\setcounter{enumi}{1}
\tightlist
\item
  Now lets consider the simplest one var linear model.

  \begin{itemize}
  \tightlist
  \item
    We will need model code
  \item
    And data
  \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}{A simple model: Code}
\protect\hypertarget{a-simple-model-code}{}
To implement a stan model you should write the code in a text editor and
save it as a text file. You can also write it directly in your script.
You can then bring the file into R or call the file directly.

\begin{itemize}
\tightlist
\item
  There are many examples of stan models here:

  \begin{itemize}
  \tightlist
  \item
    https://github.com/stan-dev/example-models/tree/master/ARM/Ch.4
  \item
    https://github.com/stan-dev/example-models/wiki
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{A simple model: Code}
\protect\hypertarget{a-simple-model-code-1}{}
I saved a simple model called \texttt{one\_var.stan} locally. Here it
is:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{readLines}\NormalTok{(}\StringTok{"assets/one\_var.stan"}\NormalTok{, }\AttributeTok{warn =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{cat}\NormalTok{(}\AttributeTok{sep =} \StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
data {
  int<lower=0> N;
  vector[N] Y;
  vector[N] X;
}
parameters {
  real a;
  real b;
  real<lower=0> sigma;
}
model {
  Y ~ normal(a + b * X, sigma);
}
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{A simple model: Code}
\protect\hypertarget{a-simple-model-code-2}{}
The key features here are (read from bottom up!):

\begin{itemize}
\tightlist
\item
  \(Y\) is assumed to be normally distributed with mean
  \texttt{a\ +\ bX} and standard deviation \texttt{sigma}.
\item
  There are then three parameters: \texttt{a}, \texttt{b},
  \texttt{sigma}.
\item
  There are no priors placed on these but sigma is constrained to be
  positive. Without priors improper flat priors are assumed.
\item
  Stan expects a data set that contains three things: a scalar,
  \texttt{N} and \texttt{X1,}Y` data
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Simple model: Data}
\protect\hypertarget{simple-model-data}{}
We feed data to the model in the form of a list. The idea of a list is
that the data can include all sorts of objects, not just a single
dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{=} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{20}\NormalTok{)}

\NormalTok{some\_data }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
 \AttributeTok{N =} \DecValTok{20}\NormalTok{,}
 \AttributeTok{X =}\NormalTok{ X,}
 \AttributeTok{Y =}\NormalTok{ X }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{20}\NormalTok{)}
\NormalTok{ )}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Simple model: Now let's Run It}
\protect\hypertarget{simple-model-now-lets-run-it}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file =} \StringTok{"assets/one\_var.stan"}\NormalTok{, }
          \AttributeTok{data =}\NormalTok{ some\_data)}
\end{Highlighting}
\end{Shaded}

When you run the model you get a lot of useful output on the estimation
and the posterior distribution. Here though are the key results: :::
\{.cell\} ::: \{.cell-output-display\}

\begin{tabular}{l|r|r|r}
\hline
  & mean & sd & Rhat\\
\hline
a & -0.179 & 0.214 & 1\\
\hline
b & 0.738 & 0.183 & 1\\
\hline
sigma & 0.950 & 0.175 & 1\\
\hline
\end{tabular}

::: :::

These look good.

The Rhat at the end tells you about convergence. You want this very
close to 1.
\end{frame}

\begin{frame}[fragile]{A simple model: Now lets use it}
\protect\hypertarget{a-simple-model-now-lets-use-it}{}
The model output contains the full posterior distribution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_posterior }\OtherTok{\textless{}{-}}\NormalTok{ M }\SpecialCharTok{|\textgreater{}} \FunctionTok{extract}\NormalTok{() }\SpecialCharTok{|\textgreater{}} \FunctionTok{data.frame}\NormalTok{() }

\NormalTok{my\_posterior }\SpecialCharTok{|\textgreater{}} \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(a,b)) }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{0_lectures_files/figure-beamer/figposta-1.pdf}

}

\end{figure}
\end{frame}

\begin{frame}[fragile]{A simple model: Now lets use it}
\protect\hypertarget{a-simple-model-now-lets-use-it-1}{}
With the full posterior you can can look at marginal posterior
distributions over arbitrary transformations of parameters.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{((my\_posterior}\SpecialCharTok{$}\NormalTok{a }\SpecialCharTok{+}\NormalTok{ my\_posterior}\SpecialCharTok{$}\NormalTok{b)}\SpecialCharTok{/}\NormalTok{my\_posterior}\SpecialCharTok{$}\NormalTok{a) }\SpecialCharTok{|\textgreater{}} \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{kable}\NormalTok{(}\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in UseMethod("tidy"): no applicable method for 'tidy' applied to an object of class "c('summaryDefault', 'table')"
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Building up}
\protect\hypertarget{building-up}{}
Let's go back to the code.

There we had three key blocks: \texttt{data}, \texttt{parameters}, and
\texttt{model}

More generally the blocks you can specify are:

\begin{itemize}
\tightlist
\item
  \texttt{data} (define the vars that will be coming in from the data
  list)
\item
  \texttt{transformed\ data} (can be used for preprocessing)
\item
  \texttt{parameters} (required: defines the parameters to be estimated)
\item
  \texttt{transformed\ parameters} (transformations of parameters useful
  for computational reasons and sometimes for clarity)
\item
  \texttt{model} (give priors and likelihood)
\item
  \texttt{generated\ quantities} (can be used for post processing)
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Parameters block}
\protect\hypertarget{parameters-block}{}
The parameters block declared the set of parameters that we wanted to
estimate. In the simple model these were \texttt{a}, \texttt{b}, and
\texttt{sigma}. Note in the declaration we also:

\begin{itemize}
\tightlist
\item
  said what kind of parameters they (vectors, matrices, simplices etc)
\item
  gave possible constraints
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Parameters block}
\protect\hypertarget{parameters-block-1}{}
Instead of defining: ::: \{.cell\}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{real a;}
\NormalTok{real b;}
\end{Highlighting}
\end{Shaded}

:::

We could have defined ::: \{.cell\}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector[}\DecValTok{2}\NormalTok{] coefs;}
\end{Highlighting}
\end{Shaded}

:::

and then referenced \texttt{coef{[}1{]}} and \texttt{coef{[}2{]}} in the
model block.
\end{frame}

\begin{frame}[fragile]{Parameters block}
\protect\hypertarget{parameters-block-2}{}
Or we could also have imposed the constraint that the slope coefficient
is positive by defining: ::: \{.cell\}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{real a;}
\NormalTok{real}\SpecialCharTok{\textless{}}\NormalTok{lower }\OtherTok{=} \DecValTok{0}\SpecialCharTok{\textgreater{}}\NormalTok{ b;}
\end{Highlighting}
\end{Shaded}

:::
\end{frame}

\begin{frame}[fragile]{Model Block}
\protect\hypertarget{model-block}{}
In the model block we give the likelihood

But we can also give the priors (if we want to). If priors are not
provided, flat (possibly improper) priors are assumed

In our case for example we could have provided something like

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model \{}
\NormalTok{  b }\SpecialCharTok{\textasciitilde{}} \FunctionTok{normal}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{, }\DecValTok{1}\NormalTok{);}
\NormalTok{  Y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{normal}\NormalTok{(a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ X, sigma);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This suggests that we start off believing \texttt{b} is centered on -10.
That will surely matter for our conclusions. Lets try it:
\end{frame}

\begin{frame}[fragile]{Version 2}
\protect\hypertarget{version-2}{}
This time I will write the model right in the editor:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_model }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] Y;}
\StringTok{  vector[N] X;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real a;}
\StringTok{  real b;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  b \textasciitilde{} normal({-}10,1);}
\StringTok{  Y \textasciitilde{} normal(a + b * X, sigma);}
\StringTok{\}}
\StringTok{\textquotesingle{}}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Estimation 2}
\protect\hypertarget{estimation-2}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M2 }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{model\_code =}\NormalTok{ new\_model, }\AttributeTok{data =}\NormalTok{ some\_data)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r}
\hline
  & mean & sd & Rhat\\
\hline
a & -1.338 & 2.444 & 1.003\\
\hline
b & -7.875 & 1.172 & 1.003\\
\hline
sigma & 10.988 & 2.499 & 1.001\\
\hline
\end{tabular}

Note that we get a much lower estimate for \texttt{b} with the same
data.
\end{frame}

\begin{frame}{A multilevel model}
\protect\hypertarget{a-multilevel-model}{}
Now imagine a setting in which there are 10 villages, each with 10
respondents. Half in each village are assigned to treatment \(X=1\), and
half to control \(X=0\).

Say that there is possible a village specific average outcome:
\(Y_v = a_v + b_vX\) where \(a_v\) and \(b_v\) are each draw from some
distribution with a mean and variance of interest. The individual
outcomes are draws from a village level distribution centered on the
village specific average outcome.

This all implies a multilevel structure.
\end{frame}

\begin{frame}[fragile]{A ml model}
\protect\hypertarget{a-ml-model}{}
Here is a model for this

\tiny

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ml\_model }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}}
\StringTok{data \{}
\StringTok{  vector[100] Y;}
\StringTok{  int\textless{}lower=0,upper=1\textgreater{} X[100];}
\StringTok{  int village[100];}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  vector\textless{}lower=0\textgreater{}[3] sigma; }
\StringTok{  vector[10] a;}
\StringTok{  vector[10] b;}
\StringTok{  real mu\_a;}
\StringTok{  real mu\_b;}
\StringTok{\}}
\StringTok{transformed parameters \{}
\StringTok{  vector[100] Y\_vx;}
\StringTok{  for (i in 1:100) Y\_vx[i] = a[village[i]] + b[village[i]] * X[i];}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  a \textasciitilde{} normal(mu\_a, sigma[1]);}
\StringTok{  b \textasciitilde{} normal(mu\_b, sigma[2]);}
\StringTok{  Y \textasciitilde{} normal(Y\_vx, sigma[3]);}
\StringTok{\}}
\StringTok{\textquotesingle{}}
\end{Highlighting}
\end{Shaded}

Here is a slightly more general version:
https://github.com/stan-dev/example-models/blob/master/ARM/Ch.17/17.1\_radon\_vary\_inter\_slope.stan
\end{frame}

\begin{frame}[fragile]{Multilevel model: Data}
\protect\hypertarget{multilevel-model-data}{}
Lets create some multilevel data. Looking at this, can you tell what is
the typical village level effect? How much heterogeneity is there?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{village   }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\AttributeTok{each =} \DecValTok{10}\NormalTok{)}
\NormalTok{village\_b }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\NormalTok{X         }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, }\DecValTok{50}\NormalTok{)}
\NormalTok{Y         }\OtherTok{\textless{}{-}}\NormalTok{ village\_b[village]}\SpecialCharTok{*}\NormalTok{X }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{)}

\NormalTok{ml\_data }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{village =}\NormalTok{ village,}
  \AttributeTok{X =}\NormalTok{ X, }
  \AttributeTok{Y =}\NormalTok{ Y)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Multilevel Results}
\protect\hypertarget{multilevel-results}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M\_ml }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{model\_code =}\NormalTok{ ml\_model, }\AttributeTok{data =}\NormalTok{ ml\_data)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r}
\hline
  & mean & sd & Rhat\\
\hline
mu\_a & -0.29 & 0.25 & 1.00\\
\hline
mu\_b & 1.89 & 0.26 & 1.00\\
\hline
sigma[1] & 0.61 & 0.25 & 1.00\\
\hline
sigma[2] & 0.47 & 0.28 & 1.01\\
\hline
sigma[3] & 0.98 & 0.08 & 1.00\\
\hline
\end{tabular}
\end{frame}

\begin{frame}{A game and a structural model}
\protect\hypertarget{a-game-and-a-structural-model}{}
Say that a set of people in a population are playing sequential
prisoner's dilemmas.

In such games selfish behavior might suggest defections by everyone
everywhere. But of course people often cooperate. Why might this be?

\begin{itemize}
\tightlist
\item
  One possible reason is that some people are irrational, in the sense
  that they simply choose to cooperate, ignoring the payoffs.
\item
  Another possibility is that rational people think that others are
  irrational, in the sense that they think that others will reciprocate
  when they observe cooperative action
\end{itemize}
\end{frame}

\begin{frame}{Model}
\protect\hypertarget{model}{}
We will capture some of this intuition with a behavioral type model in
which

\begin{itemize}
\tightlist
\item
  each player has a ``rationality'' propensity of \(r_i\) -- this is the
  probability with which they choose to do the rational thing, rather
  than the generous thing
\item
  \(r_i \sim U[0, \theta]\) for \(\theta > .5\).
\item
  A player with rationality propensity of \(r_i\) believes
  \(r_j \sim [0, r_i]\). So everyone assumes that they are the most
  rational people in the room\ldots{}
\item
  The game is such that: * second mover: a second mover with rationality
  propensity \(r_i\) will cooperate with probability \(1-r_i\) if the
  first mover cooperated; otherwise they defect * first mover: a first
  mover with \(r_i\) will cooperate nonstrategically with probability
  \((1-r_i)\); however with probability \(r_i\) they will also cooperate
  \emph{strategically} if they think that the second mover has
  \(r_j<.25\).
\end{itemize}
\end{frame}

\begin{frame}{Expectations from model}
\protect\hypertarget{expectations-from-model}{}
In all, this means that a player with propensity \(r_i>.5\) will
cooperate with probability \(1-r_i\); a player with propensity
\(r_i<.5\) will cooperate with probability \(1\).

Interestingly the not-very-rational people sometimes cooperate
strategically but the really rational people never cooperate
strategically because they think it won't work.
\end{frame}

\begin{frame}{Event Probabilities}
\protect\hypertarget{event-probabilities}{}
What then are the probabilities of each of the possible outcomes?

\begin{itemize}
\tightlist
\item
  There will be cooperation by \emph{both} players with probability
  \((\int_0^{.5} p(r_i) dr_i + \int_{.5}^1 p(r_i)(1-r_i) dr_i)\int_0^1p(r_i)(1-r_i)dr_i\)
\item
  There will be cooperation by player 1 only with probability
  \((\int_0^{.5} p(r_i) dr_i + \int_{.5}^1 p(r_i)(1-r_i) dr_i)(\int_0^1p(r_i)(r_i)dr_i)\)
\item
  There will be cooperation by neither with probability:
  \(1-\int_0^{.5} p(r_i) dr_i - \int_{.5}^1 p(r_i)(1-r_i) dr_i\)
\end{itemize}

where \(p\) is the density function on \(r_i\) given \(\theta\)
\end{frame}

\begin{frame}{Event probabilities}
\protect\hypertarget{event-probabilities-1}{}
Given the assumption on \(p\)

\begin{itemize}
\tightlist
\item
  There will be cooperation by \emph{both} players with probability
  \((1+.25/\theta -.5\theta)(1-.5\theta)\)
\item
  There will be cooperation by player 1 only with probability
  \((1+.25/\theta -.5\theta)(.5\theta)\)
\item
  There will be cooperation by neither player with probability
  \((.5\theta-.25/\theta)\)
\end{itemize}
\end{frame}

\begin{frame}{Data}
\protect\hypertarget{data}{}
\begin{itemize}
\item
  We have data on the actions of the first movers and the second movers
  and are interested in the distribution of the \(p_i\)s.
\item
  Lets collapse that data into a simple list of the number of each type
  of game outcome:
\item
  And say we start off with a uniform prior of \(\theta\).
\item
  What should we conclude about \(\theta\)?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Model}
\protect\hypertarget{model-1}{}
Here's a model:

\tiny

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{game\_model }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} play[3];}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real\textless{}lower=.5, upper=1\textgreater{} theta;}
\StringTok{\}}
\StringTok{transformed parameters \{}
\StringTok{simplex[3] w;}
\StringTok{ w[1] = (1+.25*theta {-} .5*theta)*(1{-}.5*theta);}
\StringTok{ w[2] = (1+.25*theta {-} .5*theta)*(.5*theta);}
\StringTok{ w[3] = ({-}.25*theta  + .5*theta);}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  play \textasciitilde{} multinomial(w);}
\StringTok{\}}
\StringTok{\textquotesingle{}}
\end{Highlighting}
\end{Shaded}

Note we define event weights as transformed parameters on a simplex. We
also constrain \(\theta\) to be \(>.5\). Obviously we are relying
\emph{a lot} on our model.
\end{frame}

\begin{frame}[fragile]{Plot posterior on \(\theta\)}
\protect\hypertarget{plot-posterior-on-theta}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M3 }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{model\_code =}\NormalTok{ game\_model,  }
           \AttributeTok{data =} \FunctionTok{list}\NormalTok{(}\AttributeTok{play =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{0_lectures_files/figure-beamer/unnamed-chunk-347-1.pdf}

}

\end{figure}
\end{frame}

\begin{frame}[fragile]{Plot posterior on \(\theta\)}
\protect\hypertarget{plot-posterior-on-theta-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M4 }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{model\_code =}\NormalTok{ game\_model,  }
           \AttributeTok{data =} \FunctionTok{list}\NormalTok{(}\AttributeTok{play =} \FunctionTok{c}\NormalTok{(}\DecValTok{20}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{4}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{0_lectures_files/figure-beamer/unnamed-chunk-350-1.pdf}

}

\end{figure}
\end{frame}

\begin{frame}{Posterior on a quantity of interest}
\protect\hypertarget{posterior-on-a-quantity-of-interest}{}
What is the probability of observing \emph{strategic} first round
cooperation?

A player with rationality \(r_i\) will cooperate strategically with
probability \(r_i\) if \(r_i<.5\) and 0 otherwise. Thus we are
interested in \(\int_0^{.5}r_i/\theta dr_i = .125/\theta\)

\begin{figure}

{\centering \includegraphics[width=0.5\textwidth,height=\textheight]{0_lectures_files/figure-beamer/unnamed-chunk-351-1.pdf}

}

\end{figure}
\end{frame}

\hypertarget{design}{%
\section{Design}\label{design}}

\hypertarget{topics}{%
\subsection{Topics}\label{topics}}

\begin{frame}{Topics}
\begin{itemize}
\tightlist
\item
  Sampling schemes
\item
  Randomization schemes
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Experiments}
\protect\hypertarget{experiments}{}
\begin{itemize}
\item
  Experiments are investigations in which an intervention, in all its
  essential elements, is under the control of the investigator. (Cox \&
  Reid)
\item
  Two major types of control:

\begin{verbatim}
      1. control over assignment to treatment -- this is at the heart of many field experiments 
      2. control over the treatment itself -- this is at the heart of many lab experiments
\end{verbatim}
\item
  Main focus today is on 1 and on the question:
  \textit{how does control over assignment to treatment allow you to make reasonable statements about causal effects?}
\end{itemize}
\end{frame}

\begin{frame}{Experiments}
\protect\hypertarget{experiments-1}{}
\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{figs/labfield}
\end{figure}
\end{frame}

\begin{frame}[fragile]{Basic randomization \label{schemes}}
\protect\hypertarget{basic-randomization}{}
\hyperlink{ideas}{\beamergotobutton{Top}}

\begin{itemize}
\tightlist
\item
  Basic randomization is very simple. For example, say you want to
  assign 5 of 10 units to treatment. Here is simple code:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{:}\DecValTok{10} \SpecialCharTok{\%in\%} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{)    }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{\ldots should be replicable}
\protect\hypertarget{should-be-replicable}{}
In general you might want to set things up so that your randomization is
\textbf{replicable}. You can do this by setting a \textbf{seed}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{20111112}\NormalTok{)}
\DecValTok{1}\SpecialCharTok{:}\DecValTok{10} \SpecialCharTok{\%in\%} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{20111112}\NormalTok{)}
\DecValTok{1}\SpecialCharTok{:}\DecValTok{10} \SpecialCharTok{\%in\%} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Basic randomization}
\protect\hypertarget{basic-randomization-1}{}
Even better is to set it up so that it can reproduce
\textbf{lots of possible draws} so that you can check the propensities
for each unit.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{20111112}\NormalTok{)}
\NormalTok{P }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{1000}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(i) }\DecValTok{1}\SpecialCharTok{:}\DecValTok{10} \SpecialCharTok{\%in\%} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{)) }
\FunctionTok{apply}\NormalTok{(P, }\DecValTok{1}\NormalTok{, mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] 0.495 0.493 0.512 0.522 0.505 0.522 0.479 0.510 0.444 0.518
\end{verbatim}

Here the \(P\) matrix gives 1000 possible ways of allocating 5 of 10
units to treatment. We can then confirm that the average propensity is
0.5.

\begin{itemize}
\tightlist
\item
  A huge advantage of this approach is that if you make a mess of the
  random assignment;
  \textbf{you can still generate the P matrix and use that for all analyses}!
\end{itemize}
\end{frame}

\begin{frame}{Do it in advance}
\protect\hypertarget{do-it-in-advance}{}
\begin{itemize}
\tightlist
\item
  Unless you need them to keep subjects at ease, leave your spinners and
  your dice and your cards behind.
\item
  Especially when you have multiple or complex randomizations you are
  generally much better doing it with a computer in advance
\end{itemize}

\begin{figure}
\centering
\includegraphics[width=.8\linewidth]{figs/dictionary.png}
\caption{A survey dictionary with results from a complex randomization presented in a simple way for enumerators}
\label{fig:dictionary}
\end{figure}
\end{frame}

\begin{frame}{Did the randomization ``work'\,'?}
\protect\hypertarget{did-the-randomization-work}{}
\footnotesize * People often wonder: did randomization work? * Common
practice is to implement a set of \(t\)-tests to see if there is balance
* This makes no sense.

\footnotesize * If you doubt whether it was \textbf{implemented}
properly do an \(F\) test * If you worry about \textbf{variance} specify
controls in advance as a function of relation with outcomes (more on
this later) * If you worry about \textbf{conditional bias} then look at
substantive differences between groups, not \(t\)--tests
\end{frame}

\hypertarget{cluster-randomization}{%
\subsection{Cluster Randomization}\label{cluster-randomization}}

\begin{frame}{Cluster Randomization}
\protect\hypertarget{cluster-randomization-1}{}
\begin{itemize}
\tightlist
\item
  Simply place units into groups (clusters) and then randomly assign the
  groups to treatment and control.
\item
  All units in a given group get the same treatment
\end{itemize}

\textbf{Note:} clusters are part of your design, not part of the world.
\end{frame}

\begin{frame}{Cluster Randomization}
\protect\hypertarget{cluster-randomization-2}{}
\begin{itemize}
\item
  Often used if intervention has to function at the cluster level
  \textit{or} if outcome defined at the cluster level.
\item
  \textbf{Disadvantage:* \}} loss of statistical power
\item
  However: perfectly possible to assign \emph{some} treatments at
  cluster level and then \emph{other} treatments at the individual level

  \footnotesize
\item
  \textbf{Principle:} (unless you are worried about spillovers)
  generally make clusters as small as possible
\item
  \textbf{Principle:} Surprisingly, variability in cluster size makes
  analysis harder. (See analysis section)\\
\item
  \textbf{Be clear} about whether you believe effects are operating at
  the cluster level or at the individual level. This matters for power
  calculations.
\item
  \textbf{Be clear} about whether spillover effects operate only within
  clusters or also across them. If within only you might be able to
  interpret treatment as the effect of being in a treated cluster\dots 
\end{itemize}
\end{frame}

\begin{frame}{Cluster Randomization: Block by cluster size}
\protect\hypertarget{cluster-randomization-block-by-cluster-size}{}
\small Surprisingly, if clusters are of different sizes the difference
in means estimator is \textit{not} unbiased, even if all units are
assigned to treatment with the same probability. \bigskip
\textbf{Here's the intuition.} Say there are two clusters each with
homogeneous treatment effects:

\begin{table}
\begin{tabular}{cccc}
Cluster & Size  & Y0 &  Y1 \\ \hline
1   &  1000000  &  0    &  1 \\
2   &  1    &  0    &  0
\end{tabular} 
\end{table}

Then: * What is the true average treatment effect? * What do you expect
to estimate from cluster random assignment?

The solution is to block by cluster size. For more see:
\url{http://gking.harvard.edu/files/cluster.pdf}
\end{frame}

\hypertarget{blocked-assignments-and-other-restricted-randomizations}{%
\subsection{\texorpdfstring{Blocked assignments and other restricted
randomizations
\label{blocked}}{Blocked assignments and other restricted randomizations }}\label{blocked-assignments-and-other-restricted-randomizations}}

\begin{frame}{Blocking}
\protect\hypertarget{blocking}{}
There are more or less \textbf{efficient} ways to randomize.

\begin{itemize}
\tightlist
\item
  Randomization helps ensure good balance on all covariates (observed
  and unobserved) \textit{in expectation}.\\
\item
  But balance may not be so great \textit{in realization}
\item
  Blocking can help ensure balance ex post on observables
\end{itemize}

Consider a case with four units and two strata. There are 6 possible
assignments of 2 units to treatment:

\begin{table} \scriptsize
    \centering
        \begin{tabular}{cccc|cccccc} 
        ID  &   X   &   Y(0)    &   Y(1)    &   R1  &   R2  &   R3  &   R4  &   R5  &   R6  \\ \hline
        1   &   1   &   0   &   1   &   1   &   1   &   1   &   0   &   0   &   0   \\
        2   &   1   &   0   &   1   &   1   &   0   &   0   &   1   &   1   &   0   \\ \hline
        3   &   2   &   1   &   2   &   0   &   1   &   0   &   1   &   0   &   1   \\
        4   &   2   &   1   &   2   &   0   &   0   &   1   &   0   &   1   &   1   \\ \hline \hline
        $\widehat{\tau}$:   &       &       &       &   0   &   1   &   1   &   1   &   1   &   2   \\
        \end{tabular}
\end{table}

Even with a constant treatment effect and everything uniform within
blocks, there is variance in the estimation of \(\widehat{\tau}\). This
can be eliminated by excluding R1 and R6.
\end{frame}

\begin{frame}[fragile]{Blocking}
\protect\hypertarget{blocking-1}{}
Simple blocking in R (5 pairs):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(i) }\FunctionTok{rank}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\DecValTok{2}\NormalTok{))}\SpecialCharTok{==}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l}
\hline
1 & 2 & 3 & 4 & 5\\
\hline
TRUE & TRUE & TRUE & FALSE & FALSE\\
\hline
FALSE & FALSE & FALSE & TRUE & TRUE\\
\hline
\end{tabular}
\end{frame}

\begin{frame}{Of blocks and clusters}
\protect\hypertarget{of-blocks-and-clusters}{}
\begin{figure}
\centering
\includegraphics[width=0.6\linewidth]{figs/bf}
\label{fig:bf}
\end{figure}
\end{frame}

\begin{frame}{Blocking}
\protect\hypertarget{blocking-2}{}
\begin{itemize}
\tightlist
\item
  Blocking is a case of \textbf{restricted randomization}. Although each
  unit is sampled with equal probability, the \textit{profiles} of
  possible assignments are not.
\item
  You have to take account of this when doing analysis
\item
  There are many other approaches.

  \begin{itemize}
  \tightlist
  \item
    \textbf{Matched Pairs} are a particularly fine approach to blocking
  \item
    You could also randomize and then \textbf{replace the randomization}
    if you do not like the balance. This sounds tricky (and it is) but
    it is OK as long as you understand the true lottery process you are
    employing and incorporate that into analysis
  \item
    It is even possible to block on \textbf{covariates for which you
    don't have data} ex ante, by using methods in which you allocate
    treatment over time as a function of features of your sample (also
    tricky)
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Other types of restricted randomization}
\protect\hypertarget{other-types-of-restricted-randomization}{}
\begin{itemize}
\tightlist
\item
  Really you can set whatever criterion you want for your set of treated
  units to have (eg no treated unit beside another treated unit; at
  least 5 from the north, 10 from the south, guaranteed balance by some
  continuous variable etc)
\item
  You just have to be sure that you understand the random process that
  was used and that you can use it in the analysis stage
\item
  But here be dragons

  \begin{itemize}
  \tightlist
  \item
    The more complex your design, the more complex your analysis.
  \item
    General injunction
    (\href{http://www.ncbi.nlm.nih.gov/pubmed/15580598}{Senn 2004} ``as
    ye randomize so shall ye analyze'\,')
  \item
    In general you should make sure that a given randomization procedure
    coupled with a given estimation procedure will produce an unbiased
    estimate. \texttt{DeclareDesign} can help with this.
  \end{itemize}
\end{itemize}
\end{frame}

\hypertarget{factorial-designs}{%
\subsection{Factorial Designs}\label{factorial-designs}}

\begin{frame}{Factorial Designs}
\protect\hypertarget{factorial-designs-1}{}
\begin{itemize}
\tightlist
\item
  Often when you set up an experiment you want to look at more than one
  treatment.
\item
  Should you do this or not? How should you use your power?
\end{itemize}
\end{frame}

\begin{frame}{Factorial Designs}
\protect\hypertarget{factorial-designs-2}{}
\begin{itemize}
\tightlist
\item
  Often when you set up an experiment you want to look at more than one
  treatment.
\item
  Should you do this or not? How should you use your power?
\end{itemize}

\begin{table} 
\tiny
\begin{minipage}[b]{0.2\linewidth}\centering
    \begin{tabular}{c|cc}
    \footnotesize
        &               $T2=0$ & $T2=1$ \\ \hline 
    T1 = 0  &   $50\%$ & $0\%$ \\
    T1 = 1  &   $50\%$ &  $0\%$ \\
    \end{tabular}
\end{minipage}
\bigskip
\hspace{0.1cm}

\begin{minipage}[b]{0.2\linewidth}\centering
    \begin{tabular}{c|cc}
    \tiny
    &               $T2=0$ & $T2=1$ \\ \hline
    T1 = 0  &   $25\%$ & $25\%$ \\
    T1 = 1  &   $25\%$ &  $25\%$ \\
    \end{tabular}
\end{minipage}
\bigskip
\hspace{0.1cm}

\begin{minipage}[b]{0.2\linewidth}
    \centering
    \begin{tabular}{c|cc}
    \tiny
    &               $T2 = 0$ & $T2 = 1$ \\ \hline
    T1 = 0  &   $33.3\%$ & $33.3\%$ \\
    T1 = 1  &   $33.3\%$ &  $0\%$ \\
    \end{tabular}
    \end{minipage}
\end{table}
\end{frame}

\begin{frame}{Factorial Designs}
\protect\hypertarget{factorial-designs-3}{}
\begin{itemize}
\tightlist
\item
  Surprisingly adding multiple treatments does not eat into your power
  (unless you are decomposing a complex treatment -- then it can. Why?)
\item
  Especially when you use a fully crossed design like the middle one
  above.
\item
  Fisher: ``No aphorism is more frequently repeated in connection with
  field trials, than that we must ask Nature few questions, or, ideally,
  one question, at a time. The writer is convinced that this view is
  wholly mistaken.''
\item
  However -- adding multiple treatments \textit{does} alter the
  \textbf{interpretation} of your treatment effects. If T2 is an unusual
  treatment for example, then half the T1 effect is measured for unusual
  situations.
\end{itemize}
\end{frame}

\begin{frame}{Factorial Designs: In practice}
\protect\hypertarget{factorial-designs-in-practice}{}
\begin{itemize}
\tightlist
\item
  In practice if you have a lot of treatments it can be hard to do full
  factorial designs -- there may be too many combinations.\\
\item
  In such cases people use \textbf{fractional factorial designs}, like
  the one below (5 treatments but only 8 units!)

  \begin{table}[htbp]\scriptsize
    \centering
        \begin{tabular}{cccccc}\scriptsize
            Variation   &   T1  &   T2  &   T3  &   T4  &   T5  \\ \hline
            1   &   0   &   0   &   0   &   1   &   1   \\
            2   &   0   &   0   &   1   &   0   &   0   \\
            3   &   0   &   1   &   0   &   0   &   1   \\
            4   &   0   &   1   &   1   &   1   &   0   \\
            5   &   1   &   0   &   0   &   1   &   0   \\
            6   &   1   &   0   &   1   &   0   &   1   \\
            7   &   1   &   1   &   0   &   0   &   0   \\
            8   &   1   &   1   &   1   &   1   &   1   \\
        \end{tabular}
  \end{table}
\item
  Then randomly assign units to rows. Note columns might also be
  blocking covariates.
\item
  In R, look at \scriptsize \{\ttfamily library(survey); hadamard(7)\}
\end{itemize}
\end{frame}

\begin{frame}{Factorial Designs: In practice}
\protect\hypertarget{factorial-designs-in-practice-1}{}
\begin{itemize}
\tightlist
\item
  But be careful: you have to be comfortable with possibly not having
  any simple counterfactual unit for any unit (invoke
  sparsity-of-effects principle).

  \begin{table}[htbp]\scriptsize
   \centering
       \begin{tabular}{cccccc}\scriptsize
           Unit    &   T1  &   T2  &   T3  &   T4  &   T5  \\ \hline
           1   &   0   &   0   &   0   &   1   &   1   \\
           2   &   0   &   0   &   1   &   0   &   0   \\
           3   &   0   &   1   &   0   &   0   &   1   \\
           4   &   0   &   1   &   1   &   1   &   0   \\
           5   &   1   &   0   &   0   &   1   &   0   \\
           6   &   1   &   0   &   1   &   0   &   1   \\
           7   &   1   &   1   &   0   &   0   &   0   \\
           8   &   1   &   1   &   1   &   1   &   1   \\
       \end{tabular}
  \end{table}
\item
  In R, look at \scriptsize \{\ttfamily library(survey); hadamard(7)\}
\end{itemize}
\end{frame}

\hypertarget{external-validity-can-randomization-strategies-help}{%
\subsection{External Validity: Can randomization strategies
help?}\label{external-validity-can-randomization-strategies-help}}

\begin{frame}{Principle: Address \textbf{external validity} at the
design stage}
\protect\hypertarget{principle-address-external-validity-at-the-design-stage}{}
Anything to be done on randomization to address external validity
concerns?

\begin{itemize}
\tightlist
\item
  \textbf{Note 1}: There is little or nothing about field experiments
  that makes the external validity problem greater for these than for
  other ``sample based'\,' research
\item
  \textbf{Note 2}: Studies that use up the available universe (cross
  national studies) actually have a distinct external validity problem
\item
  Two ways to think about external validity issues:

  \begin{enumerate}
  \tightlist
  \item
    Are things likely to operate in other units like they operate in
    these units? (even with the same intervention)
  \item
    Are the processes in operation in this treatment likely to operate
    in other treatments? (even in this population)
  \end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}{Principle: Address \textbf{external validity} at the
design stage}
\protect\hypertarget{principle-address-at-the-design-stage}{}
\begin{itemize}
\tightlist
\item
  Two ways to think about external validity issues:

  \begin{enumerate}
  \tightlist
  \item
    Are things likely to operate in other units like they operate in
    these units? (even with the same intervention) 2.Are the processes
    in operation in this treatment likely to operate in other
    treatments? (even in this population)
  \end{enumerate}
\item
  Two approaches for 1.

  \begin{itemize}
  \tightlist
  \item
    Try to sample cases and estimate
    \textit{population average treatment effects}
  \item
    Exploit internal variation: block on features that make the case
    unusal and assess importance of these (eg is unit poor? assess how
    effects differ in poor and wealthy components)
  \end{itemize}
\item
  2 is harder and requires a sharp identification of context free
  primitives, if there are such things.
\end{itemize}
\end{frame}

\hypertarget{assignments-with-declaredesign}{%
\subsection{Assignments with
`DeclareDesign``}\label{assignments-with-declaredesign}}

\begin{frame}[fragile]{A design: Multilevel data}
\protect\hypertarget{a-design-multilevel-data}{}
A design with hierarchical data and different assignment schemes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}
    \AttributeTok{school =} \FunctionTok{add\_level}\NormalTok{(}\AttributeTok{N =} \DecValTok{16}\NormalTok{, }
                       \AttributeTok{u\_school =} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{)),     }
    \AttributeTok{classroom =} \FunctionTok{add\_level}\NormalTok{(}\AttributeTok{N =} \DecValTok{4}\NormalTok{,    }
                  \AttributeTok{u\_classroom =} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{)),}
    \AttributeTok{student =}  \FunctionTok{add\_level}\NormalTok{(}\AttributeTok{N =} \DecValTok{20}\NormalTok{,    }
                         \AttributeTok{u\_student =} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{))}
\NormalTok{    ) }\SpecialCharTok{+}
  \FunctionTok{declare\_model}\NormalTok{(}
    \FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .}\DecValTok{1}\SpecialCharTok{*}\NormalTok{Z }\SpecialCharTok{+}\NormalTok{ u\_classroom }\SpecialCharTok{+}\NormalTok{ u\_student }\SpecialCharTok{+}\NormalTok{ u\_school)}
\NormalTok{    ) }\SpecialCharTok{+}
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{simple\_ra}\NormalTok{(N)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_measurement}\NormalTok{(}\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z))  }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ATE =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{.method =}\NormalTok{ difference\_in\_means)    }
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Sample data \label{simpleAass}}
\protect\hypertarget{sample-data}{}
Here are the first couple of rows and columns of the resulting data
frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_data }\OtherTok{\textless{}{-}} \FunctionTok{draw\_data}\NormalTok{(design)}
\FunctionTok{kable}\NormalTok{(}\FunctionTok{head}\NormalTok{(my\_data), }\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l|r|l|r|r|r|r|r}
\hline
school & u\_school & classroom & u\_classroom & student & u\_student & Y\_Z\_0 & Y\_Z\_1 & Z & Y\\
\hline
01 & -0.77 & 01 & -0.06 & 0001 & 0.36 & -0.48 & -0.38 & 0 & -0.48\\
\hline
01 & -0.77 & 01 & -0.06 & 0002 & 0.16 & -0.67 & -0.57 & 0 & -0.67\\
\hline
01 & -0.77 & 01 & -0.06 & 0003 & 1.04 & 0.21 & 0.31 & 1 & 0.31\\
\hline
01 & -0.77 & 01 & -0.06 & 0004 & 1.54 & 0.70 & 0.80 & 0 & 0.70\\
\hline
01 & -0.77 & 01 & -0.06 & 0005 & -0.99 & -1.82 & -1.72 & 0 & -1.82\\
\hline
01 & -0.77 & 01 & -0.06 & 0006 & -0.70 & -1.53 & -1.43 & 0 & -1.53\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Sample data}
\protect\hypertarget{sample-data-1}{}
Here is the distribution between treatment and control:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{kable}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{table}\NormalTok{(my\_data}\SpecialCharTok{$}\NormalTok{Z))), }
      \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{"control"}\NormalTok{, }\StringTok{"treatment"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in eval(substitute(expr), data, enclos = parent.frame()): numeric 'envir' arg not of length one
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Complete Random Assignment using the built in
function \label{completeAss}}
\protect\hypertarget{complete-random-assignment-using-the-built-in-function}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assignment\_complete }\OtherTok{\textless{}{-}}   \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{complete\_ra}\NormalTok{(N))  }

\NormalTok{design\_complete }\OtherTok{\textless{}{-}} 
  \FunctionTok{replace\_step}\NormalTok{(design, }\StringTok{"assignment"}\NormalTok{, assignment\_complete)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Data from complete assignment}
\protect\hypertarget{data-from-complete-assignment}{}
We can draw a new set of data and look at the number of subjects in the
treatment and control groups.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{)}
\NormalTok{data\_complete }\OtherTok{\textless{}{-}} \FunctionTok{draw\_data}\NormalTok{(design\_complete)}

\FunctionTok{kable}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{table}\NormalTok{(data\_complete}\SpecialCharTok{$}\NormalTok{Z))))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in eval(substitute(expr), data, enclos = parent.frame()): numeric 'envir' arg not of length one
\end{verbatim}
\end{frame}

\begin{frame}{Plotted}
\protect\hypertarget{plotted}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-398-1.pdf}
\end{frame}

\begin{frame}{Block Random Assignment \label{blockedAss}}
\protect\hypertarget{block-random-assignment}{}
\begin{itemize}
\tightlist
\item
  The treatment and control group will \textbf{in expectation} contain
  the same share of students in different classrooms.
\item
  But as we saw this does necessarily hold in \textbf{realization}
\item
  We make this more obvious by sorting the students by treatment status
  with schools
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Blocked design}
\protect\hypertarget{blocked-design}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assignment\_blocked }\OtherTok{\textless{}{-}}   
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ classroom))  }

\NormalTok{estimator\_blocked }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{blocks =}\NormalTok{ classroom, }
                    \AttributeTok{.method =}\NormalTok{ difference\_in\_means)  }

\NormalTok{design\_blocked }\OtherTok{\textless{}{-}} 
\NormalTok{  design }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{replace\_step}\NormalTok{(}\StringTok{"assignment"}\NormalTok{, assignment\_blocked) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{replace\_step}\NormalTok{(}\StringTok{"estimator"}\NormalTok{, estimator\_blocked)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Illustration of blocked assignment}
\protect\hypertarget{illustration-of-blocked-assignment}{}
\begin{itemize}
\tightlist
\item
  Note that subjects are sorted here after the assignment to make it
  easier to see that in this case blocking ensures that exactly 5
  students within each classroom are assigned to treatment.
\end{itemize}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-400-1.pdf}
\end{frame}

\begin{frame}[fragile]{Clustering}
\protect\hypertarget{clustering}{}
But what if all students in a given class have to be assigned the same
treatment?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assignment\_clustered }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{cluster\_ra}\NormalTok{(}\AttributeTok{clusters =}\NormalTok{ classroom))  }
\NormalTok{estimator\_clustered }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{clusters =}\NormalTok{ classroom, }
                    \AttributeTok{.method =}\NormalTok{ difference\_in\_means)  }


\NormalTok{design\_clustered }\OtherTok{\textless{}{-}} 
\NormalTok{  design }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{replace\_step}\NormalTok{(}\StringTok{"assignment"}\NormalTok{, assignment\_clustered) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{replace\_step}\NormalTok{(}\StringTok{"estimator"}\NormalTok{, estimator\_clustered)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Illustration of clustered assignment}
\protect\hypertarget{illustration-of-clustered-assignment}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-402-1.pdf}
\end{frame}

\begin{frame}[fragile]{Clustered and Blocked}
\protect\hypertarget{clustered-and-blocked}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assignment\_clustered\_blocked }\OtherTok{\textless{}{-}}   
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{block\_and\_cluster\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ school,}
                                              \AttributeTok{clusters =}\NormalTok{ classroom))  }
\NormalTok{estimator\_clustered\_blocked }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{blocks =}\NormalTok{ school, }\AttributeTok{clusters =}\NormalTok{ classroom, }
                    \AttributeTok{.method =}\NormalTok{ difference\_in\_means)  }


\NormalTok{design\_clustered\_blocked }\OtherTok{\textless{}{-}} 
\NormalTok{  design }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{replace\_step}\NormalTok{(}\StringTok{"assignment"}\NormalTok{, assignment\_clustered\_blocked) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{replace\_step}\NormalTok{(}\StringTok{"estimator"}\NormalTok{, estimator\_clustered\_blocked)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Illustration of clustered and blocked assignment}
\protect\hypertarget{illustration-of-clustered-and-blocked-assignment}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-404-1.pdf}
\end{frame}

\begin{frame}[fragile]{Illustration of efficiency gains from blocking}
\protect\hypertarget{illustration-of-efficiency-gains-from-blocking}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{designs }\OtherTok{\textless{}{-}} 
  \FunctionTok{list}\NormalTok{(}
    \AttributeTok{simple =}\NormalTok{ design, }
    \AttributeTok{complete =}\NormalTok{ design\_complete, }
    \AttributeTok{blocked =}\NormalTok{ design\_blocked, }
    \AttributeTok{clustered =}\NormalTok{ design\_clustered,  }
    \AttributeTok{clustered\_blocked =}\NormalTok{ design\_clustered\_blocked) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnoses }\OtherTok{\textless{}{-}} \FunctionTok{diagnose\_design}\NormalTok{(designs)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Illustration of efficiency gains from blocking}
\protect\hypertarget{illustration-of-efficiency-gains-from-blocking-1}{}
\begin{tabular}{l|l|l}
\hline
Design & Power & Coverage\\
\hline
simple & 0.16 & 0.95\\
\hline
 & (0.01) & (0.01)\\
\hline
complete & 0.20 & 0.96\\
\hline
 & (0.01) & (0.01)\\
\hline
blocked & 0.42 & 0.95\\
\hline
 & (0.01) & (0.01)\\
\hline
clustered & 0.06 & 0.96\\
\hline
 & (0.01) & (0.01)\\
\hline
clustered\_blocked & 0.08 & 0.96\\
\hline
 & (0.01) & (0.01)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Sampling distributions}
\protect\hypertarget{sampling-distributions}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnoses}\SpecialCharTok{$}\NormalTok{simulations\_df }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{design =} \FunctionTok{factor}\NormalTok{(design, }\FunctionTok{c}\NormalTok{(}\StringTok{"blocked"}\NormalTok{, }\StringTok{"complete"}\NormalTok{, }\StringTok{"simple"}\NormalTok{, }\StringTok{"clustered\_blocked"}\NormalTok{, }\StringTok{"clustered"}\NormalTok{))) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(estimate)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{facet\_grid}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{design)}
\end{Highlighting}
\end{Shaded}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-408-1.pdf}
\end{frame}

\begin{frame}{Nasty integer issues}
\protect\hypertarget{nasty-integer-issues}{}
\end{frame}

\hypertarget{design-diagnosis}{%
\section{Design diagnosis}\label{design-diagnosis}}

\hypertarget{outline}{%
\subsection{Outline}\label{outline}}

\begin{frame}{Outline}
\begin{enumerate}
\tightlist
\item
  Tests review
\item
  \(p\) values and significance
\item
  Power
\item
  Sources of power
\item
  Advanced applications
\end{enumerate}
\end{frame}

\hypertarget{tests}{%
\subsection{Tests}\label{tests}}

\begin{frame}{Review}
\protect\hypertarget{review}{}
In the classical approach to testing a hypothesis we ask:

\textbf{How likely are we to see data like this if indeed the hypothesis
is true?}

\begin{itemize}
\tightlist
\item
  If the answer is ``not very likely'' then we treat the hypothesis as
  suspect.
\item
  If the answer is \emph{not} ``not very likely'' then the hypothesis is
  maintained (some say ``accepted'' but this is tricky as you may want
  to ``maintain'' multiple incompatible hypotheses)
\end{itemize}

How unlikely is ``not very likely''?
\end{frame}

\begin{frame}{Weighing Evidence}
\protect\hypertarget{weighing-evidence}{}
When we test a hypothesis we decide first on what sort of evidence we
need to see in order to decide that the hypothesis is not reliable.

\begin{itemize}
\item
  \textbf{Othello} has a hypothesis that Desdemona is innocent.
\item
  \textbf{Iago} confronts him with evidence:

  \begin{itemize}
  \tightlist
  \item
    See how she looks at him: would she look a him like that if she were
    innocent?
  \item
    \ldots{} would she defend him like that if she were innocent?
  \item
    \ldots{} would he have her handkerchief if she were innocent?
  \item
    Othello, the chances of all of these things arising if she were
    innocent is surely less than 5\%
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Hypotheses are often rejected, sometimes maintained, but
rarely accepted}
\protect\hypertarget{hypotheses-are-often-rejected-sometimes-maintained-but-rarely-accepted}{}
\begin{itemize}
\item
  Note that Othello is focused on the probability of the events if she
  were innocent but not the probability of the events if Iago were
  trying to trick him.
\item
  He is not assessing his belief in whether she is faithful, but rather
  how likely the data would be if she were faithful.
\end{itemize}

So:

\begin{itemize}
\tightlist
\item
  He assesses: \(\Pr(\text{Data} | \text{Hypothesis is TRUE})\)
\item
  While a Bayesian would assess:
  \(\Pr(\text{Hypothesis is TRUE} | \text{Data})\)
\end{itemize}
\end{frame}

\begin{frame}{Recap: Calculate a \(p\) value in your head}
\protect\hypertarget{recap-calculate-a-p-value-in-your-head}{}
\begin{itemize}
\item
  Illustrating \(p\) values via ``randomization inference''
\item
  Say you randomized assignment to treatment and your data looked like
  this.
\end{itemize}

\begin{longtable}[]{@{}lllllllllll@{}}
\toprule\noalign{}
Unit & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\midrule\noalign{}
\endhead
Treatment & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
Health score & 4 & 2 & 3 & 1 & 2 & 3 & 4 & 8 & 7 & 6 \\
\bottomrule\noalign{}
\end{longtable}

Then:

\begin{itemize}
\tightlist
\item
  Does the treatment improve your health?
\item
  What's the \(p\) value for the null that treatment had no effect on
  anybody?
\end{itemize}
\end{frame}

\begin{frame}{Calculate a \(p\) value in your head}
\protect\hypertarget{calculate-a-p-value-in-your-head-2}{}
\begin{itemize}
\tightlist
\item
  Illustrating \(p\) values via ``randomization inference''
\item
  Say you randomized assignment to treatment and your data looked like
  this.
\end{itemize}

\begin{longtable}[]{@{}lllllllllll@{}}
\toprule\noalign{}
Unit & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\midrule\noalign{}
\endhead
Treatment & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
Health score & 4 & 2 & 3 & 1 & 2 & 3 & 4 & 8 & 7 & 6 \\
\bottomrule\noalign{}
\end{longtable}

Then:

\begin{itemize}
\tightlist
\item
  Does the treatment improve your health?
\item
  What's the \(p\) value for the null that treatment had no effect on
  anybody?
\end{itemize}
\end{frame}

\hypertarget{power}{%
\subsection{Power}\label{power}}

\hypertarget{what-power-is}{%
\subsection{What power is}\label{what-power-is}}

\begin{frame}{What power is}
Power is just the probability of \st{getting a significant result}
rejecting a hypothesis.

Simple enough but it presupposes:

\begin{itemize}
\tightlist
\item
  A well defined hypothesis
\item
  An actual stipulation of the world under which you evaluate the
  probability
\item
  A procedure for producing results and determining of they are
  significant / rejecting a hypothesis
\end{itemize}
\end{frame}

\begin{frame}{By hand}
\protect\hypertarget{by-hand}{}
I want to test the hypothesis that a six never comes up on this dice.

Here's my \textbf{test}:

\begin{itemize}
\tightlist
\item
  I will roll the dice \textbf{once}.
\item
  If a six comes up I will reject the hypothesis.
\end{itemize}

What is the power of this test?

\includegraphics[width=1in,height=\textheight]{assets/dice.jpeg}
\end{frame}

\begin{frame}{By hand}
\protect\hypertarget{by-hand-1}{}
I want to test the hypothesis that a six never comes up on this dice.

Here's my \textbf{test}:

\begin{itemize}
\tightlist
\item
  I will roll the dice \textbf{twice}.
\item
  If a six comes up \textbf{either time} I will reject the hypothesis.
\end{itemize}

What is the power of \emph{this} test?

\includegraphics[width=1in,height=\textheight]{assets/dice.jpeg}
\end{frame}

\begin{frame}{Two probabilities}
\protect\hypertarget{two-probabilities}{}
Power sometimes seems more complicated because hypothesis rejection
involves a calculated probability and so you need the probability of a
probability.

I want to test the hypothesis that this dice is \emph{fair}.

Here's my \textbf{test}:

\begin{itemize}
\tightlist
\item
  I will roll the dice \textbf{1000} times and if I see fewer than
  \emph{x} 6s or more than \emph{y} 6s I will reject the hypothesis.
\end{itemize}

Now:

\begin{itemize}
\tightlist
\item
  What should \emph{x} and \emph{y} be?
\item
  What is the power of this test?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Step 1: When do you reject?}
\protect\hypertarget{step-1-when-do-you-reject}{}
For this we need to figure a rule for rejection. This is based on
identifying events that should be unlikely under the hypothesis.

Here is how many 6's I would expect if the dice is fair:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fabricate}\NormalTok{(}\AttributeTok{N =} \DecValTok{1001}\NormalTok{, }\AttributeTok{sixes =} \DecValTok{0}\SpecialCharTok{:}\DecValTok{1000}\NormalTok{, }\AttributeTok{p =} \FunctionTok{dbinom}\NormalTok{(sixes, }\DecValTok{1000}\NormalTok{, }\DecValTok{1}\SpecialCharTok{/}\DecValTok{6}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(sixes, p)) }\SpecialCharTok{+} \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-434-1.pdf}
\end{frame}

\begin{frame}[fragile]{Step 1: When do you reject?}
\protect\hypertarget{step-1-when-do-you-reject-1}{}
I can figure out from this that 143 or fewer is really very few and 190
or more is really very many:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\AttributeTok{lower =} \FunctionTok{pbinom}\NormalTok{(}\DecValTok{143}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{1}\SpecialCharTok{/}\DecValTok{6}\NormalTok{), }\AttributeTok{upper =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pbinom}\NormalTok{(}\DecValTok{189}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{1}\SpecialCharTok{/}\DecValTok{6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     lower      upper 
0.02302647 0.02785689 
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Step 2: What is the power?}
\protect\hypertarget{step-2-what-is-the-power}{}
\begin{itemize}
\item
  Now we need to stipulate some belief about how the world really
  works---this is not the null hypothesis that we plan to reject, but
  something that we actually take to be true.
\item
  For instance: we think that \emph{in fact} sixes appear 20\% of the
  time.
\end{itemize}

Now what's the probability of seeing at least 190 sixes?

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pbinom}\NormalTok{(}\DecValTok{189}\NormalTok{, }\DecValTok{1000}\NormalTok{, .}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.796066
\end{verbatim}

So given I think 6s appear 20\% of the time, I think it likely I'll see
at least 190 sixes and reject the hypothesis of a fair dice.
\end{frame}

\begin{frame}{Rule of thumb}
\protect\hypertarget{rule-of-thumb}{}
\begin{itemize}
\tightlist
\item
  80\% or 90\% is a common rule of thumb for ``sufficient'' power
\item
  but really, how much power you need depends on the purpose
\end{itemize}
\end{frame}

\begin{frame}{Think about}
\protect\hypertarget{think-about}{}
\begin{itemize}
\tightlist
\item
  Are there other tests I could have implemented?
\item
  Are there other ways to improve this test?
\end{itemize}
\end{frame}

\begin{frame}{Last subtleties}
\protect\hypertarget{last-subtleties}{}
\begin{itemize}
\tightlist
\item
  Is a significant result from an underpowered study less credible?
  (only if there is a significance filter)
\item
  What significance level should you choose for power? (Obviously the
  stricter the level the lower the power, so use what you will use when
  you actually implement tests)
\item
  Do you really have to know the effect size to do power analysis? (No,
  but you should know at least what effects sizes you would want to be
  sure about picking up if they were present)
\item
  Power is just one of many possible diagnosands
\item
  What's power for Bayesians?
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Power via design diagnosis}
\protect\hypertarget{power-via-design-diagnosis}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{b }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}

\NormalTok{design }\OtherTok{\textless{}{-}} 
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }
    \AttributeTok{U =} \FunctionTok{rnorm}\NormalTok{(N),}
    \FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ U)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{simple\_ra}\NormalTok{(N),}
                     \AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+} 
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }\AttributeTok{.method =}\NormalTok{ lm\_robust)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{``Run'' the design once}
\protect\hypertarget{run-the-design-once-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{run\_design}\NormalTok{(design)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{Summary of a single 'run' of the design}
\centering
\begin{tabular}[t]{l|r|l|l|r|r|r|r|r|r|r|l}
\hline
inquiry & estimand & estimator & term & estimate & std.error & statistic & p.value & conf.low & conf.high & df & outcome\\
\hline
ate & 0.5 & estimator & Z & 0.42 & 0.17 & 2.45 & 0.02 & 0.08 & 0.76 & 98 & Y\\
\hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}[fragile]{Run it many times}
\protect\hypertarget{run-it-many-times-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims\_1 }\OtherTok{\textless{}{-}} \FunctionTok{simulate\_design}\NormalTok{(design) }

\NormalTok{sims\_1 }\SpecialCharTok{|\textgreater{}} \FunctionTok{select}\NormalTok{(sim\_ID, estimate, p.value)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r}
\hline
sim\_ID & estimate & p.value\\
\hline
1 & 0.81 & 0.00\\
\hline
2 & 0.40 & 0.04\\
\hline
3 & 0.88 & 0.00\\
\hline
4 & 0.72 & 0.00\\
\hline
5 & 0.38 & 0.05\\
\hline
6 & 0.44 & 0.02\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Power is mass of the sampling distribution of
decisions under the model}
\protect\hypertarget{power-is-mass-of-the-sampling-distribution-of-decisions-under-the-model-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims\_1 }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(p.value)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ .}\DecValTok{05}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-442-1.pdf}
\end{frame}

\begin{frame}[fragile]{Power is mass of the sampling distribution of
decisions under the model}
\protect\hypertarget{power-is-mass-of-the-sampling-distribution-of-decisions-under-the-model-2}{}
Obviously related to the estimates you might get

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims\_1 }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{significant =}\NormalTok{ p.value }\SpecialCharTok{\textless{}=}\NormalTok{ .}\DecValTok{05}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(estimate, p.value, }\AttributeTok{color =}\NormalTok{ significant)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-443-1.pdf}
\end{frame}

\begin{frame}[fragile]{Check coverage is correct}
\protect\hypertarget{check-coverage-is-correct}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims\_1 }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{within =}\NormalTok{ (b }\SpecialCharTok{\textgreater{}}\NormalTok{ sims\_1}\SpecialCharTok{$}\NormalTok{conf.low) }\SpecialCharTok{\&}\NormalTok{ (b }\SpecialCharTok{\textless{}}\NormalTok{ sims\_1}\SpecialCharTok{$}\NormalTok{conf.high)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{pull}\NormalTok{(within) }\SpecialCharTok{|\textgreater{}} \FunctionTok{mean}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.9573333
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Check validity of \(p\) value}
\protect\hypertarget{check-validity-of-p-value}{}
A valid \(p\)-value satisfies \(\Pr(p≤x)≤x\) for every \(x \in[0,1]\)
(under the null)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims\_2 }\OtherTok{\textless{}{-}} 
  
  \FunctionTok{redesign}\NormalTok{(design, }\AttributeTok{b =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  
  \FunctionTok{simulate\_design}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-447-1.pdf}
\end{frame}

\begin{frame}[fragile]{Design diagnosis does it all (over multiple
designs)}
\protect\hypertarget{design-diagnosis-does-it-all-over-multiple-designs-1}{}
\begin{Shaded}
\begin{Highlighting}[]
  \FunctionTok{diagnose\_design}\NormalTok{(design)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l}
\hline
Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
0.50 & 0.00 & 0.20 & 0.20 & 0.70 & 0.95\\
\hline
(0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Design diagnosis does it all}
\protect\hypertarget{design-diagnosis-does-it-all-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{redesign}\NormalTok{(}\AttributeTok{b =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{diagnose\_design}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l|l}
\hline
b & Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
0 & -0.00 & -0.00 & 0.20 & 0.20 & 0.05 & 0.95\\
\hline
 & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
0.25 & 0.25 & -0.00 & 0.20 & 0.20 & 0.23 & 0.95\\
\hline
 & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
0.5 & 0.50 & 0.00 & 0.20 & 0.20 & 0.70 & 0.95\\
\hline
 & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
1 & 1.00 & 0.00 & 0.20 & 0.20 & 1.00 & 0.95\\
\hline
 & (0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.00)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Diagnose over multiple moving parts (and ggplot)}
\protect\hypertarget{diagnose-over-multiple-moving-parts-and-ggplot}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\SpecialCharTok{|\textgreater{}}
  \DocumentationTok{\#\# Redesign}
  \FunctionTok{redesign}\NormalTok{(}\AttributeTok{b =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\AttributeTok{N =} \DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{300}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \DocumentationTok{\#\# Diagnosis}
  \FunctionTok{diagnose\_design}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \DocumentationTok{\#\# Prep}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(diagnosand }\SpecialCharTok{==} \StringTok{"power"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \DocumentationTok{\#\# Plot}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(N, estimate, }\AttributeTok{color =} \FunctionTok{factor}\NormalTok{(b))) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Diagnose over multiple moving parts (and ggplot)}
\protect\hypertarget{diagnose-over-multiple-moving-parts-and-ggplot-1}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-453-1.pdf}
\end{frame}

\begin{frame}[fragile]{Diagnose over multiple moving parts and multiple
diagnosands (and ggplot)}
\protect\hypertarget{diagnose-over-multiple-moving-parts-and-multiple-diagnosands-and-ggplot}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\SpecialCharTok{|\textgreater{}}

  \DocumentationTok{\#\# Redesign}
  \FunctionTok{redesign}\NormalTok{(}\AttributeTok{b =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\AttributeTok{N =} \DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{300}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  
  \DocumentationTok{\#\# Diagnosis}
  \FunctionTok{diagnose\_design}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  
  \DocumentationTok{\#\# Prep}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  
  \DocumentationTok{\#\# Plot}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(N, estimate, }\AttributeTok{color =} \FunctionTok{factor}\NormalTok{(b))) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{diagnosand)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Diagnose over multiple moving parts and multiple
diagnosands (and ggplot)}
\protect\hypertarget{diagnose-over-multiple-moving-parts-and-multiple-diagnosands-and-ggplot-1}{}
\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-455-1.pdf}
\end{frame}

\hypertarget{beyond-basics}{%
\subsection{Beyond basics}\label{beyond-basics}}

\begin{frame}{Power tips}
\protect\hypertarget{power-tips}{}
coming up:

\begin{itemize}
\tightlist
\item
  power everywhere
\item
  power with bias
\item
  power with the wrong standard errors
\item
  power with uncertainty over effect sizes
\item
  power and multiple comparisons
\end{itemize}
\end{frame}

\begin{frame}{Power depends on all parts of MIDA}
\protect\hypertarget{power-depends-on-all-parts-of-mida}{}
We often focus on sample sizes

\textbf{But}

Power also depends on

\begin{itemize}
\tightlist
\item
  the model -- obviously signal to noise
\item
  the assignments and specifics of sampling strategies
\item
  estimation procedures
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Power when estimates are biased}
\protect\hypertarget{power-when-estimates-are-biased}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bad\_design }\OtherTok{\textless{}{-}} 
  
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{100}\NormalTok{, }
    \AttributeTok{U =} \FunctionTok{rnorm}\NormalTok{(N),}
    \FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \DecValTok{0} \SpecialCharTok{*}\NormalTok{ X }\SpecialCharTok{+}\NormalTok{ U, }\AttributeTok{conditions =} \FunctionTok{list}\NormalTok{(}\AttributeTok{X =} \DecValTok{0}\SpecialCharTok{:}\DecValTok{1}\NormalTok{)),}
    \AttributeTok{X =} \FunctionTok{ifelse}\NormalTok{(U }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)) }\SpecialCharTok{+} 
  
  \FunctionTok{declare\_measurement}\NormalTok{(}\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X)) }\SpecialCharTok{+} 
  
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(Y\_X\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_X\_0)) }\SpecialCharTok{+} 
  
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }\AttributeTok{.method =}\NormalTok{ lm\_robust)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Power when estimates are biased}
\protect\hypertarget{power-when-estimates-are-biased-1}{}
You can see from the null design that power is great but bias is
terrible and coverage is way off.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{diagnose\_design}\NormalTok{(bad\_design)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l}
\hline
Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
1.59 & 1.59 & 0.12 & 1.60 & 1.00 & 0.00\\
\hline
(0.01) & (0.01) & (0.00) & (0.01) & (0.00) & (0.00)\\
\hline
\end{tabular}

Power without unbiasedness corrupts, absolutely
\end{frame}

\begin{frame}[fragile]{Power with a more subtly biased experimental
design}
\protect\hypertarget{power-with-a-more-subtly-biased-experimental-design}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{another\_bad\_design }\OtherTok{\textless{}{-}} 
  
  \FunctionTok{declare\_model}\NormalTok{(}
    \AttributeTok{N =} \DecValTok{100}\NormalTok{, }
    \AttributeTok{female =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, N}\SpecialCharTok{/}\DecValTok{2}\NormalTok{),}
    \AttributeTok{U =} \FunctionTok{rnorm}\NormalTok{(N),}
    \FunctionTok{potential\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ female }\SpecialCharTok{*}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ U)) }\SpecialCharTok{+} 
  
  \FunctionTok{declare\_assignment}\NormalTok{(}
    \AttributeTok{Z =} \FunctionTok{block\_ra}\NormalTok{(}\AttributeTok{blocks =}\NormalTok{ female, }\AttributeTok{block\_prob =} \FunctionTok{c}\NormalTok{(.}\DecValTok{1}\NormalTok{, .}\DecValTok{5}\NormalTok{)),}
    \AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+} 

  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+} 
  
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z }\SpecialCharTok{+}\NormalTok{ female, }\AttributeTok{inquiry =} \StringTok{"ate"}\NormalTok{, }
                    \AttributeTok{.method =}\NormalTok{ lm\_robust)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
  \FunctionTok{diagnose\_design}\NormalTok{(another\_bad\_design)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}{Power with a more subtly biased experimental design}
\protect\hypertarget{power-with-a-more-subtly-biased-experimental-design-1}{}
You can see from the null design that power is great but bias is
terrible and coverage is way off.

\begin{tabular}{l|l|l|l|l|l}
\hline
Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
0.76 & 0.26 & 0.24 & 0.35 & 0.84 & 0.85\\
\hline
(0.01) & (0.01) & (0.01) & (0.01) & (0.01) & (0.02)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Power with the wrong standard errors}
\protect\hypertarget{power-with-the-wrong-standard-errors}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clustered\_design }\OtherTok{\textless{}{-}}
  \FunctionTok{declare\_model}\NormalTok{(}
    \AttributeTok{cluster =} \FunctionTok{add\_level}\NormalTok{(}\AttributeTok{N =} \DecValTok{10}\NormalTok{, }\AttributeTok{cluster\_shock =} \FunctionTok{rnorm}\NormalTok{(N)),}
    \AttributeTok{individual =} \FunctionTok{add\_level}\NormalTok{(}
        \AttributeTok{N =} \DecValTok{100}\NormalTok{,}
        \AttributeTok{Y\_Z\_0 =} \FunctionTok{rnorm}\NormalTok{(N) }\SpecialCharTok{+}\NormalTok{ cluster\_shock,}
        \AttributeTok{Y\_Z\_1 =} \FunctionTok{rnorm}\NormalTok{(N) }\SpecialCharTok{+}\NormalTok{ cluster\_shock)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ATE =} \FunctionTok{mean}\NormalTok{(Y\_Z\_1 }\SpecialCharTok{{-}}\NormalTok{ Y\_Z\_0)) }\SpecialCharTok{+}
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{cluster\_ra}\NormalTok{(}\AttributeTok{clusters =}\NormalTok{ cluster)) }\SpecialCharTok{+}
  \FunctionTok{declare\_measurement}\NormalTok{(}\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{inquiry =} \StringTok{"ATE"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l}
\hline
Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
-0.00 & -0.00 & 0.64 & 0.64 & 0.79 & 0.20\\
\hline
(0.01) & (0.01) & (0.01) & (0.01) & (0.01) & (0.01)\\
\hline
\end{tabular}

What alerts you to a problem?
\end{frame}

\begin{frame}[fragile]{Let's fix that one}
\protect\hypertarget{lets-fix-that-one}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clustered\_design\_2  }\OtherTok{\textless{}{-}}
\NormalTok{  clustered\_design }\SpecialCharTok{|\textgreater{}} \FunctionTok{replace\_step}\NormalTok{(}\DecValTok{5}\NormalTok{, }
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z, }\AttributeTok{clusters =}\NormalTok{ cluster))}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|l|l|l|l|l}
\hline
Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
0.00 & -0.00 & 0.66 & 0.65 & 0.06 & 0.94\\
\hline
(0.02) & (0.02) & (0.01) & (0.01) & (0.01) & (0.01)\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Power when you are not sure about effect sizes
(always!)}
\protect\hypertarget{power-when-you-are-not-sure-about-effect-sizes-always}{}
\begin{itemize}
\tightlist
\item
  you can do power analysis for multiple stipulations
\item
  or you can design with a distribution of effect sizes
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_uncertain }\OtherTok{\textless{}{-}}
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{1000}\NormalTok{, }\AttributeTok{b =} \DecValTok{1}\SpecialCharTok{+}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{), }\AttributeTok{Y\_Z\_1 =} \FunctionTok{rnorm}\NormalTok{(N), }\AttributeTok{Y\_Z\_2 =} \FunctionTok{rnorm}\NormalTok{(N) }\SpecialCharTok{+}\NormalTok{ b, }\AttributeTok{Y\_Z\_3 =} \FunctionTok{rnorm}\NormalTok{(N) }\SpecialCharTok{+}\NormalTok{ b) }\SpecialCharTok{+}
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{complete\_ra}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{num\_arms =} \DecValTok{3}\NormalTok{, }\AttributeTok{conditions =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{declare\_measurement}\NormalTok{(}\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =} \FunctionTok{mean}\NormalTok{(b)) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Z), }\AttributeTok{term =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{draw\_estimands}\NormalTok{(design\_uncertain)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  inquiry estimand
1     ate 1.523312
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{draw\_estimands}\NormalTok{(design\_uncertain)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  inquiry  estimand
1     ate 0.7887188
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Multiple comparisons correction (complex code)}
\protect\hypertarget{multiple-comparisons-correction-complex-code}{}
Say I run two tests and want to correct for multiple comparisons.

Two approaches. First, by hand:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OtherTok{=}\NormalTok{ .}\DecValTok{2}

\NormalTok{design\_mc }\OtherTok{\textless{}{-}}
  \FunctionTok{declare\_model}\NormalTok{(}\AttributeTok{N =} \DecValTok{1000}\NormalTok{, }\AttributeTok{Y\_Z\_1 =} \FunctionTok{rnorm}\NormalTok{(N), }\AttributeTok{Y\_Z\_2 =} \FunctionTok{rnorm}\NormalTok{(N) }\SpecialCharTok{+}\NormalTok{ b, }\AttributeTok{Y\_Z\_3 =} \FunctionTok{rnorm}\NormalTok{(N) }\SpecialCharTok{+}\NormalTok{ b) }\SpecialCharTok{+}
  \FunctionTok{declare\_assignment}\NormalTok{(}\AttributeTok{Z =} \FunctionTok{complete\_ra}\NormalTok{(}\AttributeTok{N =}\NormalTok{ N, }\AttributeTok{num\_arms =} \DecValTok{3}\NormalTok{, }\AttributeTok{conditions =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{declare\_measurement}\NormalTok{(}\AttributeTok{Y =} \FunctionTok{reveal\_outcomes}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Z)) }\SpecialCharTok{+}
  \FunctionTok{declare\_inquiry}\NormalTok{(}\AttributeTok{ate =}\NormalTok{ b) }\SpecialCharTok{+}
  \FunctionTok{declare\_estimator}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Z), }\AttributeTok{term =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Multiple comparisons correction (complex code)}
\protect\hypertarget{multiple-comparisons-correction-complex-code-1}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_mc }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{simulate\_designs}\NormalTok{(}\AttributeTok{sims =} \DecValTok{1000}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(term }\SpecialCharTok{!=} \StringTok{"(Intercept)"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(sim\_ID) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_bonferroni =} \FunctionTok{p.adjust}\NormalTok{(}\AttributeTok{p =}\NormalTok{ p.value, }\AttributeTok{method =} \StringTok{"bonferroni"}\NormalTok{),}
         \AttributeTok{p\_holm =} \FunctionTok{p.adjust}\NormalTok{(}\AttributeTok{p =}\NormalTok{ p.value, }\AttributeTok{method =} \StringTok{"holm"}\NormalTok{),}
         \AttributeTok{p\_fdr =} \FunctionTok{p.adjust}\NormalTok{(}\AttributeTok{p =}\NormalTok{ p.value, }\AttributeTok{method =} \StringTok{"fdr"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarize}\NormalTok{(}
    \StringTok{"Power using naive p{-}values"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(p.value }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{),}
    \StringTok{"Power using Bonferroni correction"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(p\_bonferroni }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{),}
    \StringTok{"Power using Holm correction"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(p\_holm }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{),}
    \StringTok{"Power using FDR correction"} \OtherTok{=} \FunctionTok{mean}\NormalTok{(p\_fdr }\SpecialCharTok{\textless{}=} \FloatTok{0.05}\NormalTok{)}
\NormalTok{    ) }
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r|r}
\hline
Power using naive p-values & Power using Bonferroni correction & Power using Holm correction & Power using FDR correction\\
\hline
0.7374 & 0.6318 & 0.6886 & 0.7032\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Multiple comparisons correction (approach 2)}
\protect\hypertarget{multiple-comparisons-correction-approach-2}{}
The alternative approach (generally better!) is to design with a custom
estimator that includes your corrections.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_estimator }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) }
  \FunctionTok{lm\_robust}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(Z), }\AttributeTok{data =}\NormalTok{ data) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(term }\SpecialCharTok{!=} \StringTok{"(Intercept)"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p.naive =}\NormalTok{ p.value,}
         \AttributeTok{p.value =} \FunctionTok{p.adjust}\NormalTok{(}\AttributeTok{p =}\NormalTok{ p.naive, }\AttributeTok{method =} \StringTok{"bonferroni"}\NormalTok{))}
  

\NormalTok{design\_mc\_2 }\OtherTok{\textless{}{-}}\NormalTok{ design\_mc }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{replace\_step}\NormalTok{(}\DecValTok{5}\NormalTok{, }\FunctionTok{declare\_estimator}\NormalTok{(}\AttributeTok{handler =} \FunctionTok{label\_estimator}\NormalTok{(my\_estimator))) }

\FunctionTok{run\_design}\NormalTok{(design\_mc\_2) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(term, estimate, p.value, p.naive) }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|r|r}
\hline
term & estimate & p.value & p.naive\\
\hline
factor(Z)2 & 0.2508003 & 0.0021145 & 0.0010573\\
\hline
factor(Z)3 & 0.2383963 & 0.0052469 & 0.0026235\\
\hline
\end{tabular}
\end{frame}

\begin{frame}[fragile]{Multiple comparisons correction (Null model
case)}
\protect\hypertarget{multiple-comparisons-correction-null-model-case}{}
Lets try same thing for a null model (using
\texttt{redesign(design\_mc\_2,\ b\ =\ 0)})

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design\_mc\_3 }\OtherTok{\textless{}{-}} 
\NormalTok{  design\_mc\_2 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{redesign}\NormalTok{(}\AttributeTok{b =} \DecValTok{0}\NormalTok{) }

\FunctionTok{run\_design}\NormalTok{(design\_mc\_3) }\SpecialCharTok{|\textgreater{}} \FunctionTok{select}\NormalTok{(estimate, p.value, p.naive) }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r}
\hline
estimate & p.value & p.naive\\
\hline
-0.0363484 & 1 & 0.6297813\\
\hline
-0.0020170 & 1 & 0.9787214\\
\hline
\end{tabular}
\end{frame}

\begin{frame}{Multiple comparisons correction (Null model case)}
\protect\hypertarget{multiple-comparisons-correction-null-model-case-1}{}
\ldots and power:

\begin{tabular}{l|l|l|l|l|l}
\hline
Mean Estimate & Bias & SD Estimate & RMSE & Power & Coverage\\
\hline
0.00 & 0.00 & 0.08 & 0.08 & 0.02 & 0.95\\
\hline
(0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.01)\\
\hline
-0.00 & -0.00 & 0.08 & 0.08 & 0.02 & 0.96\\
\hline
(0.00) & (0.00) & (0.00) & (0.00) & (0.00) & (0.01)\\
\hline
\end{tabular}

bothered?
\end{frame}

\begin{frame}{You might try}
\protect\hypertarget{you-might-try}{}
\begin{itemize}
\tightlist
\item
  Power for an interaction (in a factorial design)
\item
  Power for a binary variable (versus a continuous variable?)
\item
  Power from adding covariates in the analysis stage
\item
  Power gains from blocked randomization
\item
  Power losses from clustering at different levels
\item
  Controlling the ICC directly? (see book cluster designs section)
\end{itemize}
\end{frame}

\begin{frame}{Big takeaways}
\protect\hypertarget{big-takeaways}{}
\begin{itemize}
\tightlist
\item
  Power is affected not just by sample size, variability and effect size
  but also by you data and analysis strategies.
\item
  Try to estimate power under multiple scenarios
\item
  Try to use the same code for calculating power as you will use in your
  ultimate analysis
\item
  Basically the same procedure can be used for any design. If you can
  declare a design and have a test, you can calculate power
\item
  Your power might be right but misleading. For confidence:

  \begin{itemize}
  \tightlist
  \item
    Don't just check power, check bias and coverage also
  \item
    Check power especially \emph{under the null}
  \end{itemize}
\item
  Don't let a focus on power distract you from more \emph{substantive}
  diagnosands
\end{itemize}
\end{frame}

\hypertarget{topics}{%
\section{Topics}\label{topics}}

\begin{frame}{Topics}
\hyperlink{ideas}{\beamergotobutton{Top}}
\end{frame}

\hypertarget{noncompliance-and-the-late-estimand}{%
\subsection{\texorpdfstring{Noncompliance and the LATE estimand
\label{LATE}}{Noncompliance and the LATE estimand }}\label{noncompliance-and-the-late-estimand}}

\begin{frame}{LATE---Local Average Treatment Effects}
\protect\hypertarget{latelocal-average-treatment-effects}{}
\footnotesize

Sometimes you give a medicine but only a non random sample of people
actually try to use it. Can you still estimate the medicine's effect?

\begin{table}
    \scriptsize
    \centering
        \begin{tabular}{l|cc}
        &$X=0$&$X=1$\\ \hline
        $T=0$& $\overline{y}_{00}$ & $\overline{y}_{01}$ \\
           & $(n_{00})$ & $(n_{01})$\\ \hline
        $T=1$& $\overline{y}_{10}$ & $\overline{y}_{11}$ \\ 
               & $(n_{10})$ & $(n_{11})$\\ \hline
        \end{tabular}
\end{table}

Say that people are one of 3 types:

\begin{enumerate}
\tightlist
\item
  \(n_a\) ``always takers'\,' have \(X=1\) no matter what and have
  average outcome \(\overline{y}_a\)
\item
  \(n_n\) never takers have \(X=0\) no matter what with outcome
  \(\overline{y}_n\)
\item
  \(n_c\) compliers have \(X=T\) and average outcomes
  \(\overline{y}^1_c\) if treated and \(\overline{y}^0_c\) if not.
\end{enumerate}
\end{frame}

\begin{frame}{LATE---Local Average Treatment Effects}
\protect\hypertarget{latelocal-average-treatment-effects-1}{}
Sometimes you give a medicine but only a non random sample of people
actually try to use it. Can you still estimate the medicine's effect?

\begin{table}
    \scriptsize
    \centering
        \begin{tabular}{l|cc}
        &$X=0$&$X=1$\\ \hline
        $T=0$& $\overline{y}_{00}$ & $\overline{y}_{01}$ \\
           & $(n_{00})$ & $(n_{01})$\\ \hline
        $T=1$& $\overline{y}_{10}$ & $\overline{y}_{11}$ \\ 
               & $(n_{10})$ & $(n_{11})$\\ \hline
        \end{tabular}
\end{table}

We can figure something about types:

\begin{table}
\scriptsize
\centering
\begin{tabular}{l|cc}
&$X=0$ & $X=1$\\ \hline
$T=0$ &  $\frac{\frac{1}{2}n_c}{\frac{1}{2}n_c + \frac{1}{2}n_n} \overline{y}^0_{c}+\frac{\frac{1}{2}n_n}{\frac{1}{2}n_c + \frac{1}{2}n_n} \overline{y}_{n}$ &  $\overline{y}_{a}$ \\
$T=1$& $\overline{y}_{n}$ & 
$\frac{\frac{1}{2}n_c}{\frac{1}{2}n_c + \frac{1}{2}n_a} \overline{y}^1_{c}+\frac{\frac{1}{2}n_a}{\frac{1}{2}n_c + \frac{1}{2}n_a} \overline{y}_{a}$         \\ \hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}{LATE---Local Average Treatment Effects}
\protect\hypertarget{latelocal-average-treatment-effects-2}{}
\footnotesize

You give a medicine to 50\% but only a non random sample of people
actually try to use it. Can you still estimate the medicine's effect?

\begin{table}
\scriptsize
\centering
\begin{tabular}{l|cc}
&$X=0$&$X=1$\\ \hline
$T=0$ & $\frac{n_c}{n_c + n_n} \overline{y}^0_{c}+\frac{n_n}{n_c + n_n} \overline{y}_n$ &  $\overline{y}_{a}$ \\
(n)&   ($\frac{1}{2}(n_c + n_n)$) &  ($\frac{1}{2}n_a$)\\ \\
$T=1$& $\overline{y}_{n}$ & $\frac{n_c}{n_c + n_a} \overline{y}^1_{c}+\frac{n_a}{n_c + n_a} \overline{y}_{a}$  \\
(n)&  ($\frac{1}{2}n_n$) &  ($\frac{1}{2}(n_a+n_c)$)\\

\end{tabular}
\end{table}

Average in \(T=0\) group:
\(\frac{{n_c} \overline{y}^0_{c}+ \left(n_{n}\overline{y}_{n} +{n_a} \overline{y}_a\right)}{n_a+n_c+n_n}\)

Average in \(T=1\) group:
\(\frac{{n_c} \overline{y}^1_{c} + \left(n_{n}\overline{y}_{n} +{n_a} \overline{y}_a \right)}{n_a+n_c+n_n}\)

Difference: \(ITT = ({\overline{y}^1_c-\overline{y}^0_c})\frac{n_c}{n}\)

So: \(LATE = ITT\times\frac{n}{n_c}\)
\end{frame}

\begin{frame}{The good and the bad of LATE}
\protect\hypertarget{the-good-and-the-bad-of-late}{}
\begin{itemize}
\tightlist
\item
  You get a well-defined estimate even when there is non-random take-up
\item
  May sometimes be used to assess mediation or knock-on effects
\item
  But:

  \begin{itemize}
  \tightlist
  \item
    You need assumptions (monotonicity and the exclusion restriction --
    \emph{where were these used above}?)
  \item
    Your estimate is only for a subpopulation
  \item
    The subpopulation is not chosen by you and is unknown
  \item
    Different encouragements may yield different estimates since they
    may encourage different subgroups
  \end{itemize}
\end{itemize}
\end{frame}

\hypertarget{spillovers}{%
\subsection{\texorpdfstring{Spillovers\label{SUTVA}}{Spillovers}}\label{spillovers}}

\begin{frame}{SUTVA violations (Spillovers)}
\protect\hypertarget{sutva-violations-spillovers}{}
\scriptsize Spillovers can result in the estimation of weaker effects
when effects are actually stronger.

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-517-1.pdf}

\scriptsize The key problem is that \(Y(1)\) and \(Y(0)\) are not
sufficient to describe potential outcomes
\end{frame}

\begin{frame}{SUTVA violations}
\protect\hypertarget{sutva-violations}{}
More completely specified potential outcomes (and estimands)

\begin{table}
\scriptsize
\begin{center}
\tiny
\begin{tabular}{cc|cc|cc|cc|cc|cc}
     & & \multicolumn{2}{c}{0} & \multicolumn{2}{c}{1} & \multicolumn{2}{c}{2}  & \multicolumn{2}{c}{3}& \multicolumn{2}{c}{4}\\ \hline 
    Unit    &   Location&   $D_\emptyset$ & $y(D_\emptyset)$ & $D_1$        & $y(D_1)$  &  $D_2$        & $y(D_2)$   &$D_3$     & $y(D_3)$    &$D_4$        & $y(D_4)$    \\
    \hline
    A&  1 & 0 & 0 & 1 &3 &0 &1 & 0 & 0 &0 &0\\
    B & 2 & 0 & 0 & 0 &3 &1 &3 & 0 & 3 &0 &0\\
    C & 3 & 0 & 0 & 0 &0 &0 &3 & 1 & 3 &0 &3\\
    D & 4 & 0 & 0 & 0 &0 &0 &0 & 0 & 1 &1 &3\\
    \hline\hline
\multicolumn{2}{l|}{$\bar{y}_\text{treated}$} && - && 3 && 3 && 3 && 3  \\ 
\multicolumn{2}{l|}{$\bar{y}_\text{untreated}$} && 0 && 1 && 4/3 && 4/3 && 1  \\ 
\multicolumn{2}{l|}{$\bar{y}_\text{neighbors}$} && - && 3 && 2 && 2 && 3  \\ 
\multicolumn{2}{l|}{$\bar{y}_\text{pure control}$} && 0 && 0 && 0 && 0 && 0  \\ 
\hline
\multicolumn{2}{l|}{ATT (direct effect)} && - && 3 && 3 && 3  && 3 \\ 
\multicolumn{2}{l|}{ATT (indirect effect)} && - && 3 && 2 && 2 && 3  \\ 

    \hline
    \end{tabular}
    \end{center}

    \caption{Potential outcomes for four units for different treatment profiles, $D_1$-$D_4$. $D_i$ represents an allocation to treatment and $y_j(D_i)$ is the potential outcome for (row) unit $j$ given (column) allocation $i$.}
\label{PotentialOutcomes112}

\end{table}
\end{frame}

\begin{frame}{SUTVA violations}
\protect\hypertarget{sutva-violations-1}{}
\begin{table}
\scriptsize
    \begin{center}
    \tiny
    \begin{tabular}{cc|cc|cc|cc|cc|cc}
     & & \multicolumn{2}{c}{0} & \multicolumn{2}{c}{1} & \multicolumn{2}{c}{2}  & \multicolumn{2}{c}{3}& \multicolumn{2}{c}{4}\\ \hline 
    Unit    &   Location&   $D_\emptyset$ & $y(D_\emptyset)$ & $D_1$        & $y(D_1)$  &  $D_2$        & $y(D_2)$   &$D_3$     & $y(D_3)$    &$D_4$        & $y(D_4)$    \\
    \hline
    A   &   1 & 0 & 0   & 1 &3 &0 &1 & 0 & 0 &0 &0\\
    B & 2 & 0 & 0 & 0 &3 &1 &3 & 0 & 3 &0 &0\\
    C & 3 & 0 & 0 & 0 &0 &0 &3 & 1 & 3 &0 &3\\
    D & 4 & 0 & 0 & 0 &0 &0 &0 & 0 & 1 &1 &3\\
    \end{tabular}
    \end{center}    \scriptsize
    \caption{Potential outcomes for four units for different treatment profiles, $D_1$-$D_4$. $D_i$ represents an allocation to treatment and $y_j(D_i)$ is the potential outcome for (row) unit $j$ given (column) allocation $i$.} 
    \label{PotentialOutcomes51}
\end{table}

\begin{itemize}
\tightlist
\item
  The key is to think through the structure of spillovers.
\item
  Here immediate neighbors are exposed
\item
  In this case we can \textbf{define a direct treatment} (being exposed)
  and \textbf{an indirect treatment} (having a neighbor exposed) and we
  can work out
  \textit{the \textbf{propensity} for each unit of receiving each type of treatment}\\
\item
  These may be non uniform (here central types are more likely to have
  teated neighbors); but we can still use the randomization to assess
  effects
\end{itemize}

\textbf{Idea}: You can use the design to get a handle on spillovers
\end{frame}

\begin{frame}{SUTVA violations}
\protect\hypertarget{sutva-violations-2}{}
Even still, to estimate effects you need some SUTVA like assumption.

\includegraphics[width=22.92in,height=\textheight]{figs/neelan.png}

But NB: Estimates of treatment effects are sensitive to assumptions of
spillover structures. In this example if one compared the outcome
between treated units and all control units that are at least \(n\)
positions away from a treated unit you will get the wrong answer unless
\(n \geq 7\).
\end{frame}

\hypertarget{mediation}{%
\subsection{\texorpdfstring{Mediation\label{mediation}}{Mediation}}\label{mediation}}

\begin{frame}{The problem of unidentified mediators}
\protect\hypertarget{the-problem-of-unidentified-mediators}{}
\begin{itemize}
\tightlist
\item
  Consider a causal system like the below.
\item
  The effect of X on M1 and M2 can be measured in the usual way.
\item
  But unfortunately, if there are multiple mediators, the effect of M1
  (or M2) on Y is not identified.
\item
  The `exclusion restriction' is obviously violated when there are
  multiple mediators (unless you can account for them all).
\end{itemize}

\includegraphics[width=1.49in,height=\textheight]{figs/med1.png}
\end{frame}

\begin{frame}{The problem of unidentified mediators}
\protect\hypertarget{the-problem-of-unidentified-mediators-1}{}
\footnotesize * An obvious approach is to first examine the (average)
effect of X on M1 and then use another manipulation to examine the
(average) effect of M1 on Y. * But
\textbf{both of these average effects may be positive (for example) even if there is no effect of X on Y through M1}.\\
\textbackslash end\{itemize\}

\includegraphics[width=1.6in,height=\textheight]{figs/med2.png}
\end{frame}

\begin{frame}{The problem of unidentified mediators}
\protect\hypertarget{the-problem-of-unidentified-mediators-2}{}
\footnotesize * An obvious approach is to first examine the (average)
effect of X on M1 and then use another manipulation to examine the
(average) effect of M1 on Y. * Similarly
\textbf{both of these average effects may be zero even if X affects on Y through M1 for every unit!}.\\
\textbackslash end\{itemize\}

\includegraphics[width=1.6in,height=\textheight]{figs/med2.png}
\end{frame}

\begin{frame}{The problem of unidentified mediators}
\protect\hypertarget{the-problem-of-unidentified-mediators-3}{}
\footnotesize * Another somewhat obvious approach is see how the effect
of \(X\) on \(Y\) in a regression is reduced when you control for \(M\).
If the effect of \(X\) on \(Y\) passes through \(M\) then surely there
should be no effect of \(X\) on \(Y\) after you control for \(M\). * But
this common strategy is also not guaranteed to produce reliable
results\\
* See \href{http://imai.princeton.edu/projects/mechanisms.html}{Imai} on
better ways to think about this problem and designs to address it\\
\textbackslash end\{itemize\}
\end{frame}

\begin{frame}{The problem of unidentified mediators: Quantities}
\protect\hypertarget{the-problem-of-unidentified-mediators-quantities}{}
\begin{itemize}
\tightlist
\item
  In the potential outcomes framework we can describe a
  \textbf{mediation effect} as (see Imai et al):
  \[\delta_i(t) = Y_i(t, M_i(1)) - Y_i(t, M_i(0)) \textbf{ for } t = 0,1\]
\item
  The \textbf{direct effect} is:
  \[\psi_i(t) = Y_i(1, M_i(t)) - Y_i(0, M_i(t)) \textbf{ for } t = 0,1\]
\item
  This is a \textbf{decomposition}, since:
  \[Y_i(1, M_i(1))  - Y_1(0, M_i(0)) = \frac{1}{2}(\delta_i(1) + \delta_i(0) + \psi_i(1) + \psi_i(0))  \]
\item
  If (and a big if), there are no interaction effects---ie
  \(\delta_i(1) = \delta_i(0), \psi_i(1) = \psi_i(0)\), then
  \[Y_i(1, M_i(1))  - Y_1(0, M_i(0)) = \delta_i  + \psi_i\]
\item
  The bad news is that although a single experiment might identify the
  total effect, it can not identify these elements of the direct effect.
\end{itemize}
\end{frame}

\begin{frame}{The problem of unidentified mediators: Solutions?}
\protect\hypertarget{the-problem-of-unidentified-mediators-solutions}{}
\begin{itemize}
\tightlist
\item
  Check \textbf{formal requirement} for identification under single
  experiment design (``sequential ignorability''---that, conditional on
  actual treatment, it is as if the value of the mediation variable is
  randomly assigned relative to potential outcomes). But this is strong
  (and in fact unverifiable) and if it does not hold, bounds on effects
  always include zero (Imai et al)
\item
  You can use \textbf{interactions} with covariates \textbf{if you are
  willing to make assumptions on no heterogeneity of direct treatment
  effects} over covariates. eg you think that money makes people get to
  work faster because they can buy better cars; you look at the marginal
  effect of more money on time to work for people with and without cars
  and find it higher for the latter. This might imply mediation through
  transport but only if there is no direct effect heterogeneity (eg
  people with cars are less motivated by money).
\end{itemize}
\end{frame}

\begin{frame}{The problem of unidentified mediators: Solutions?}
\protect\hypertarget{the-problem-of-unidentified-mediators-solutions-1}{}
\begin{itemize}
\tightlist
\item
  Weaker assumptions justify \textbf{parallel design}

  \begin{itemize}
  \tightlist
  \item
    Group A: \(T\) is randomly assigned, \(M\) left free.
  \item
    Group B: divided into four groups \(T\times M\) (requires two more
    assumptions (1) that the \textbf{manipulation} of the mediator only
    affects outcomes through the mediator (2) \textbf{no interaction},
    for each unit, \(Y(1,m)-Y(0,m) = Y(1,m')-Y(0,m')\).)
  \end{itemize}
\end{itemize}

\textbf{Idea 5}: Understanding mechanisms is harder than you think.
Figure out what assumptions fly.
\end{frame}

\hypertarget{differences-in-differences}{%
\subsection{Differences in
differences}\label{differences-in-differences}}

\begin{frame}{Differences in differences}
New challenges, new developments
\end{frame}

\hypertarget{regression-discontintuity}{%
\subsection{Regression discontintuity}\label{regression-discontintuity}}

\begin{frame}{Regression discontintuity}
Errors and diagnostics
\end{frame}

\hypertarget{openscience}{%
\section{Experimentation: Processes and Workflows}\label{openscience}}

\begin{frame}{Experimentation: Processes and Workflows}
\begin{itemize}
\tightlist
\item
  Scope for experimentation
\item
  Ethics of experiments
\item
  Open science workflows
\end{itemize}
\end{frame}

\hypertarget{when-to-experiment}{%
\subsection{\texorpdfstring{When to experiment
\label{L_prospects}}{When to experiment }}\label{when-to-experiment}}

\begin{frame}{Prospects}
\protect\hypertarget{prospects}{}
\begin{itemize}
\tightlist
\item
  Whenever someone is uncertain about \emph{something} they are doing
  (all the time)
\item
  Whenever someone hits scarcity constraints
\item
  When people have incentives to demonstrate that they are doing the
  right thing (careful\ldots)
\end{itemize}
\end{frame}

\begin{frame}{Prospects}
\protect\hypertarget{prospects-1}{}
\begin{itemize}
\tightlist
\item
  \textbf{Advice}: If you can, \textbf{start from theory} and find an
  intervention, rather than the other way around.
\item
  \textbf{Advice}: If you can, go for \emph{structure} rather than
  \emph{gimmicks}
\item
  \textbf{Advice}: In attempts to parse, beware of generating unnatural
  interventions (how should a voter think of a politician that describes
  his policy towards Korea in detail but does not mention the economy?
  Is not mentioning the economy sending an unintended message?)
\end{itemize}
\end{frame}

\begin{frame}{Prospects \& Potential}
\protect\hypertarget{prospects-potential}{}
\begin{itemize}
\tightlist
\item
  Randomization of where police are stationed (India)
\item
  Randomization of how government tax collectors get paid (do they get a
  share?) (Pakistan)
\item
  Randomization of the voting rules for determining how decisions get
  made (Afghanistan)
\item
  Random assignment of populations to peacekeepers (Liberia)
\item
  Random assignment of ex-combatants out of their networks (Indonesia)
\item
  Randomization of students to ethnically homogeneous or ethnically
  diverse schools (anywhere?)
\end{itemize}
\end{frame}

\hypertarget{ethics}{%
\subsection{\texorpdfstring{Ethics
\label{ethics}}{Ethics }}\label{ethics}}

\begin{frame}{Constraint: Is it ethical to manipulate subjects for
research purposes?}
\protect\hypertarget{constraint-is-it-ethical-to-manipulate-subjects-for-research-purposes}{}
\begin{itemize}
\item
  There is no foundationless answer to this question. So let's take some
  foundations from the Belmont report and seek to ensure:

  \begin{enumerate}
  \tightlist
  \item
    Respect for persons
  \item
    Beneficence
  \item
    Justice
  \end{enumerate}
\item
  Unfortunately, operationalizing these requires further ethical
  theories. Let's assume that (1) is operationalized by informed consent
  (a very liberal idea). We are a bit at sea for (2) and (3) (the
  Belmont report suggests something like a utilitarian solution).
\item
  The major focus on (1) by IRBs might follow from the view that if
  subjects consent, then they endorse the ethical calculations made for
  2 and 3 --- \emph{they} think that it is good and fair.
\item
  This is a little tricky, though, since the study may not be good or
  fair because of implications for non-subjects.
\end{itemize}
\end{frame}

\begin{frame}{Is it ethical to manipulate subjects for research
purposes?}
\protect\hypertarget{is-it-ethical-to-manipulate-subjects-for-research-purposes}{}
\begin{itemize}
\item
  The problem is that many (many) field experiments have nothing like
  informed consent.
\item
  For example, whether the government builds a school in your village,
  whether an ad appears on your favorite radio show, and so on.
\item
  Consider three cases:

  \begin{enumerate}
  \tightlist
  \item
    You work with a nonprofit to post (true?) posters about the crimes
    of politicians on billboards to see effects on \textbf{voters}
  \item
    You hire confederates to offer bribes to \textbf{police officers} to
    see if they are more likely to bend the law for coethnics
  \item
    The British government asks you to work on figuring out how the use
    of water cannons helps stop \textbf{rioters} rioting
  \end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}{Is it ethical to manipulate subjects for research
purposes?}
\protect\hypertarget{is-it-ethical-to-manipulate-subjects-for-research-purposes-1}{}
\begin{itemize}
\item
  Consider three cases:

  \begin{itemize}
  \tightlist
  \item
    You work with a nonprofit to post (true?) posters about the crimes
    of politicians on billboards to see effects on \textbf{voters}
  \item
    You hire confederates to offer bribes to \textbf{police officers} to
    see if they are more likely to bend the law for coethnics
  \item
    The British government asks you to work on figuring out how the use
    of water cannons helps stop \textbf{rioters} rioting
  \end{itemize}
\item
  In all cases, there is \textbf{no consent} given by subjects.
\item
  In 2 and 3, the treatment is \textbf{possibly harmful} for subjects,
  and the results might also be harmful. But even in case 1, there could
  be major unintended harmful consequences.
\item
  In cases 1 and 3, however, the ``intervention'' is within the sphere
  of \textbf{normal activities} for the implementer.
\end{itemize}
\end{frame}

\begin{frame}{Constraint: Is it ethical to manipulate subjects for
research purposes?}
\protect\hypertarget{constraint-is-it-ethical-to-manipulate-subjects-for-research-purposes-1}{}
\begin{itemize}
\item
  Sometimes it is possible to use this point of difference to make a
  ``spheres of ethics'' argument for ``embedded experimentation.''
\item
  \textbf{Spheres of Ethics Argument}: Experimental research that
  involves manipulations that are not normally appropriate for
  researchers may nevertheless be ethical if:

  \begin{itemize}
  \tightlist
  \item
    Researchers and implementers agree on a \textbf{division of
    responsibility} where implementers take on responsibility for
    actions
  \item
    Implementers have \textbf{legitimacy} to make these decisions within
    the sphere of the intervention
  \item
    Implementers are indeed \textbf{materially independent} of
    researchers (no swapping hats)
  \end{itemize}
\item
  Difficulty with this argument:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Question begging}: How to determine the legitimacy of the
    implementer? (Can we rule out Nazi doctors?)
  \end{itemize}
\end{itemize}

Otherwise keep focus on consent and desist if this is not possible
\end{frame}

\hypertarget{transparency-experimentation}{%
\subsection{\texorpdfstring{Transparency \& Experimentation
\label{registeration}}{Transparency \& Experimentation }}\label{transparency-experimentation}}

\begin{frame}{Contentious Issues}
\protect\hypertarget{contentious-issues}{}
Experimental researchers are deeply engaged in the movement towards more
transparency social science research.

Contentious issues (mostly):

\begin{itemize}
\tightlist
\item
  \textbf{Analytic replication.} This should be a no brainer. Set
  everything up so that replication is easy. Use rmarkdown, or knitr or
  sweave. Or produce your replication code as a package.
\end{itemize}
\end{frame}

\begin{frame}{Contentious Issues}
\protect\hypertarget{contentious-issues-1}{}
Experimental researchers are deeply engaged in the movement towards more
transparency social science research.

Contentious issues (mostly):

\begin{itemize}
\item
  \textbf{Data.} How soon should you make your data available?
  \textbf{My view}: as soon as possibe. Along with working papers and
  before publication. Before it affects policy in any case. Own the
  ideas not the data.

  \begin{itemize}
  \tightlist
  \item
    Hard core: no citation without (analytic) replication. Perhaps.
    Non-replicable results should not be influencing policy.
  \end{itemize}
\item
  \textbf{Where should you make your data available?} Dataverse is focal
  for political science. Not personal website (mea culpa)
\item
  \textbf{What data should you make available?} Disagreement is over how
  raw your data should be. \textbf{My view}: as raw as you can but at
  least post cleaning and pre-manipulation.
\end{itemize}
\end{frame}

\begin{frame}{Contentious Issues}
\protect\hypertarget{contentious-issues-2}{}
Experimental researchers are deeply engaged in the movement towards more
transparency social science research.

Contentious issues (mostly):

\begin{itemize}
\item
  \textbf{Should you register?}: Hard to find reasons against. But case
  strongest in testing phase rather than exploratory phase.
\item
  \textbf{Registration}: When should you register? \textbf{My view:}
  Before treatment assignment. (Not just before analysis, mea culpa)
\item
  \textbf{Registration}: Should you deviate from an preanalysis plan if
  you change your mind about optimal estimation strategies. \textbf{My
  view:} Yes, but make the case and describe both sets of results.
\end{itemize}
\end{frame}

\begin{frame}{Contentious Issues}
\protect\hypertarget{contentious-issues-3}{}
Experimental researchers are deeply engaged in the movement towards more
transparency social science research.

Contentious issues (mostly):

\begin{itemize}
\item
  \textbf{Registration}: When should you register? \textbf{My view:}
  Before treatment assignment. (Not just before analysis, mea culpa)
\item
  \textbf{Registration}: Should you deviate from an preanalysis plan if
  you change your mind about optimal estimation strategies. \textbf{My
  view:} Yes, but make the case and describe both sets of results.
\end{itemize}
\end{frame}

\hypertarget{pre-registration-rationales-and-structures}{%
\subsection{Pre-registration rationales and
structures}\label{pre-registration-rationales-and-structures}}

\begin{frame}{Two distinct rationales for registration}
\protect\hypertarget{two-distinct-rationales-for-registration}{}
\begin{itemize}
\item
  File drawer bias (Publication bias)
\item
  Analysis bias (Fishing)
\end{itemize}
\end{frame}

\begin{frame}{File drawer bias}
\protect\hypertarget{file-drawer-bias}{}
-- Say in truth \(X\) affects \(Y\) in 50\% of cases.

-- Researchers conduct multiple excellent studies. But they only write
up the 50\% that produce ``positive'' results.

-- Even if each individual study is indisputably correct, the account in
the research record -- that X affects Y in 100\% of cases -- will be
wrong.

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-533-1.pdf}
\end{frame}

\begin{frame}{File drawer bias}
\protect\hypertarget{file-drawer-bias-1}{}
-- Say in truth \(X\) affects \(Y\) in 50\% of cases.

-- Researchers conduct multiple excellent studies. But they only write
up the 50\% that produce ``positive'' results.

-- Even if each individual study is indisputably correct, the account in
the research record -- that X affects Y in 100\% of cases -- will be
wrong.

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-534-1.pdf}
\end{frame}

\begin{frame}{File drawer bias}
\protect\hypertarget{file-drawer-bias-2}{}
Exacerbated by:

-- Publication bias -- the positive results get published

-- Citation bias -- the positive results get read and cited

-- Chatter bias -- the positive results gets blogged, tweeted and TEDed.
\end{frame}

\begin{frame}{Analysis bias (Fishing)}
\protect\hypertarget{analysis-bias-fishing}{}
-- Say in truth \(X\) affects \(Y\) in 50\% of cases.

-- But say that researchers enjoy discretion to select measures for
\(X\) or \(Y\), or enjoy discretion to select statistical models after
seeing \(X\) and \(Y\) in each case.

-- Then, with enough discretion, 100\% of analyses may report positive
effects, even if all studies get published.

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-535-1.pdf}
\end{frame}

\begin{frame}{Analysis bias (Fishing)}
\protect\hypertarget{analysis-bias-fishing-1}{}
-- Say in truth \(X\) affects \(Y\) in 50\% of cases.

-- But say that researchers enjoy discretion to select measures for
\(X\) or \(Y\), or enjoy discretion to select statistical models after
seeing \(X\) and \(Y\) in each case.

-- Then, with enough discretion, 100\% of analyses may report positive
effects, even if all studies get published.

\includegraphics{0_lectures_files/figure-beamer/unnamed-chunk-536-1.pdf}
\end{frame}

\begin{frame}{Analysis bias (Fishing)}
\protect\hypertarget{analysis-bias-fishing-2}{}
-- Try the exact fishy test
\href{https://macartan.shinyapps.io/fish/}{An Exact Fishy Test
(https://macartan.shinyapps.io/fish/)}

-- What's the problem with this test?
\end{frame}

\begin{frame}{Evidence-Proofing: Illustration}
\protect\hypertarget{evidence-proofing-illustration}{}
\begin{itemize}
\item
  When your conclusions do not really depend on the data
\item
  Eg -- some evidence will always support your proposition -- some
  interpretation of evidence will always support your proposition
\item
  Knowing the mapping from data to inference in advance gives a handle
  on the false positive rate.
\end{itemize}
\end{frame}

\begin{frame}{Evidence Proofing: Bayesian Illustration}
\protect\hypertarget{evidence-proofing-bayesian-illustration}{}
\begin{itemize}
\tightlist
\item
  Say choice of two pieces of evidence to bring to bear, \(K1\) or
  \(K2\)
\end{itemize}

\begin{table}

\caption{Likelihoods}\begin{minipage}[t]{0.50\linewidth}
\subcaption{\label{tbl-anonymous-96063-1}}

{\centering 

\caption{If TRUE }\tabularnewline

\centering
\begin{tabular}{>{}c|c|c|c}
\hline
 & \$K\_1\$ = No & \$K\_1\$ = Yes & All\\
\hline
\textbf{\$K\_2\$ = No} & 0.9 & 0.05 & 0.95\\
\hline
\textbf{\$K\_2\$ = Yes} & 0.05 & 0 & 0.05\\
\hline
\textbf{All} & 0.95 & 0.05 & 1\\
\hline
\end{tabular}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}
\subcaption{\label{tbl-anonymous-96063-2}}

{\centering 

\caption{If FALSE }\tabularnewline

\centering
\begin{tabular}{>{}c|c|c|c}
\hline
 & \$K\_1\$ = No & \$K\_1\$ = Yes & All\\
\hline
\textbf{\$K\_2\$ = No} & 0 & 0.05 & 0.05\\
\hline
\textbf{\$K\_2\$ = Yes} & 0.05 & 0.9 & 0.95\\
\hline
\textbf{All} & 0.05 & 0.95 & 1\\
\hline
\end{tabular}

}

\end{minipage}%

\end{table}

\begin{itemize}
\tightlist
\item
  Posterior \textbar{} K1 = Posterior \textbar{} K2 = 95\%
\item
  Probability positive claim \textbar{} H is false; evidence randomly
  selected (p) = 5\%
\item
  Probability positive claim \textbar{} H is false; evidence is fished
  (p) = 10\%
\end{itemize}
\end{frame}

\begin{frame}{Evidence Proofing: Bayesian Illustration}
\protect\hypertarget{evidence-proofing-bayesian-illustration-1}{}
\begin{itemize}
\tightlist
\item
  Say choice of two pieces of evidence to bring to bear, \(K1\) or
  \(K2\)
\end{itemize}

\begin{table}

\caption{Likelihoods}\begin{minipage}[t]{0.50\linewidth}
\subcaption{\label{tbl-anonymous-5905318-1}}

{\centering 

\caption{If TRUE }\tabularnewline

\centering
\begin{tabular}{>{}c|c|c|c}
\hline
 & \$K\_1\$ = No & \$K\_1\$ = Yes & All\\
\hline
\textbf{\$K\_2\$ = No} & 0.9 & 0.05 & 0.95\\
\hline
\textbf{\$K\_2\$ = Yes} & 0.05 & 0 & 0.05\\
\hline
\textbf{All} & 0.95 & 0.05 & 1\\
\hline
\end{tabular}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}
\subcaption{\label{tbl-anonymous-5905318-2}}

{\centering 

\caption{If FALSE }\tabularnewline

\centering
\begin{tabular}{>{}c|c|c|c}
\hline
 & \$K\_1\$ = No & \$K\_1\$ = Yes & All\\
\hline
\textbf{\$K\_2\$ = No} & 0 & 0.05 & 0.05\\
\hline
\textbf{\$K\_2\$ = Yes} & 0.05 & 0.9 & 0.95\\
\hline
\textbf{All} & 0.05 & 0.95 & 1\\
\hline
\end{tabular}

}

\end{minipage}%

\end{table}

\begin{itemize}
\tightlist
\item
  What's the truly correct inference if you KNOW that researcher is a
  fisher?
\item
  Depends: say you thought K1 and K2 were sought in order. Then if K2
  evidence is presented this means K1 not found. So posterior
  \textbar K2 only = 50\%.
\end{itemize}
\end{frame}

\begin{frame}{The scope for fishing}
\protect\hypertarget{the-scope-for-fishing}{}
\includegraphics[width=6.98in,height=\textheight]{assets/fishing.png}
\end{frame}

\begin{frame}{Evidence from political science}
\protect\hypertarget{evidence-from-political-science}{}
\includegraphics[width=2.82in,height=\textheight]{assets/hack.png}

Source: Gerber and Malhotra
\end{frame}

\begin{frame}{More evidence from TESS}
\protect\hypertarget{more-evidence-from-tess}{}
\begin{itemize}
\tightlist
\item
  Malhotra tracked 221 TESS studies.
\item
  20\% of the null studies were published. 65\% not even written up
  (file drawer or anticipation of publication bias)
\item
  60\% of studies with strong results were published.
\end{itemize}

Implications are:

\begin{itemize}
\tightlist
\item
  population of results not representative
\item
  (subtler) individual published studies are also more likely to be
  overestimates
\end{itemize}
\end{frame}

\begin{frame}{The problem}
\protect\hypertarget{the-problem}{}
\begin{itemize}
\item
  Summary: we do not know when we can or cannot trust claims made by
  researchers.
\item
  {[}Not a tradition specific claim{]}
\end{itemize}
\end{frame}

\begin{frame}{Registration as a possible solution}
\protect\hypertarget{registration-as-a-possible-solution}{}
Simple idea:

-- It's about communication: -- just say what you are planning on doing
before you do it -- if you don't have a plan, say that -- If you do
things differently from what you were planning to do, say that

Bells and whistles

-- To be really useful a registry would have to have some credibility,
some searchability, and some consistency in fields.
\end{frame}

\begin{frame}{Registration as a possible solution}
\protect\hypertarget{registration-as-a-possible-solution-1}{}
Elements:

\begin{itemize}
\item
  Make it a facility
\item
  Non-mandatory
\item
  Non-binding
\item
  But comprehensive
\item
  Report whether registered or not
\item
  Report changes in plans
\end{itemize}
\end{frame}

\begin{frame}{What's the Right Scope:}
\protect\hypertarget{whats-the-right-scope}{}
For discussion: but claims of ``tests'' seem like a good start
\end{frame}

\begin{frame}{Bells and Whistles: Certificaton?}
\protect\hypertarget{bells-and-whistles-certificaton}{}
Center for Open Science Badges

\begin{itemize}
\tightlist
\item
  A public date-time stamped registration is in an institutional
  registration system (e.g., ClinicalTrials.gov, Open Science Framework)
\item
  Registration pre-dates realization of the outcomes
\item
  Registered design and analysis plan corresponds directly to reported
  design and analysis
\item
  Full disclosure of results following the registered plan
\end{itemize}

Notations PR (peer review certified), DE (data exist), and TC
(transparent changes)

\includegraphics[width=0.8in,height=\textheight]{assets/badge.png}

\begin{itemize}
\tightlist
\item
  https://osf.io/tvyxz/wiki/1.\%20View\%20the\%20Badges/
\end{itemize}
\end{frame}

\begin{frame}{Bells and Whistles: Certificaton?}
\protect\hypertarget{bells-and-whistles-certificaton-1}{}
Center for Open Science Badges

\begin{itemize}
\tightlist
\item
  Requires validating body (eg journal or registry)
\item
  Validation on process not on quality
\item
  Emphasis on transparency
\end{itemize}
\end{frame}

\begin{frame}{Possible Cycle}
\protect\hypertarget{possible-cycle}{}
\includegraphics[width=3.18in,height=\textheight]{assets/cycle.png}
\end{frame}

\begin{frame}{Possible Models}
\protect\hypertarget{possible-models}{}
\begin{itemize}
\tightlist
\item
  Journal-led model: let the registry follow
\end{itemize}

-- Hard form -- Medical sciences for RCTs -- Soft form -- Medical
sciences for observational studies

\begin{itemize}
\tightlist
\item
  Professional Association led model
\end{itemize}

-- AEA for RCTs -- APSA?

\begin{itemize}
\item
  Funder led model (more mandatory) -- RIDIE, NSF?
\item
  Bottom up model? -- Eg established by APSA sections; CQRM, PolMeth,
  Experiments? No formal journal recognition.
\end{itemize}

But even the simple idea is not everywhere welcome. There are many
worries and some myths.
\end{frame}

\hypertarget{worries-and-myths-around-registration}{%
\subsection{Worries and Myths around
registration}\label{worries-and-myths-around-registration}}

\begin{frame}{Myth: Concerns about fishing presuppose researcher
dishonesty}
\protect\hypertarget{myth-concerns-about-fishing-presuppose-researcher-dishonesty}{}
\begin{itemize}
\item
  Fishing can happen in very subtle ways, and may seem natural and
  justifiable.
\item
  Example:
\end{itemize}

-- I am interested in whether more democratic institutions result in
better educational outcomes. -- I examine the relationship between
institutions and literacy and between institutions and school
attendance. -- The attendance measure is significant and the literacy
one is not. Puzzled, I look more carefully at the literacy measure and
see various outliers and indications of measurement error. As I think
more I realize too that literacy is a slow moving variable and may not
be the best measure anyhow. I move forward and start to analyze the
attendance measure only, perhaps conducting new tests, albeit with the
same data.
\end{frame}

\begin{frame}{Structural challenge}
\protect\hypertarget{structural-challenge}{}
Our journal review process is largely organized around advising
researchers how to adjust analysis in light of findings in the data.
\end{frame}

\begin{frame}{Myth: Fishing is technique specific}
\protect\hypertarget{myth-fishing-is-technique-specific}{}
\begin{itemize}
\item
  Frequentists can do it
\item
  Bayesians can do it too.
\item
  Qualitative researchers can also do it.
\item
  You can even do it with descriptive statistics
\end{itemize}
\end{frame}

\begin{frame}{Myth: Fishing is estimand specific}
\protect\hypertarget{myth-fishing-is-estimand-specific}{}
\begin{itemize}
\tightlist
\item
  You can do it when estimating causal effects
\item
  You can do it when studying mechanisms
\item
  You can do it when estimating counts
\end{itemize}
\end{frame}

\begin{frame}{Myth: Registration only makes sense for experimental
studies, not for observational studies}
\protect\hypertarget{myth-registration-only-makes-sense-for-experimental-studies-not-for-observational-studies}{}
\begin{itemize}
\item
  The key distinction is between prospective and retrospective studies.
\item
  Not between experimental and observational studies.
\item
  A reason (from the medical literature) why registration is especially
  important for experiments: because you owe it to subjects
\item
  A reason why registration is less important for experiments: because
  it is more likely that the intended analysis is implied by the design
  in an experimental study. Researcher degrees of freedom may be
  greatest for observational qualitative analyses.
\end{itemize}
\end{frame}

\begin{frame}{Worry: Registration will create administrative burdens for
researchers, reviewers, and journals}
\protect\hypertarget{worry-registration-will-create-administrative-burdens-for-researchers-reviewers-and-journals}{}
\begin{itemize}
\tightlist
\item
  Registration will produce some burden but does not require the
  creation of content that is not needed anyway
\end{itemize}

-- It does shift preparation of analyses forward -- And it also can
increase the burden of developing analyses plans even for projects that
don't work. But that is in part, the point.

\begin{itemize}
\tightlist
\item
  Upside is that ultimate analyses may be much easier.
\end{itemize}
\end{frame}

\begin{frame}{Worry: Registration will force people to implement
analyses that they know are wrong}
\protect\hypertarget{worry-registration-will-force-people-to-implement-analyses-that-they-know-are-wrong}{}
\begin{itemize}
\tightlist
\item
  Most arguments for registration in social science advocate for
  non-binding registration, where deviations from designs are possible,
  though they should be described.
\item
  Even if it does not prevent them, a merit of registration is that it
  makes deviations visible.
\end{itemize}
\end{frame}

\begin{frame}{Myth: Replication (or other transparency practices)
obviates the need for registration}
\protect\hypertarget{myth-replication-or-other-transparency-practices-obviates-the-need-for-registration}{}
\begin{itemize}
\tightlist
\item
  There are lots of good things to do, including replication.
\item
  Many of these do not substitute for each other. (How to interpret a
  fished replication of a fished analysis?)
\item
  And they may likely act as complements
\item
  Registration can clarify details of design and analysis and ensure
  early preparation of material. Indeed material needed for replication
  may be available even before data collection
\end{itemize}
\end{frame}

\begin{frame}{Worry: Registration will put researchers at risk of
scooping}
\protect\hypertarget{worry-registration-will-put-researchers-at-risk-of-scooping}{}
\begin{itemize}
\tightlist
\item
  But existing registries allow people to protect registered designs for
  some period
\item
  Registration may let researchers lay claim to a design
\end{itemize}
\end{frame}

\begin{frame}{Worry: Registration will kill creativity}
\protect\hypertarget{worry-registration-will-kill-creativity}{}
\begin{itemize}
\tightlist
\item
  This is an empirical question. However, under a nonmandatory system
  researchers could:
\item
  Register a plan for structured exploratory analysis
\item
  Decide that exploration is at a sufficiently early stage that no
  substantive registration is possible and proceed without registration.
\end{itemize}
\end{frame}

\begin{frame}{Implications:}
\protect\hypertarget{implications}{}
\begin{itemize}
\item
  In neither case would the creation of a registration facility prevent
  exploration.
\item
  What it might do is make it less credible for someone to claim that
  they have tested a proposition when in fact the proposition was
  developed using the data used to test it.
\item
  Registration communicates when researchers are angage in exploration
  or not. We love exploration and should be proud of it.
\end{itemize}
\end{frame}

\begin{frame}{The challenge of historical data}
\protect\hypertarget{the-challenge-of-historical-data}{}
\begin{itemize}
\item
  Does registering analyses of historical data make sense?
\item
  The problem is not just that researchers might have already seen the
  testing data; but that they have seen data that is correlated with it.
\end{itemize}
\end{frame}

\begin{frame}{Historical data: Illustration}
\protect\hypertarget{historical-data-illustration}{}
\begin{itemize}
\item
  Consider historical proposition H. -- Say we start with a prior of .5
  that H is true. -- Say that if H is true then we observe K1 with
  probability 0.8 but if it is false we observe K1 with probability 0.2
  (``double decisiveness'') -- Similarly if H is true then we observe K2
  with probability 0.8 but if it is false we observe K2 with probability
  0.2 (``double decisiveness'' again)
\item
  Say we observe K1 (some collection of facts)
\item
  We then update our belief in H\ldots{}
\end{itemize}
\end{frame}

\begin{frame}{Historical data: Illustration}
\protect\hypertarget{historical-data-illustration-1}{}
\begin{itemize}
\item
  Our updated belief is:
  \[\Pr(H|K1) = \Pr(K1|H)\Pr(H)/\Pr(K1) = \frac{.8*.5}{.8*.5+.2*.5}  = 80\%\]
\item
  We are now 80\% confident in proposition H.
\item
  We decide to look for evidence K2. And we find it!
\item
  Our posterior is now:
  \[\Pr(H|K2) = \Pr(K2|H)\Pr(H)/\Pr(K2) =.8*.8/(.8*.8+.2*.2)  = 94\%\]
\item
  Or is it?
\end{itemize}
\end{frame}

\begin{frame}{Historical data: Illustration}
\protect\hypertarget{historical-data-illustration-2}{}
\begin{itemize}
\tightlist
\item
  Our updated belief is:
\end{itemize}

\[\Pr(H|K1) = \Pr(K1|H)\Pr(H)/\Pr(K1) = .8*.5/(.8*.5+.2*.5)  = 80\%\]

\begin{itemize}
\item
  We are now 80\% confident in proposition H.
\item
  We decide to look for evidence K2. And we find it!
\item
  Our posterior is now:
  \[Pr(H|K2) = Pr(K2|H)Pr(H)/Pr(K2) =.8*.8/(.8*.8+.2*.2)  = 94%
  \]
\item
  Or is it?
\end{itemize}
\end{frame}

\begin{frame}{Historical data: Illustration}
\protect\hypertarget{historical-data-illustration-3}{}
\begin{itemize}
\item
  What if there are correlated probabilities?
\item
  Then
\end{itemize}

\[\Pr(H | K1 \& K2) = .76 \times .5/(.76 \times .5 + .16 \times .5) = 83\%\]
\end{frame}

\begin{frame}{Historical data: Illustration}
\protect\hypertarget{historical-data-illustration-4}{}
\begin{itemize}
\item
  In a sense the fishing has already happened.
\item
  How so?
\item
  Say the proposition is FALSE but K1 is still observed
\item
  A decision is then made to seek ``new data'' K2
\item
  Now K2 will be observed with 80\% probability even though H is false
\end{itemize}
\end{frame}

\begin{frame}{Historical data: Illustration}
\protect\hypertarget{historical-data-illustration-5}{}
\begin{itemize}
\item
  Naïve inference (using a prior of 80\% due to K1): 94\% if K2; 50\% if
  not K2
\item
  Inference if K1 used to decide on search for K2 but prior is ``reset''
  to .5 80\% if K2; 20\% if not K2
\item
  Sophisticated inference: 83\% if K2; 50\% if not K2
\item
  This sophisticated inference is unchanged if you take explicit account
  of the fact that searching for K2 was conditional on K1; either way it
  is still \(\Pr(H | K1, K2)\).
\item
  \emph{It requires assessing the probability of knowing what you know
  now and finding out what you will find, if the proposition is true or
  false.}
\end{itemize}
\end{frame}

\begin{frame}{Historical data: Illustration}
\protect\hypertarget{historical-data-illustration-6}{}
\begin{itemize}
\item
  Naïve inference (using a prior of 80\% due to K1): 94\% if K2; 50\% if
  not K2
\item
  Inference if K1 used to decide on search for K2 but prior is ``reset''
  to .5 80\% if K2; 20\% if not K2
\item
  Sophisticated inference: 83\% if K2; 50\% if not K2
\item
  This sophisticated inference is unchanged if you take explicit account
  of the fact that searching for K2 was conditional on K1; either way it
  is still Pr(H \textbar{} K1, K2).
\item
  \emph{Can such beliefs be elicited?} Perhaps.
\end{itemize}
\end{frame}

\begin{frame}{Will it make a difference?}
\protect\hypertarget{will-it-make-a-difference}{}
\begin{itemize}
\tightlist
\item
  Striking paucity of evidence.
\end{itemize}
\end{frame}

\begin{frame}{How to?}
\protect\hypertarget{how-to}{}
\begin{itemize}
\tightlist
\item
  Let's look at an example
\item
  Design declaration idea
\end{itemize}
\end{frame}

\hypertarget{reconciliation}{%
\subsection{Reconciliation}\label{reconciliation}}

\begin{frame}{Reconciliation}
Incentives and strategies
\end{frame}

\begin{frame}{Reconciliation}
\protect\hypertarget{reconciliation-1}{}
\includegraphics[width=2.45in,height=\textheight]{assets/reconciliation.png}
\end{frame}

\begin{frame}{Reconciliation}
\protect\hypertarget{reconciliation-2}{}
\end{frame}

\hypertarget{replication-files}{%
\subsection{Replication files}\label{replication-files}}



\end{document}
