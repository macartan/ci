---
format: 
   revealjs:
    embed-resources: true
    theme: serif
    slide-level: 3
    slide-number: true
    show-slide-number: all
    preview-links: auto
    number-sections: false
    code-fold: true
    code-summary: "Show the code"
    scrollable: true
title: "Group 4 Exercises"
author:
  - name: Philipp Heyna
    email: philipp.heyna@hu-berlin.de
  - name: Nader Hotait
    email: nader.hotait@hu-berlin.de
  - name: Daniel Kuhlen
    email: kuhlenda@hu-berlin.de
  - name: Robert Stelzle
    email: robert.martin.stelzle@student.hu-berlin.de
  - name: Yoanna Yankova
    email: yankovay@hu-berlin.de
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

```{r packages, echo=FALSE}
# packages
pacman::p_load(tidyverse,
               DeclareDesign,
               CausalQueries,
               knitr,
               kableExtra)
```

# Task 2.4

---

::: {.callout-note icon=false collapse="true"}

### Task 2.4

**Confounded**

Declare a design in which:

* The assignment of a  treatment $X$ depends in part on upon some other, binary, variable $W$: in particular  $\Pr(X=1|W=0) = .2$ and $\Pr(X=1|W=1) = .5$)
* The outcome $Y$ depends on both $X$ and $W$: in particular $Y = X*W + u$ where $u$ is a random shock.
* Diagnose a design with three approaches to estimating the effect of $X$ on $Y$: (a) ignoring $W$ (b) adding $W$ as a linear control (c) including both $W$  and an interaction between $W$ and $X$. 

Discuss results. Do any of these return the right answer?

**Hint:** You can add three separate `declare_estimator` steps. They should have distinct labels. The trickiest part is to figure out how to extract the estimate in (c) because you will have both a main term and an interaction term for $X$.

:::


### Discussion 2.4

```{r model_declaration_1, echo=TRUE}

set.seed(123)

declaration <- 
  declare_model(
    N = 1000, # Arbitrary population of 1000
    U = rnorm(N), # Assuming error term is random
    W = rbinom(N, 1, 0.5), +
    potential_outcomes(Y ~ Z * W + U)) + # Potential Outcomes as defined in task
  declare_inquiry(ATE = (mean(Y_Z_1 - Y_Z_0))) + 
  declare_assignment(Z = rbinom(N, 1, prob = ifelse(W == 1, 0.5, 0.2))) + # Assignment conditional on W 
  declare_measurement(Y = reveal_outcomes(Y ~ Z)) +
  declare_estimator(
    Y ~ Z, term = "Z", inquiry = "ATE", label = "a) Ignore W") +  # Ignoring W
  declare_estimator(
    Y ~ Z + W, term = "Z", inquiry = "ATE",label = "b) Control for W") + # Controlling for W
  declare_estimator(
    Y ~ Z + Z * W + W, term = "Z", inquiry = "ATE",label = "c) Interaction") # Interaction


### MODEL DIAGNOSIS

model_diagnosis <-
  diagnose_design(declaration,
                  sims = 500,
                  bootstrap_sims = 100)

reshape_diagnosis(model_diagnosis) %>%
  kable() %>%
  kableExtra::kable_styling(font_size = 15)
```

### Discussion 2.4
The role of $W$ is defined as a confounder since it serves as a parent variable influencing both the treatment assignment $X$ and the treatment outcome $Y$ (see @fig-confounding-dag). Failing to adjust for this confounder in the model can lead to biased estimations. Such a bias is conventionally referred to as "common cause confounding bias" or, in other words, a violation of the backdoor criterion. Therefore, it is crucial to incorporate $W$ into the model. Utilizing simulations through `DeclareDesign`, we gain insights into this specific phenomenon. From the simulation results, it is evident that the model which accounts for $W$ (*"Control for W"*) produces mean estimates that are considerably closer and less biased compared to the estimand than the model that neglects $W$ (*"Ignore W"*). Furthermore, both the coverage and RMSE metrics suggest that the estimates from the model accounting for the confounder are less erroneous compared to those from the model that disregards it.

### Discussion 2.4

```{r}
#| label: fig-confounding-dag
#| fig-cap: "$W$ as a common cause confounder of $X$ and $Y$"
#| echo: false
#| fig-width: 10
#| fig-height: 4

make_model("W -> X -> Y <- W") %>%
  plot(x_coord = c(1.5,1,2), y_coord = c(2,1,1))
```

# Task 3.4

---

::: {.callout-note icon=false collapse="true"}

### Task 3.4
* A set of units have outcome $Y^1_i$ at baseline.
* At endline they have potential outcomes $Y^2_i(0)$ and  $Y^2_i(1)$


1. Write down the estimand for the average effect of treatment on endline outcomes
2. Write down the estimand for the average effect of treatment on the change from baseline to endline for all units

Compare these and discuss.
:::


### Discussion

Assuming following:

1. $\text{ATE}_{\text{endline}} = \frac{1}{N} \sum_{i=1}^{N} \left( Y^2_i(1) - Y^2_i(0) \right)$
2. $\text{ATE}_{\text{change}} = \frac{1}{N} \sum_{i=1}^{N} \left( \left( Y^2_i(1) - Y^1_i \right) - \left( Y^2_i(0) - Y^1_i \right) \right)$

One can conclude that $\text{ATE}_{\text{endline}}$ approximates an estimator, which informs us about the average size of the treatment effect on a binary outcome. However, $\text{ATE}_{\text{change}}$ provides insight into the treatment effect as a comparison between conditions before and after treatment, indicating the effectiveness of the treatment relative to not being treated. Hence, the first scenario informs us about the strength of the treatment given the prevalence of positive outcomes, while the second scenario reveals the effectiveness of the treatment by considering the initial conditions of the treated units.

Assuming that $ATE = ATT$ and considering  $Y^{t=1}_i$ and $Y^{t=2}_i$ in this scenario, one could describe $\text{ATE}_{\text{endline}}$ as a between-estimator of treated units, and $\text{ATE}_{\text{change}}$ as an in-between estimation of treated units before and after treatment, effectively combining between- and within-unit estimations.

# Task 4.4

---

::: {.callout-note icon=false collapse="true"}

### Task 4.4

Imagine a model that looks like this:

```{r, echo = FALSE, fig.height = 3, fig.width = 10}
make_model("X -> M -> Y <-> X") |> plot(x_coord = 1:3, y_coord = c(1,1,1))
```

* Say that in truth  ATE of  $X$ on $M$ is .9 and that the ATE of  $M$ on $Y$ is .9. Is the implied effect of 0.81 on $X$ on $Y$ identified?   
* Say that in truth  ATE of  $X$ on $M$ is 1 and that the ATE of  $M$ on $Y$ is 1. Is the implied effect of 1 on $X$ on $Y$ identified?   
* Discuss 

**Hint**: This question is asking about the front door criterion. Check whether the conditions apply for the front door criterion on hold. Note that an effect is *not* identified if the data pattern it produces is also consistent with a different effect. Is that the case here? Note you can generate and update models of this form with `CausalQueries`.
:::

### Discussion

Three conditions have to be met for the front door criterion to hold:

* M completely mediates the effect of X on Y, i.e. all causal paths from X to Y go through M
* There us no unblocked backdoor path from X to M
* All backdoor paths from M to Y are blocked by X

```{r}
make_model("X -> M -> Y <-> X") %>%
  plot()
```

Scenario 1: direct causal path between both X and Y

The second and third assumption seem to hold for the model; there is only one path from X to M and the backdoor path from M to Y is blocked by X (thus controlled for). However, there is a second direct pathway from X to Y, meaning that the first condition is violated. 

With correlations of 0.9 between both X and M and M and Y, I would therefore argue that the causal effect cannot be identified. With perfect deterministic relationships between the variables (correlation = 1), though, I think that there cannot be a backdoor path between X and Y as there is no more variance that is not explained via the pathway through M.

```{r}
make_model("X -> M -> Y <- C -> X") %>%
  plot()
```

Scenario 2: confounder causing both X and Y

Here, the front door criterion holds: The first condition is fulfilled because there is no causal path from X to Y other than the one through M.


