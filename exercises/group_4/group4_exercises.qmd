---
title: "Group 4 - Week 1 & 2"
subtitle: "Causal Inference and Experimental Design"
date: "19 January, 2024"
date-format: "long"
author:
  - name: Philipp Heyna
    email: "<a href='mailto:philipp.heyna@hu-berlin.de'><span>&#64;</span>philipp.heyna</a>"
  - name: Nader Hotait
    email: "<a href='mailto:nader.hotait@hu-berlin.de'><span>&#64;</span>nader.hotait</a>"
  - name: Daniel Kuhlen
    email: "<a href='mailto:kuhlenda@hu-berlin.de'><span>&#64;</span>kuhlenda</a>"
  - name: Yoanna Yankova
    email: "<a href='mailto:yankovay@hu-berlin.de'><span>&#64;</span>yankovay</a>"
format:
  revealjs: 
    theme: white
    logo: hu_siegel-kombi_rgb.png
    css: logo.css
    mbed-resources: true
    slide-level: 3
    slide-number: true
    show-slide-number: all
    preview-links: auto
    number-sections: false
    scrollable: true
    chalkboard: true
---

```{r packages, echo=FALSE}
# packages
pacman::p_load(tidyverse,
               DeclareDesign,
               CausalQueries,
               knitr,
               kableExtra,
               rstan)
```

## Week 1

## Q 2.4 (Confounded) {.smaller}

Declare a design in which:

* The assignment of a  treatment $X$ depends in part on upon some other, binary, variable $W$: in particular  $\Pr(X=1|W=0) = .2$ and $\Pr(X=1|W=1) = .5$)
* The outcome $Y$ depends on both $X$ and $W$: in particular $Y = X*W + u$ where $u$ is a random shock.
* Diagnose a design with three approaches to estimating the effect of $X$ on $Y$: (a) ignoring $W$ (b) adding $W$ as a linear control (c) including both $W$  and an interaction between $W$ and $X$. 

Discuss results. Do any of these return the right answer?

**Hint:** You can add three separate `declare_estimator` steps. They should have distinct labels. The trickiest part is to figure out how to extract the estimate in (c) because you will have both a main term and an interaction term for $X$.

## Model Declaration

```{r model_declaration_1, echo=TRUE}
#| code-line-numbers: "|3-6|7|8-10|11-16"
set.seed(123)
declaration <- 
  declare_model(
    N = 100, 
    U = rnorm(N),
    W = rbinom(N, 1, 0.5), +
    potential_outcomes(Y ~ X * W + U, conditions = list(X = 0:1))) +
  declare_inquiry(ATE = (mean(Y_X_1 - Y_X_0))) + 
  declare_assignment(X = rbinom(N, 1, prob = ifelse(W == 1, 0.5, 0.2))) + 
  declare_measurement(Y = reveal_outcomes(Y ~ X)) +
  declare_estimator(
    Y ~ X, term = "X", inquiry = "ATE", label = "a) Ignore W") +
  declare_estimator(
    Y ~ X + W, term = "X", inquiry = "ATE",label = "b) Control for W") +
  declare_estimator(
    Y ~ X + X * W + W, term = "X", inquiry = "ATE",label = "c) Interaction")
```

## Model Diagnosis

```{r echo=TRUE}
model_diagnosis <-
  diagnose_design(declaration,
                  sims = 500,
                  bootstrap_sims = 100)

reshape_diagnosis(model_diagnosis) %>%
  kable() %>%
  kableExtra::kable_styling(font_size = 18)
```

## Discussion {.smaller}

The role of $W$ is defined as a confounder since it serves as a parent variable influencing both the treatment assignment $X$ and the treatment outcome $Y$. Failing to adjust for this confounder in the model can lead to biased estimations. Such a bias is conventionally referred to as "common cause confounding bias" or, in other words, a violation of the backdoor criterion. Therefore, it is crucial to incorporate $W$ into the model. Utilizing simulations through `DeclareDesign`, we gain insights into this specific phenomenon. From the simulation results, it is evident that the model which accounts for $W$ (*"Control for W"*) produces mean estimates that are considerably closer and less biased compared to the estimand than the model that neglects $W$ (*"Ignore W"*). Furthermore, both the SD and RMSE metrics suggest that the estimates from the model accounting for the confounder are less erroneous compared to those from the model that disregards it.


## Q 3.4

+ A set of units have outcome $Y^1_i$ at baseline.
+ At endline they have potential outcomes $Y^2_i(0)$ and  $Y^2_i(1)$

1. Write down the estimand for the average effect of treatment on endline outcomes
2. Write down the estimand for the average effect of treatment on the change from baseline to endline for all units

Compare these and discuss.

## Discussion{.smaller}

Assuming:

1. $\text{ATE}_{\text{endline}} = \frac{1}{N} \sum_{i=1}^{N} \left( Y^2_i(1) - Y^2_i(0) \right)$
2. $\text{ATE}_{\text{change}} = \frac{1}{N} \sum_{i=1}^{N} \left( \left( Y^2_i(1) - Y^1_i \right) - \left( Y^2_i(0) - Y^1_i \right) \right)$

.   .   .   

One can conclude that $\text{ATE}_{\text{endline}}$ approximates an estimator, which informs us about the average size of the treatment effect on a binary outcome. However, $\text{ATE}_{\text{change}}$ provides insight into the treatment effect as a comparison between conditions before and after treatment, indicating the effectiveness of the treatment relative to not being treated. Hence, the first scenario informs us about the strength of the treatment given the prevalence of positive outcomes, while the second scenario reveals the effectiveness of the treatment by considering the initial conditions of the treated units.

.   .   .   

Assuming that $ATE = ATT$ and considering  $Y^{t=1}_i$ and $Y^{t=2}_i$ in this scenario, one could describe $\text{ATE}_{\text{endline}}$ as a between-estimator of treated units, and $\text{ATE}_{\text{change}}$ as an in-between estimation of treated units before and after treatment, effectively combining between- and within-unit estimations.

## Q 4.4 {.smaller}
Imagine a model that looks like this:

```{r, echo = FALSE, fig.height = 3, fig.width = 10}
make_model("X -> M -> Y <-> X") |> plot(x_coord = 1:3, y_coord = c(1,1,1))
```

* Say that in truth  ATE of  $X$ on $M$ is .9 and that the ATE of  $M$ on $Y$ is .9. Is the implied effect of 0.81 on $X$ on $Y$ identified?   
* Say that in truth  ATE of  $X$ on $M$ is 1 and that the ATE of  $M$ on $Y$ is 1. Is the implied effect of 1 on $X$ on $Y$ identified?   
* Discuss

**Hint**: This question is asking about the front door criterion. Check whether the conditions apply for the front door criterion on hold. Note that an effect is *not* identified if the data pattern it produces is also consistent with a different effect. Is that the case here? Note you can generate and update models of this form with `CausalQueries`.


## Discussion 
Three conditions have to be met for the front door criterion to hold:

+ $M$ completely mediates the effect of $X$ on Y, i.e., all causal paths from $X$ to $Y$ go through $M$
+ There us no unblocked backdoor path from $X$ to $M$
+ All backdoor paths from $M$ to $Y$ are blocked by $X$

## Scenario 1{.smaller}
**Direct causal path between both X and Y**

```{r fig.height = 3, fig.width = 10}
make_model("X -> M -> Y <-> X") %>%
  plot(x_coord = 1:3, y_coord = c(1,1,1))
```

The second and third assumption seem to hold for the model; there is only one path from X to M and the backdoor path from M to Y is blocked by X (thus controlled for). However, there is a second direct pathway from X to Y, meaning that the first condition is violated. 

With correlations of 0.9 between both X and M and M and Y, I would therefore argue that the causal effect cannot be identified. With perfect deterministic relationships between the variables (correlation = 1), though, I think that there cannot be a backdoor path between X and Y as there is no more variance that is not explained via the pathway through M.


## Scenario 2{.smaller}
**Confounder causing both X and Y**

```{r fig.height = 3, fig.width = 10}
make_model("X -> M -> Y <- C -> X") %>%
  plot(x_coord = c(2,1,2,3), y_coord = c(2,1,1,1))
```

Here, the front door criterion holds: The first condition is fulfilled because there is no causal path from X to Y other than the one through M.

## Using `CausalQueries` 1 {.smaller}

```{r echo=TRUE}
model <- make_model("X -> M -> Y <-> X")
model <- set_priors(model, distribution = "jeffreys")
data_1 <- fabricate(N = 6500, 
                  X = rep(0:1, N/2), 
                  M = rbinom(N, 1, 0.05 + .9*X), 
                  Y = rbinom(N, 1, 0.05 + .9*M))

model_1 <- model %>%
  update_model(data_1, refresh = 0)

query_model(
    model = model_1, 
    using = c("priors", "posteriors"),
    query = "Y[X=1] - Y[X=0]",
    )  %>%
  kable(digits = 2) %>%
  kableExtra::kable_styling(font_size = 18)
```


## Using `CausalQueries` 2 {.smaller}

```{r echo=TRUE}
data_2 <- fabricate(N = 6500, 
                  X = rep(0:1, N/2), 
                  M = X, 
                  Y = M)

model_2 <- model %>%
  update_model(data_2, refresh = 0)

query_model(
    model = model_2, 
    using = c("priors", "posteriors"),
    query = "Y[X=1] - Y[X=0]",
    )  %>%
  kable(digits = 2) %>%
  kableExtra::kable_styling(font_size = 18)
```

## Week 2

## Q 5.4 {.smaller}

Say you want to include a control variable. But you have missingness in the control. Should you proceed and what can you do about it? Declare a design for an experiment in which a binary covariate X is related to potential outcomes, according to b, and so to treatment effects. Say X is missing with probability p.

Compare answer strategies in which you:

-   do not control for
-   do control for but drop whenever is missing and
-   Treat as a block in your analysis design with three values (0, 1, and missing).

### Varying N {.smaller}

```{r echo=TRUE}
p <- 0.5

# Model with standard random assignment
model_default <-
  declare_model(
    N = 100,
    b = 0.5,
    X = b * rbinom(N, size = 1, prob = 0.5),
    X_mi = ifelse(X == 1, # New version of X with missings (missing completely at random)
                  sample(x = c(1, NA), size = N, prob = c(1-p, p), replace = TRUE),
                  sample(x = c(0, NA), size = N, prob = c(1-p, p), replace = TRUE)),
    Blocks = case_when(X_mi == 1 ~ "one",
                       X_mi == 0 ~ "zero",
                       is.na(X_mi) == TRUE ~ "missing"),
    U = rnorm(N, mean = 0, sd = 1),
    potential_outcomes(Y ~ Z + Z * X + X + U, conditions = list(Z = c(0, 1)))
  )

inquiry_ate <- 
  declare_inquiry(ATE = mean(Y_Z_1 - Y_Z_0))

data_strategy_ra <- 
  declare_assignment(Z = complete_ra(N)) +
  declare_measurement(Y = reveal_outcomes(Y ~ Z))
  
answer_strategy_ra <-  
  declare_estimator(Y ~ Z, covariates = ~X, .method = lm_lin, inquiry = "ATE", label = "X Complete") +
  declare_estimator(Y ~ Z, inquiry = "ATE", label = "X Drop") +
  declare_estimator(Y ~ Z, covariates = ~X_mi, .method = lm_lin, inquiry = "ATE", label = "X Incomplete")

design_54_N_ra <- model_default + inquiry_ate + data_strategy_ra + answer_strategy_ra

# Data and Answer strategies for block random assignment
data_strategy_bl <-
  declare_assignment(Z = block_ra(blocks = Blocks),
                     Y = reveal_outcomes(Y ~ Z))
  
answer_strategy_bl <-
  declare_estimator(Y ~ Z, covariates = ~X_mi, .method = lm_lin, label = "X Blocks")

design_54_N_bl <- model_default + inquiry_ate + data_strategy_bl + answer_strategy_bl

# Varying N
design_54_N_ra <- redesign(design_54_N_ra, N = c(10, 50, 100, 500, 1000))
design_54_N_bl <- redesign(design_54_N_bl, N = c(10, 50, 100, 500, 1000))
```

### Varying N: Graph

```{r echo=FALSE}
#| warning: false

df_vary_N_ra <- design_54_N_ra %>% 
  diagnose_design() %>%
  reshape_diagnosis() %>%
  mutate(N = as.numeric(N))

df_vary_N_bl <- design_54_N_bl %>% 
  diagnose_design() %>%
  reshape_diagnosis() %>%
  mutate(N = as.numeric(N))

df_vary_N <- rbind(df_vary_N_ra, df_vary_N_bl)

df_vary_N_plot <- as.data.frame(df_vary_N) %>%
  filter(str_detect(Design, "design")) %>%
  mutate(RMSE = as.numeric(RMSE)) %>%
  select(Estimator, N, RMSE)

ggplot(df_vary_N_plot, aes(x = N, y = RMSE, color = factor(Estimator))) +
  geom_line() +
  labs(title = "Varying N",
       color = "Estimator") +
  theme_bw()
```

### Varying p {.smaller}

```{r echo=TRUE}
p01 <- 0.1
p03 <- 0.3
p07 <- 0.7
p09 <- 0.9

# Using basic model components with N = 100 and p = 0.5
design_54_p05_ra <- model_default + inquiry_ate + data_strategy_ra + answer_strategy_ra
design_54_p05_bl <- model_default + inquiry_ate + data_strategy_bl + answer_strategy_bl

# New models with p = 0.1
model_p01 <-
  declare_model(
    N = 100,
    b = 0.5,
    X = rbinom(N, size = 1, prob = 0.5),
    X_mi = ifelse(X == 1, # New version of X with missings (missing completely at random)
                  sample(x = c(1, NA), size = N, prob = c(1-p01, p01), replace = TRUE),
                  sample(x = c(0, NA), size = N, prob = c(1-p01, p01), replace = TRUE)),
    Blocks = case_when(X_mi == 1 ~ "one",
                       X_mi == 0 ~ "zero",
                       is.na(X_mi) == TRUE ~ "missing"),
    U = b * X + rnorm(N, mean = 0, sd = 1),
    potential_outcomes(Y ~ Z + b * X + U, conditions = list(Z = c(0, 1)))
  )

design_54_p01_ra <- model_p01 + inquiry_ate + data_strategy_ra + answer_strategy_ra
design_54_p01_bl <- model_p01 + inquiry_ate + data_strategy_bl + answer_strategy_bl

# New models with p = 0.3
model_p03 <-
  declare_model(
    N = 100,
    b = 0.5,
    X = rbinom(N, size = 1, prob = 0.5),
    X_mi = ifelse(X == 1, # New version of X with missings (missing completely at random)
                  sample(x = c(1, NA), size = N, prob = c(1-p03, p03), replace = TRUE),
                  sample(x = c(0, NA), size = N, prob = c(1-p03, p03), replace = TRUE)),
    Blocks = case_when(X_mi == 1 ~ "one",
                       X_mi == 0 ~ "zero",
                       is.na(X_mi) == TRUE ~ "missing"),
    U = b * X + rnorm(N, mean = 0, sd = 1),
    potential_outcomes(Y ~ Z + b * X + U, conditions = list(Z = c(0, 1)))
  )

design_54_p03_ra <- model_p03 + inquiry_ate + data_strategy_ra + answer_strategy_ra
design_54_p03_bl <- model_p03 + inquiry_ate + data_strategy_bl + answer_strategy_bl

# New models with p = 0.7
model_p07 <- # random assignment
  declare_model(
    N = 100,
    b = 0.5,
    X = rbinom(N, size = 1, prob = 0.5),
    X_mi = ifelse(X == 1, # New version of X with missings (missing completely at random)
                  sample(x = c(1, NA), size = N, prob = c(1-p07, p07), replace = TRUE),
                  sample(x = c(0, NA), size = N, prob = c(1-p07, p07), replace = TRUE)),
    Blocks = case_when(X_mi == 1 ~ "one",
                       X_mi == 0 ~ "zero",
                       is.na(X_mi) == TRUE ~ "missing"),
    U = b * X + rnorm(N, mean = 0, sd = 1),
    potential_outcomes(Y ~ Z + b * X + U, conditions = list(Z = c(0, 1)))
  )

design_54_p07_ra <- model_p07 + inquiry_ate + data_strategy_ra + answer_strategy_ra
design_54_p07_bl <- model_p07 + inquiry_ate + data_strategy_bl + answer_strategy_bl

# New models with p = 0.9
model_p09 <- # random assignment
  declare_model(
    N = 100,
    b = 0.5,
    X = rbinom(N, size = 1, prob = 0.5),
    X_mi = ifelse(X == 1, # New version of X with missings (missing completely at random)
                  sample(x = c(1, NA), size = N, prob = c(1-p09, p09), replace = TRUE),
                  sample(x = c(0, NA), size = N, prob = c(1-p09, p09), replace = TRUE)),
    Blocks = case_when(X_mi == 1 ~ "one",
                       X_mi == 0 ~ "zero",
                       is.na(X_mi) == TRUE ~ "missing"),
    U = b * X + rnorm(N, mean = 0, sd = 1),
    potential_outcomes(Y ~ Z + b * X + U, conditions = list(Z = c(0, 1)))
  )

design_54_p09_ra <- model_p09 + inquiry_ate + data_strategy_ra + answer_strategy_ra
design_54_p09_bl <- model_p09 + inquiry_ate + data_strategy_bl + answer_strategy_bl

designs_vary_p <- list("R 0.1" = design_54_p01_ra,
                       "B 0.1" = design_54_p01_bl,
                       "R 0.3" = design_54_p03_ra,
                       "B 0.3" = design_54_p03_bl,
                       "R 0.5" = design_54_p05_ra,
                       "B 0.5" = design_54_p05_bl,
                       "R 0.7" = design_54_p07_ra,
                       "B 0.7" = design_54_p07_bl,
                       "R 0.9" = design_54_p09_ra,
                       "B 0.9" = design_54_p09_bl)
```

### Varying p: Graph

```{r echo=FALSE}
#| warning: false

df_vary_p <- designs_vary_p %>% 
  diagnose_design() %>%
  reshape_diagnosis()

df_vary_p_plot <- as.data.frame(df_vary_p) %>%
  filter(str_detect(Design, "0.")) %>%
  mutate(p = as.numeric(substr(Design, 3, 6))) %>%
  mutate(RMSE = as.numeric(RMSE)) %>%
  select(Estimator, p, RMSE)

ggplot(df_vary_p_plot, aes(x = p, y = RMSE, color = factor(Estimator))) +
  geom_line() +
  labs(title = "Varying p",
       color = "Estimator") +
  theme_bw()
```

### Varying b {.smaller}

```{r echo=TRUE}
# Using basic model components with N = 100
design_54_b_ra <- model_default + inquiry_ate + data_strategy_ra + answer_strategy_ra
design_54_b_bl <- model_default + inquiry_ate + data_strategy_bl + answer_strategy_bl

# Varying b
design_54_b_ra <- redesign(design_54_b_ra, b = c(0.1, 0.3, 0.5, 0.7, 0.9))
design_54_b_bl <- redesign(design_54_b_bl, b = c(0.1, 0.3, 0.5, 0.7, 0.9))

designs_vary_b <- append(design_54_b_ra,
                         design_54_b_bl)

names(designs_vary_b) <-
  list("b = 0.1 Random",
       "b = 0.3 Random",
       "b = 0.5 Random",
       "b = 0.7 Random",
       "b = 0.9 Random",
       "b = 0.1 Blocks",
       "b = 0.3 Blocks",
       "b = 0.5 Blocks",
       "b = 0.7 Blocks",
       "b = 0.9 Blocks")
```

### Varying b: Graph

```{r echo=FALSE}
#| warning: false

df_vary_b <- designs_vary_b %>% 
  diagnose_design() %>%
  reshape_diagnosis()

df_vary_b_plot <- as.data.frame(df_vary_b) %>%
  filter(str_detect(Design, "0.")) %>%
  mutate(RMSE = as.numeric(RMSE)) %>%
  mutate(b = as.numeric(b)) %>%
  select(Estimator, b, RMSE)

ggplot(df_vary_b_plot, aes(x = b, y = RMSE, color = factor(Estimator))) +
  geom_line() +
  labs(title = "Varying b",
       color = "Estimator") +
  theme_bw()
```

## Week 3

## Q 6.4  {.smaller}

Hierarchical

Generate a simple multilevel experimental design (e.g 20 children each in 20 schools). Assume that the treatment effect in each schools is drawn from a normal distribution with a given variance

Use design diagnosis to assess the ability of a Bayesian multilevel hierarchical to recover

Bonus: Are estimates of treatment effects more or less reliable than what you would get from a frequentist approach that interacts school IDs with treatment?

## Solution

```{r}
#| output: false
#| echo: true

set.seed(123)
stan_model <- stan_model(file = "multilevel_model.stan")

# Generate data
N <- 400
school <- rep(1:20, each = 20)
school_b <- 1 + rnorm(20)
X <- rep(0:1, times = N / 2)  # Ensure X has length 400
Y <- school_b[school] * X + rnorm(N)

# Prepare data list
ml_data <- list(
  N = N,
  school = school,
  X = X,
  Y = Y
)

# Fit the Bayesian multilevel hierarchical model
fit <- sampling(stan_model, data = ml_data, iter = 2000, chains = 4)
```

## Solution

```{r}
#| echo: false
print(fit, pars = c("sigma[1]", "sigma[2]", "sigma[3]", "mu_a", "mu_b"))
```

## Week 4

## Q 9.4  {.smaller}

Which of these problems could be addressed using instrumental variables? In each case, what kinds of concern might you have about the IV strategy?

## Instrumental Variables

1. We observe a variable, the **instrument**, that is correlated with the outcome
2. The **instrument** has no causal effect on the outcome.
3. The **instrument** has a causal effect on the treatment.
4. We assume random assignment of the **instrument**.
5. The causal effect of the **instrument** on the treatment is their correlation in the data.
6. Since the **instrument** is randomly assigned, it is not correlated with any other confounders except the treatment.

## Instrumental Variables: DAG
Example: The colonial origins of comparative development: An empirical investigation

```{r iv_dag}

smoking_ca_dag <- ggdag::dagify(outcome ~ treatment,
                                outcome ~ U,
                                treatment ~ U,
                                treatment ~ instrument,
                                labels = c("outcome" = "Y (GDP)", 
                                           "instrument" = "Z (Settler Mortality)",
                                           "treatment" = "X (Institutions)",
                                           "U" = "U")
                                )

ggdag::ggdag(smoking_ca_dag, 
             text = FALSE, 
             use_labels = "label") +
  theme_void()
```

## Scenario 1
*Experimenters introduce a unconditional cash transfers into a set of villages in 2012 and use it to measure access school attendance in 2015. You come on the scene later and are interested in whether the transfer could have led to greater political participation in 2017.*

**IV applicability**: This scenario does not lend itself for the IV-Strategy since the interest is in the effect of a random treatment (cash transfers) directly on the outcome (political participation)

## Scenario 2
*Experimenters introduce an unconditional cash transfers into a set of villages in 2012 and use it to measure access school attendance in 2015. You come on the scene later and are interested in whether the increased school attendance could have led to greater political participation in 2017.*

**IV applicability**: Yes, if the cash transfers are assumed to only affect political participation through increased school attendance.

**IV concerns**: This is a very strong (implausible) assumption.

## Scenario 3
*You want to understand the effects of attending a rally on subsequent support for a candidate. You send a random set of voters a flyer about an upcoming demonstration.*

**IV applicability**: Yes

**IV concerns**:

* Flyer should not effect outcome (e.g. by providing informmation or framing a candidate)
* Non-Compliance
  + People who receive the flyer and do not attend the rally
  + People who do not receive the flyer and attend the rally 

## Scneario 4
*You want to understand the effects of attending a rally on subsequent support for a candidate. You send a random set of voters a flyer about an upcoming demonstration but you find out later that your enumerators did not deliver the flyers in a bunch of areas.*

**IV concerns**:

* Violations of the assumption that the instrument is randomly assigned
  + non-delivery might be correlated with characteristics of the areas which also influence candidate support

## Scneario 5
*You want to understand the effects sending flyers about an upcoming demonstration but you find out later that your computer code used incomplete data when making assignments and so failed to assign treatment to a whole bunch of regions.*

## Scenario 6 
*You want to understand whether sending flyers increases participation because people actually go to the rallies or because peopleâ€™s general level awareness of the election increases, whether or not they go.*
